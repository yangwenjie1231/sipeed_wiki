{"/maixpy/doc/en/ai_model_converter/maixcam.html":{"title":"Convert ONNX Model to a Format Usable by MaixCAM / MaixPy (MUD)","content":" title: Convert ONNX Model to a Format Usable by MaixCAM / MaixPy (MUD) ## Introduction Models trained on a computer cannot be directly used by MaixCAM due to its limited hardware performance. Generally, we need to perform `INT8` quantization to reduce computation and convert the model into a format supported by MaixCAM. This article explains how to convert an ONNX model into a format that MaixCAM can use (MUD model). ## Model File Formats Supported by MaixCAM MUD (Model Universal Description file) is a model description file supported by MaixPy, used to unify model files across different platforms, making MaixPy code cross platform compatible. It is essentially a text file in `ini` format and can be edited with a text editor. Typically, a MUD file is accompanied by one or more actual model files. For MaixCAM, the actual model file is in `.cvimodel` format, with the MUD file providing some descriptive information. For example, a `YOLOv8` model consists of two files: `yolov8n.mud` and `yolov8n.cvimodel`. The former contains: ```ini [basic] type cvimodel model yolov8n.cvimodel [extra] model_type yolov8 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair dryer, toothbrush ``` This file specifies the model type as `cvimodel` and the model path relative to the MUD file as `yolov8n.cvimodel`. It also includes information such as preprocessing `mean` and `scale` (which should match the preprocessing method used during training), and `labels` representing the 80 categories for object detection. When using this model, place both files in the same directory. ## Preparing the ONNX Model Prepare your ONNX model and view it on [https://netron.app/](https://netron.app/) to ensure that the operators used in your model are supported by the conversion tool. The list of supported operators can be found in the **CVITEK_TPU_SDK Developer Guide.pdf** available from [Sophgo's TPU SDK](https://developer.sophgo.com/thread/473.html). ## Identify Appropriate Quantization Output Nodes Models usually have post processing nodes that are handled by the CPU. We need to strip these out as they can affect quantization quality and potentially cause quantization to fail. For example, in `YOLOv5`: ![YOLOv5 ONNX Model](../../assets/yolov5s_onnx.jpg) There are three `conv` layers, with subsequent calculations handled by the CPU. For quantization, use the outputs of these `conv` layers as the final outputs of the model. The output names in this case are `/model.24/m.0/Conv_output_0,/model.24/m.1/Conv_output_0,/model.24/m.2/Conv_output_0`. ## Setting Up the Model Conversion Environment The model conversion uses Sophgo's [https://github.com/sophgo/tpu mlir](https://github.com/sophgo/tpu mlir). We will install it in a Docker environment to avoid compatibility issues with the host machine. ### Install Docker Follow the [official Docker installation documentation](https://docs.docker.com/engine/install/ubuntu/). For example: ```shell # Install dependencies for Docker sudo apt get update sudo apt get install apt transport https ca certificates curl gnupg agent software properties common # Add the official Docker source curl fsSL https://download.docker.com/linux/ubuntu/gpg sudo apt key add sudo add apt repository \"deb [arch amd64] https://download.docker.com/linux/ubuntu $(lsb_release cs) stable\" # Install Docker sudo apt get update sudo apt get install docker ce docker ce cli containerd.io ``` ### Pull the Docker Image ```shell docker pull sophgo/tpuc_dev:latest ``` > If pulling from within China, you may experience slow speeds. Consider setting up a local mirror. You can search for instructions or refer to [Docker Proxy and Mirror Setup](https://neucrack.com/p/286). ### Run the Container ```shell docker run privileged name tpu env v /home/$USER/data:/home/$USER/data it sophgo/tpuc_dev ``` This command starts a container named `tpu env`, mounting the `~/data` directory from the host to the container's `~/data`, enabling file sharing and path consistency. To start the container next time, use `docker start tpu env && docker attach tpu env`. ### Install tpu mlir Download the `whl` file from [GitHub](https://github.com/sophgo/tpu mlir/releases) and place it in the `~/data` directory. Install it in the container: ```shell pip install tpu_mlir*.whl # Replace with the downloaded file name ``` Running `model_transform.py` should display help information, indicating a successful installation. ## Writing the Conversion Script The conversion mainly involves two commands: `model_transform.py` and `model_deploy.py`. To simplify the process, create a script `convert_yolov5_to_cvimodel.sh`: ```shell #!/bin/bash set e net_name yolov5s input_w 640 input_h 640 # mean: 0, 0, 0 # std: 255, 255, 255 # mean # 1/std # mean: 0, 0, 0 # scale: 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 mkdir p workspace cd workspace # convert to mlir model_transform.py \\ model_name ${net_name} \\ model_def ../${net_name}.onnx \\ input_shapes [[1,3,${input_h},${input_w}]] \\ mean \"0,0,0\" \\ scale \"0.00392156862745098,0.00392156862745098,0.00392156862745098\" \\ keep_aspect_ratio \\ pixel_format rgb \\ channel_format nchw \\ output_names \"/model.24/m.0/Conv_output_0,/model.24/m.1/Conv_output_0,/model.24/m.2/Conv_output_0\" \\ test_input ../dog.jpg \\ test_result ${net_name}_top_outputs.npz \\ tolerance 0.99,0.99 \\ mlir ${net_name}.mlir # export bf16 model # not use quant_input, use float32 for easy coding model_deploy.py \\ mlir ${net_name}.mlir \\ quantize BF16 \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ model ${net_name}_bf16.cvimodel echo \"calibrate for int8 model\" # export int8 model run_calibration.py ${net_name}.mlir \\ dataset ../images \\ input_num 200 \\ o ${net_name}_cali_table echo \"convert to int8 model\" # export int8 model # add quant_input, use int8 for faster processing in maix.nn.NN.forward_image model_deploy.py \\ mlir ${net_name}.mlir \\ quantize INT8 \\ quant_input \\ calibration_table ${net_name}_cali_table \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ tolerance 0.9,0.6 \\ model ${net_name}_int8.cvimodel ``` Key parameters include: `output_names`: Names of the output nodes we identified earlier. `mean, scale`: Preprocessing methods used during training. For instance, `YOLOv5` preprocesses the image by subtracting `mean` and dividing by `std`. In this example, `mean` is `0` and `std` is `255`, meaning the scale is `1/std`. Modify these according to your model's preprocessing method. `test_input`: The image used for testing during conversion. In this script, it's `../dog.jpg`, so ensure this image is placed in the same directory as the script. Replace it according to your model. `tolerance`: Allowed error margin before and after quantization. If errors during conversion indicate values lower than this threshold, it means the converted model might have significant deviation from the ONNX model. If acceptable, you can lower this threshold. Often, this requires optimizing the model and carefully examining post processing. `quantize`: The data type for quantization. Generally, `INT8` models are used on MaixCAM. Although a BF16 model is also converted here, INT8 is preferred for speed, while BF16 can be considered if INT8 conversion is not feasible or if precision is critical. `dataset`: The dataset used for quantization. For `YOLOv5`, it's a folder of images. Copy a subset of typical images from the coco dataset. Use ` input_num` to specify the number of images used (should be ≤ the actual number in the images directory). ## Running the Conversion Script Run the script with: ```shell chmod +x convert_yolov5_to_cvimodelsh && ./convert_yolov5_to_cvimodel.sh ``` Wait for the conversion to complete. If errors occur, carefully review the previous explanations for potential issues with parameters or output layers. Upon successful conversion, the `workspace` folder will contain a `**_int8.cvimodel` file. ## Writing the MUD File Modify the MUD file according to your model. For `YOLOv5`, the MUD file looks like this. Change `labels` to match your trained model: ```ini [basic] type cvimodel model yolov5s.cvimodel [extra] model_type yolov5 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 anchors 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair dryer, toothbrush ``` The `basic` section specifies the model file type and path, necessary for loading and running the model using the `maix.nn.NN` class in `MaixPy` or `MaixCDK`. The `extra` section varies based on the model. It includes parameters such as preprocessing, post processing, and labels. For `YOLOv5`, you can download its model, copy, and modify it. If you need to support a new model not currently supported by `MaixPy`, define the `extra` parameters based on the model's preprocessing and post processing requirements, then write the corresponding decoding class. If you prefer not to modify the `MaixPy` C++ source code, you can use the `maix.nn.NN` class to load the model and handle post processing in Python, though this is less efficient. ## Writing Post processing Code If you modify the `mud` file based on supported models, you can directly use the corresponding code in `MaixPy` or `MaixCDK`. If you need to support new models, design the `mud` file and write the preprocessing and post processing code: 1. **Option 1:** Use `maix.nn.NN` in `MaixPy` to load the model, then use the `forward` or `forward_image` function to run the model and process the output with Python functions. 2. **Option 2:** In `MaixCDK`, refer to [YOLOv5 source code](https://github.com/sipeed/MaixCDK/blob/71d5b3980788e6b35514434bd84cd6eeee80d085/components/nn/include/maix_nn_yolov5.hpp), add a new `hpp` file, and create a class to process your model. Modify all functions and class `@maixpy` annotations, compile the `MaixPy` project, and call the new class to run the model in `MaixPy`. You can submit the source code (Pull Request) to the main `MaixPy` repository to contribute to the community and share new models on [MaixHub](https://maixhub.com/share) for rewards ranging from 30 to 2000 yuan based on quality!"},"/maixpy/doc/en/modules/rtc.html":{"title":"Using the RTC Module with MaixCAM MaixPy","content":" title: Using the RTC Module with MaixCAM MaixPy The MaixCAM Pro has an onboard RTC module, which will automatically synchronize the system time upon power on and also sync time from the network. It will automatically re sync when there are changes in network status. Therefore, under normal circumstances, you don’t need to manually operate the RTC; you can directly use the system’s time API to get the current time. If you do need to manually operate the RTC, please refer to [bm8653 RTC Module Usage](./bm8653.html). Before manually operating the RTC, you can disable automatic synchronization by deleting the RTC and NTP related services in the system’s `/etc/init.d` directory. > MaixCAM does not have an onboard RTC."},"/maixpy/doc/en/modules/acc.html":{"title":"Reading the Accelerometer and Attitude Calculation with MaixCAM MaixPy","content":" title: Reading the Accelerometer and Attitude Calculation with MaixCAM MaixPy ## Introduction to IMU For the MaixCAM Pro, it has an onboard QMI8658 chip that integrates a three axis gyroscope and a three axis accelerometer. This chip can provide high precision data on attitude, motion, and position, making it suitable for various applications that require accurate motion detection, such as drones, robots, game controllers, and virtual reality devices. The QMI8658 features low power consumption, high stability, and high sensitivity. Below is an introduction to using the IMU module to obtain attitude data. > MaixCAM does not have an onboard accelerometer, but you can connect one externally using an IIC driver. ## Using IMU in MaixPy Example: ```python from maix.ext_dev import imu i imu.IMU(\"qmi8658\", mode imu.Mode.DUAL, acc_scale imu.AccScale.ACC_SCALE_2G, acc_odr imu.AccOdr.ACC_ODR_8000, gyro_scale imu.GyroScale.GYRO_SCALE_16DPS, gyro_odr imu.GyroOdr.GYRO_ODR_8000) while True: data i.read() print(\"\\n \") print(f\"acc x: {data[0]}\") print(f\"acc y: {data[1]}\") print(f\"acc z: {data[2]}\") print(f\"gyro x: {data[3]}\") print(f\"gyro y: {data[4]}\") print(f\"gyro z: {data[5]}\") print(f\"temp: {data[6]}\") print(\" \\n\") ``` Initialize the IMU object according to your needs, and then call `read()` to get the raw data read from the IMU. **If the `mode` parameter is set to `DUAL`, the data returned by `read()` will be `[acc_x, acc_y, acc_z, gyro_x, gyro_y, gyro_z, temp]`. If `mode` is set to only one of ACC or GYRO, it will return only the corresponding `[x, y, z, temp]`. For example, if ACC is selected, `read()` will return `[acc_x, acc_y, acc_z, temp]`.** For detailed information on the BM8653 API, please refer to the [BM8653 API Documentation](../../../api/maix/ext_dev/imu.html)"},"/maixpy/doc/en/modules/bm8653.html":{"title":"MaixPy bm8653 Driver Instructions","content":" title: MaixPy bm8653 Driver Instructions update: date: 2024 08 27 author: iawak9lkm version: 1.0.0 content: Initial document ## Introduction to BM8653 BM8653 is a real time clock (RTC) chip widely used in various electronic devices to provide accurate time and date information. It features low power consumption and high precision, capable of continuing to operate via a backup battery when the device is powered off, ensuring the continuity and accuracy of time. ## Using BM8653 in MaixPy Using BM8653 in MaixPy is straightforward; you only need to know which I2C bus your platform's BM8653 is mounted on. The onboard BM8563 on the MaixCAM Pro is mounted on I2C 4. Example: ```python from maix import ext_dev, pinmap, err, time ### Enable I2C # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SCL\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SDA\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) BM8653_I2CBUS_NUM 4 rtc ext_dev.bm8563.BM8563(BM8653_I2CBUS_NUM) ### 2020 12 31 23:59:45 t [2020, 12, 31, 23, 59, 45] # Set time rtc.datetime(t) while True: rtc_now rtc.datetime() print(f\"{rtc_now[0]} {rtc_now[1]} {rtc_now[2]} {rtc_now[3]}:{rtc_now[4]}:{rtc_now[5]}\") time.sleep(1) ``` If you are using the onboard BM8653 on the MaixCAM Pro, there is no need to enable I2C 4. The example demonstrates reading from and writing to the BM8653, setting or retrieving the current time. You can also use the following example to set the current time in the BM8653 to the system time, or set the current system time to the time in the BM8653. ```python from maix import ext_dev, pinmap, err, time ### Enable I2C # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SCL\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SDA\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) BM8653_I2CBUS_NUM 4 rtc ext_dev.bm8563.BM8563(BM8653_I2CBUS_NUM) ### Update RTC time from system rtc.systohc() ### Update system time from RTC # rtc.hctosys() while True: rtc_now rtc.datetime() print(f\"{rtc_now[0]} {rtc_now[1]} {rtc_now[2]} {rtc_now[3]}:{rtc_now[4]}:{rtc_now[5]}\") time.sleep(1) ``` **The underlying implementation of BM8653 is similar to the singleton pattern, ensuring that read and write operations on a single BM8653 are thread safe. This means you can create BM8653 objects freely and read/write to BM8653 from any location without causing data race conditions.** The timetuple passed to the BM8653 object follows the format (year, month, day[, hour[, minute[, second]]]), meaning the first three parameters are mandatory, and any missing subsequent parameters will not modify the corresponding time. BM8653 guarantees that a returned timetuple being empty indicates an error, and if not empty, it will always contain a list of 6 elements: (year, month, day, hour, minute, second). For detailed information on the BM8653 API, please refer to the [BM8653 API Documentation](../../../api/maix/ext_dev/bm8563.html)"},"/maixpy/doc/en/modules/qmi8658.html":{"title":"MaixPy qmi8658 Driver Instructions","content":" title: MaixPy qmi8658 Driver Instructions update: date: 2024 08 27 author: iawak9lkm version: 1.0.0 content: Initial document ## Introduction to QMI8658 QMI8658 is an Inertial Measurement Unit (IMU) chip that integrates a three axis gyroscope and a three axis accelerometer. It provides high precision attitude, motion, and position data, making it suitable for various applications requiring accurate motion detection, such as drones, robots, game controllers, and virtual reality devices. QMI8658 features low power consumption, high stability, and high sensitivity. ## Using QMI8658 in MaixPy Using QMI8658 in MaixPy is straightforward; you only need to know which I2C bus your platform's QMI8658 is mounted on. The onboard QMI8658 on the MaixCAM Pro is mounted on I2C 4. Example: ```python from maix import ext_dev, pinmap, err, time ### Enable I2C # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SCL\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SDA\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) QMI8658_I2CBUS_NUM 4 imu ext_dev.qmi8658.QMI8658(QMI8658_I2CBUS_NUM, mode ext_dev.qmi8658.Mode.DUAL, acc_scale ext_dev.qmi8658.AccScale.ACC_SCALE_2G, acc_odr ext_dev.qmi8658.AccOdr.ACC_ODR_8000, gyro_scale ext_dev.qmi8658.GyroScale.GYRO_SCALE_16DPS, gyro_odr ext_dev.qmi8658.GyroOdr.GYRO_ODR_8000) while True: data imu.read() print(\"\\n \") print(f\"acc x: {data[0]}\") print(f\"acc y: {data[1]}\") print(f\"acc z: {data[2]}\") print(f\"gyro x: {data[3]}\") print(f\"gyro y: {data[4]}\") print(f\"gyro z: {data[5]}\") print(f\"temp: {data[6]}\") print(\" \\n\") ``` Initialize the QMI8658 object according to your needs, and then call `read()` to get the raw data read from the QMI8658. **If the `mode` parameter is set to `DUAL`, the data returned by `read()` will be `[acc_x, acc_y, acc_z, gyro_x, gyro_y, gyro_z, temp]`. If `mode` is set to only one of ACC or GYRO, it will return only the corresponding `[x, y, z, temp]`. For example, if ACC is selected, `read()` will return `[acc_x, acc_y, acc_z, temp]`.** For detailed information on the QMI8658 API, please refer to the [QMI8658 API Documentation](../../../api/maix/ext_dev/qmi8658.html)"},"/maixpy/doc/en/modules/tmc2209.html":{"title":"MaixPy tmc2209 单串口驱动使用介绍","content":" title: MaixPy tmc2209 单串口驱动使用介绍 update: date: 2024 08 21 author: iawak9lkm version: 1.0.0 content: 初版文档 ## Introduction to TMC2209 TMC2209 is a stepper motor driver chip produced by the German company Trinamic. It is designed specifically for 2 phase stepper motors, featuring low power consumption, high efficiency, and excellent noise suppression capabilities. TMC2209 supports currents up to 2.8A, making it suitable for various applications such as 3D printers, CNC machines, robots, etc. ## Using TMC2209 to Drive Stepper Motors in MaixPy * Ensure that your stepper motor is a 2 phase 4 wire type, and confirm the step angle of your motor (step_angle), the microstepping resolution you need (micro_step), and the distance the load moves per revolution of the motor (screw_pitch or round_mm). This information will help us configure the driver parameters later. * Generally, TMC2209 driver boards on the market have the following pins (if you find it troublesome, you can purchase our TMC2209 driver board, link [not yet available,敬请期待]): ``` EN VM MS1 GND MS2 2B RX 2A TX 1A NC 1B STEP VDD DIR GND ``` `EN`: EN is the enable pin. Connect this pin to `GND` to enable TMC2209 hardware wise. `MS1`: MS1 is one of the microstepping selection pins, used in conjunction with the MS2 pin to set the microstepping mode of the stepper motor. `MS2`: MS2 is one of the microstepping selection pins, used in conjunction with the MS1 pin to set the microstepping mode of the stepper motor. **This driver program only uses the UART mode of TMC2209. In this mode, the two microstep selection pins are respectively `AD0` (originally `MS1`) and `AD1` (originally `MS2`). The level states of these two pins together form the UART address of the TMC2209, ranging from 0x00 to 0x03.** `TX`: TX is the serial communication transmit pin, used for communication with an external microcontroller via UART. `RX`: RX is the serial communication receive pin, used for communication with an external microcontroller via UART. When using both `RX` and `TX` on TMC2209, ensure there is a 1K ohm resistor between the `RX` of the TMC2209 driver board and the `TX` of the main control chip. Otherwise, communication data anomalies may occur. `NC`: NC is the no connect pin, indicating that this pin does not need to be connected during normal use. `STEP`: STEP is the step signal input pin. Each pulse received advances the stepper motor by one step angle. Since this driver is purely UART driven, this pin does not need to be connected and can be left floating. `DIR`: DIR is the direction signal input pin, used to control the rotation direction of the stepper motor. When DIR is high, the motor rotates clockwise; when DIR is low, the motor rotates counterclockwise. Since this driver is purely UART driven, this pin does not need to be connected and can be left floating. `VM`: VM is the power input pin, connected to the positive terminal of the stepper motor's power supply. `GND`: GND is the ground pin, connected to the negative terminal of the power supply. `2B`, `2A`, `1B`, `1A`: These pins are the phase output pins of the stepper motor, connected to the two phases of the motor's coils. `VDD`: VDD is the logic power input pin, providing power to the internal logic circuits of the chip. * Using TMC2209 Driver in MaixPy As an example, let's consider a stepper motor with a step angle of 18, a microstep resolution of 256, and a screw pitch of 3mm: ```python from maix import pinmap, ext_dev, err, time port \"/dev/ttyS1\" uart_addr 0x00 uart_baudrate 115200 step_angle 18 micro_step 256 screw_pitch 3 speed 6 use_internal_sense_resistors True run_current_per 100 hold_current_per 100 if port \"/dev/ttyS1\": ret pinmap.set_pin_function(\"A19\", \"UART1_TX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ret pinmap.set_pin_function(\"A18\", \"UART1_RX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) slide ext_dev.tmc2209.ScrewSlide(port, uart_addr, uart_baudrate, step_angle, micro_step, screw_pitch, speed, use_internal_sense_resistors, run_current_per, hold_current_per) def reset_callback() > bool: if 2 > 1: # An event occurs (e.g., a sensor is triggered), # indicating that the slide has moved to the boundary and the motor needs to stop. print(\"Reset finish...\") return True # Not occurred, no need to stop the motor. return False def move_callback(per:float) > bool: # per is the percentage of the current distance moved by move() # out of the total distance required for the current move(), ranging from 0 to 100. print(f\"Slide moving... {per}\") if per > 50: # Example: Stop moving when 50% of the total distance for the current move() has been covered. print(f\"{per} > 50%, stop.\") return True return False slide.reset(reset_callback) slide.move(screw_pitch*2, 1, move_callback) slide.move( screw_pitch) while True: slide.move(screw_pitch*2) slide.move( (screw_pitch*2)) time.sleep_ms(100) ``` First, ensure that UART1 is enabled using `pinmap` in the program. Then create a `ScrewSlide` object, using the internal reference resistor by default, and defaulting to 100% of the motor's running current and 100% of the motor's holding current. These parameters may need to be adjusted according to your motor. Next, the routine declares a reset callback function and a move callback function, which are respectively passed into the `reset()` function and `move()` function. The `reset()` and `move()` functions call the callback functions periodically to confirm whether the motor needs to be stopped immediately (when the callback function returns True). Both the `move()` and `reset()` functions are blocking functions, and they will only stop the motor and return when the callback function returns True (or when the specified length of movement is completed in the case of `move()`). ## Using tmc2209 Driver for Stepper Motors with Constant Load in MaixPy **!!!Screw stepper motors with constant load should not be considered as stepper motors with constant load, because screw stepper motors have limit devices to ensure the direction of motion of the load on the rod is known, and the screw stepper motor often collides with the limit device during operation, causing the motor load to not be constant. Other cases can be deduced by analogy to know whether it is a stepper motor with constant load.** In some application scenarios, the load on the stepper motor is constant throughout, and only increases when it hits an edge and stalls. In such cases, you can use the `Slide` class instead of the `ScrewSlide` class, where `Slide` has stall detection functionality. Using `ScrewSlide` is also feasible, it does not have stall detection but is more flexible. Please choose between these two classes based on the usage scenario; this section only discusses the `Slide` class. * Implementation Principle The TMC2209 has an internal register `SG_RESULT`, which stores data proportional to the remaining torque of the motor. If the motor load is constant, the variation in the register value is very small. When the motor stalls, the register value will rapidly decrease and maintain a lower value. By finding the running average value and stall average value of this register for the constant load motor, you can measure whether the motor is stalling at any given moment. * Obtaining the Average Value of the `SG_RESULT` Register The `maix.ext_dev.tmc2209` module provides a function to obtain and save this average value, `maix.ext_dev.tmc2209.slide_scan`. example: ```python from maix import ext_dev, pinmap, err port \"/dev/ttyS1\" uart_addr 0x00 uart_baudrate 115200 step_angle 1.8 micro_step 256 round_mm 60 speed 60 use_internal_sense_resistors True run_current_per 100 hold_current_per 100 if port \"/dev/ttyS1\": ret pinmap.set_pin_function(\"A19\", \"UART1_TX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ret pinmap.set_pin_function(\"A18\", \"UART1_RX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ext_dev.tmc2209.slide_scan(port, uart_addr, uart_baudrate, step_angle, micro_step, round_mm, speed, True, True, run_current_per, hold_current_per, conf_save_path './slide_scan_example.bin', force_update False) ``` After configuring the serial port and driver parameters, call `slide_scan`. The last parameter of `slide_scan`, `force_update`, determines the behavior when the configuration file already exists: > If `force_update` is True, the old configuration will be overwritten with the new configuration. > > If `force_update` is False, the running average value will be updated to the average of the new and old values, and the stall average value will be updated to the larger of the new and old stall average values (for example, if a slide has left and right boundaries, and the left boundary stall average value is less than the right boundary stall average value, meaning the right boundary is more prone to stalling than the left boundary, the easiest stalling average value will be saved). After running this program, the stepper motor will continue to rotate forward until it encounters a stall. Wait about 300ms, then stop the program. The program will record the running average value of the `SG_RESULT` register and the stall average value to `conf_save_path`. Subsequently, the `Slide` class can load this configuration file to stop the motor when a stall is detected. * Verifying the Configuration File Values You may wonder if this configuration is actually usable. The `maix.ext_dev.tmc2209` module provides a function to test this configuration file, `slide_test`. First, ensure the motor is in a stalled state, then modify the parameters to match those used when calling `slide_scan`, and execute the following code. example ```python from maix import ext_dev, pinmap, err port \"/dev/ttyS1\" uart_addr 0x00 uart_baudrate 115200 step_angle 1.8 micro_step 256 round_mm 60 speed 60 use_internal_sense_resistors True run_current_per 100 hold_current_per 100 if port \"/dev/ttyS1\": ret pinmap.set_pin_function(\"A19\", \"UART1_TX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ret pinmap.set_pin_function(\"A18\", \"UART1_RX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ext_dev.tmc2209.slide_test(port, uart_addr, uart_baudrate, step_angle, micro_step, round_mm, speed, True, True, run_current_per, hold_current_per, conf_save_path './slide_scan_example.bin') ``` The motor will stop rotating instantly upon encountering a stall, and the program will end accordingly. The stall stop logic for `Slide.move()` and `Slide.reset()` is the same. * Using `Slide` The approach to using `Slide` is essentially the same as using `ScrewSlide`, except that `Slide` removes the callback function and adds stall stop logic. If a configuration file is not passed when using `Slide`, it can still be used. The stall detection threshold is the average at the start of motor operation multiplied by `Slide.stop_default_per()`/100. The motor stops when the recent average operation number is lower than this value. You can obtain and modify this value through `Slide.stop_default_per()`. ```python from maix import pinmap, ext_dev, err, time port \"/dev/ttyS1\" uart_addr 0x00 uart_baudrate 115200 step_angle 1.8 micro_step 256 round_mm 60 speed 60 use_internal_sense_resistors True run_current_per 100 hold_current_per 100 if port \"/dev/ttyS1\": ret pinmap.set_pin_function(\"A19\", \"UART1_TX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ret pinmap.set_pin_function(\"A18\", \"UART1_RX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) slide ext_dev.tmc2209.Slide(port, uart_addr, uart_baudrate, step_angle, micro_step, round_mm, speed, cfg_file_path \"./slide_conf.bin\") slide.reset() slide.move(60) slide.move( 60) ``` ## Notes **This driver is implemented purely through UART, offering the advantage of requiring fewer pins to drive up to 4 motors with relatively high precision. The downside is that it is not suitable for applications requiring extremely high precision.** Known Issues: * Do not use UART0 of MaixCAM as the driver's serial port, as it may cause MaixCAM to fail to boot properly. **!!! If you find any bugs, we welcome you to submit a PR to report them.** ## Disclaimer This motor driver program (hereinafter referred to as the \"Program\") is developed by [Sipeed] based on the BSD 3 open source license repository [janelia arduino/TMC2209](https://github.com/janelia arduino/TMC2209). The Program is intended for learning and research purposes only and is not guaranteed to work under all environmental conditions. Users assume all risks associated with the use of this Program. [Sipeed] shall not be liable for any losses or damages arising from the use or inability to use the Program, including but not limited to direct, indirect, incidental, special, punitive, or consequential damages. Users should conduct sufficient testing and validation to ensure that the Program meets their specific requirements and environment before using it in practical applications. [Sipeed] makes no express or implied warranties regarding the accuracy, reliability, completeness, or suitability of the Program. Users are responsible for complying with all applicable laws and regulations when using the Program and ensuring that they do not infringe upon the legal rights of any third parties. [Sipeed] shall not be liable for any consequences resulting from users' violation of laws or infringement of third party rights. The interpretation of this disclaimer is reserved by [Sipeed], who also reserves the right to modify this disclaimer at any time."},"/maixpy/doc/en/modules/thermal_cam.html":{"title":"Using Thermal Infrared Image Sensors with MaixCAM and MaixPy","content":"# Using Thermal Infrared Image Sensors with MaixCAM and MaixPy Currently, the official hardware product is not yet available. If you only need low resolution, you can purchase a serial or I2C module from online platforms like Taobao and drive it yourself. This document will be updated when the official high resolution module is released. For thermal infrared camera modules, you might consider options such as [K210 + MLX90640 Infrared Thermal Imager](https://neucrack.com/p/189) or [Heimann HTPA 32x32d Thermal Infrared](https://neucrack.com/p/199)."},"/maixpy/doc/en/modules/temp_humi.html":{"title":"Reading Temperature and Humidity Sensors with MaixCAM MaixPy","content":" title: Reading Temperature and Humidity Sensors with MaixCAM MaixPy ## Introduction By attaching a temperature and humidity sensor module to MaixCAM, you can easily read the environmental temperature and humidity. This example uses the `Si7021` sensor, which can be driven via `I2C`. The complete code is available at [MaixPy/examples/sensors/temp_humi_si7021.py](https://github.com/sipeed/MaixPy/blob/main/examples/sensors/temp_humi_si7021.py). Note that the system image needs to be version `> 2024.6.3_maixpy_v4.2.1`."},"/maixpy/doc/en/modules/tof.html":{"title":"Using TOF Modules for Distance Measurement and Terrain Detection with MaixCAM and MaixPy","content":"# Using TOF Modules for Distance Measurement and Terrain Detection with MaixCAM and MaixPy Sipeed offers [two additional TOF modules](https://wiki.sipeed.com/hardware/zh/maixsense/index.html) that can be used for distance measurement. These modules can be purchased and used with serial communication for your projects."},"/maixpy/doc/en/source_code/build.html":{"title":"MaixCAM MaixPy develop source code guide","content":" title: MaixCAM MaixPy develop source code guide ## Get source code ```shell mkdir p ~/maix cd ~/maix git clone https://github.com/sipeed/MaixPy ``` ## Getting MaixCDK Source Code The MaixPy project depends on MaixCDK. You need to clone it first and place it in a directory on your computer (do not place it under the MaixPy directory). ```shell cd ~/maix git clone https://github.com/sipeed/MaixCDK ``` Then, you need to set the environment variable MAIXCDK_PATH to specify the path to MaixCDK, which can be added in ~/.bashrc or ~/.zshrc (depending on your shell): ```shell export MAIXCDK_PATH ~/maix/MaixCDK ``` Only after successfully setting the environment variable can MaixPy locate the MaixCDK source code. ## Build and pack to wheel ```shell cd ~/maix/MaixPy python setup.py bdist_wheel maixcam ``` `maixcam` Can be replaced with other board config, see [setup.py]([./configs](https://github.com/sipeed/MaixPy/blob/main/setup.py)) 's `platform_names` variable. After build success, you will find wheel file in `dist` directory, use `pip install U MaixPy****.whl` on your device to install or upgrade. > `python setup.py bdist_wheel maixcam skip build` will not execute build command and only pack wheel, so you can use `maixcdk menuconfig` and `maixcdk build` first to customize building. > Additionally, if you are debugging APIs and need to install frequently, using pip can be slow. You can compile and then copy the maix directory directly to the /usr/lib/python3.11/site packages directory on your device to overwrite the old files. ## Build manually ```shell maixcdk build ``` ## Run test after modify source code * First, build source code by ```shell maixcdk build ``` * If build for PC self(platform `linux`): Then execute `./run.sh your_test_file_name.py` to run python script. ```shell cd test ./run.sh examples/hello_maix.py ``` * If cross compile for board: * The fastest way is copy `maix` dir to device's `/usr/lib/python3.11/site packages/` directory, then run script on device. * Or pack wheel and install on device by `pip install U MaixPy****.whl`, then run script on device. ## Preview documentation locally Documentation in [docs](https://github.com/sipeed/MaixPy/tree/main/docs) directory, use `Markdown` format, you can use [teedoc](https://github.com/teedoc/teedoc) to generate web version documentation. And the API doc is generated when build MaixPy firmware, **if you don't build MaixPy, the API doc will be empty**. ```shell pip install teedoc U cd docs teedoc install i https://pypi.tuna.tsinghua.edu.cn/simple teedoc serve ``` Then visit `http://127.0.0.1:2333` to preview documentation on web browser. ## For developers who want to contribute See [MaixPy develop source code guide](./contribute.html) If you encounter any problems when use source code, please refer to [FAQ](./faq.html) first."},"/maixpy/doc/en/source_code/add_c_module.html":{"title":"Adding a C/C++ Module to MaixCAM MaixPy","content":" title: Adding a C/C++ Module to MaixCAM MaixPy ## Introduction Sometimes you need to execute a function efficiently, and Python's speed is insufficient. In such cases, you can implement the function using C/C++ or other compiled languages. ## General Function Wrapping If the function you want to wrap does not depend on other features of MaixPy, you can directly use the general methods for adding modules to Python using C/C++. You can search for methods like `ffi` or `ctype` on the internet. > PRs are welcome to add more methods. ## If Your Module Needs to Depend on Other MaixPy Basic APIs ### Method 1 Directly modify the MaixPy firmware and then compile it. Refer to [View MaixPy API Source Code](../basic/view_src_code.html). This method is the simplest and fastest. If the code is well packaged, it can be merged into the official repository (by submitting a PR). * Follow [Compiling MaixPy Source Code](./build.html) to get the `dist/***.whl` installation package. * Send the `.whl` package from the `dist` directory to the device, then run the code `import os; os.system(\"pip install /root/xxxxx.whl\")` (replace the path accordingly). * If installing the `.whl` package is too slow during debugging, you can use `maixcdk build` to compile and then use `scp r maix_xxx root@10.228.104.1:/usr/lib/python3.11/site packages` to directly copy it to the device system to overwrite the package. Adjust the package name and device IP as needed. * Once you have finished debugging and feel that the features you added are valuable, consider merging them into the official repository. You can learn how to do this by searching for keywords like \"github submit PR\" on search engines. Modifying the code: As described in [View MaixPy API Source Code](../basic/view_src_code.html), you can view and modify the source code, add C++ functions, and include comments. After compiling, you can call them in MaixPy. It's very simple. For example: ```cpp namespace maix::test { /** * My function, add two integers. * @param a arg a, int type * @param b arg b, int type * @return int type, a + b * @maixpy maix.test.add */ int add(int a, int b); } ``` Yes, simply write a C++ function. Note the `@maixpy` comment. During compilation, a Python function will be automatically generated. It's that simple! Then you can call the function with `maix.test.add(1, 2)`. ### Method 2 Create a MaixPy module project based on an engineering template. This method is suitable for adding a package without modifying the MaixPy source code and still using MaixPy (MaixCDK) APIs. The method is as follows: * First, [compile MaixPy source code](./build.html) to ensure the compilation environment is set up correctly. * Copy the [MaixPy/tools/maix_module](https://github.com/sipeed/MaixPy/tree/main/tools/maix_module) project template to a new directory. It can be in the same directory as `MaixPy`. For example, copy all files and directories to the `maix_xxx` directory. * In the `maix_xxx` directory, run `python init_files.py` in the terminal to initialize the project files. * Change the project name: Modify the `module_name.txt` file to the desired module name, starting with `maix_`. This makes it easier for others to find your project on [pypi.org](https://pypi.org) or [github.com](https://github.com). * Run `python setup.py bdist_wheel linux` in the project root directory to build for the computer. * After building, you can directly run `python c \"import maix_xxx; maix_xxx.basic.print('Li Hua')\"` in the project root directory to test your module functions. * Run `python setup.py bdist_wheel maixcam` to build the package for `MaixCAM`. Note that the code prompt file (pyi file) can only be generated when building for the `linux` platform. Therefore, before releasing, first build for the `linux` platform to generate the code prompt file, then execute this command to generate the package for the `MaixCAM` platform. * Send the `.whl` package from the `dist` directory to the device, then run `import os; os.system(\"pip install /root/xxxxx.whl\")` (replace the path accordingly). * If installing the `.whl` package is too slow during debugging, you can use `maixcdk build` to compile and then use `scp r maix_xxx root@10.228.104.1:/usr/lib/python3.11/site packages` to directly copy it to the device system to overwrite the package. Adjust the package name and device IP as needed. * Once you have debugged your code, consider open sourcing it on [github.com](https://github.com) and uploading it to [pypi.org](https://pypi.org). You can refer to the official documentation or search for tutorials on how to upload. Generally, you need to run `pip install twine` and then `twine upload dist/maix_xxx***.whl`. After completing this, feel free to share your achievements on [maixhub.com/share](https://maixhub.com/share)! Modifying the code: As described in [View MaixPy API Source Code](../basic/view_src_code.html), add source files in the `components/maix/include` and `components/maix/src` directories, add C++ functions, and include comments. After compiling, you can call them directly. It's very simple. For example: ```cpp namespace maix_xxx::test { /** * My function, add two integers. * @param a arg a, int type * @param b arg b, int type * @return int type, a + b * @maix_xxx maix_xxx.test.add */ int add(int a, int b); } ``` Yes, simply write a C++ function. Note the `@maix_xxx` comment. During compilation, a Python function will be automatically generated. It's that simple! Then you can call the function with `maix_xxx.test.add(1, 2)`."},"/maixpy/doc/en/source_code/contribute.html":{"title":"Contributing to MaixCAM MaixPy Documentation Modification and Code Contribution","content":" title: Contributing to MaixCAM MaixPy Documentation Modification and Code Contribution ## Contributing to MaixPy Documentation Modification * Click the \"Edit this page\" button in the top right corner of the documentation you want to modify to enter the GitHub source documentation page. * Make sure you are logged in to your GitHub account. * Click the pencil icon in the top right corner of the GitHub preview documentation page to modify the content. * GitHub will prompt you to fork a copy to your own repository. Click the \"Fork\" button. > This step forks the MaixPy source code repository to your own account, allowing you to freely modify it. * Modify the documentation content, then fill in the modification description at the bottom of the page, and click \"Commit changes\". * Then find the \"Pull requests\" button in your repository and click to create a new Pull request. * In the pop up page, fill in the modification description and click \"Submit Pull request\". Others and administrators can then see your modifications on the [Pull requests page](https://github.com/sipeed/MaixPy/pulls). * Wait for the administrator to review and approve, and your modifications will be merged into the MaixPy source code repository. * After the merge is successful, the documentation will be automatically updated to the [MaixPy official documentation](https://wiki.sipeed.com/maixpy). > Due to CDN caching, it may take some time to see the update. For urgent updates, you can contact the administrator for manual refreshing. > You can also visit [en.wiki.sipeed.com/maixpy](https://en.wiki.sipeed.com/maixpy) to view the GitHub Pages service version, which is updated in real time without caching. ## Contributing to MaixPy Code Contribution * Visit the MaixPy code repository address: [github.com/sipeed/MaixPy](https://github.com/sipeed/MaixPy) * Before modifying the code, it is best to create an [issue](https://github.com/sipeed/MaixPy/issues) first, describing the content you want to modify to let others know your ideas and plans, so that everyone can participate in the modification discussion and avoid duplication of effort. * Click the \"Fork\" button in the top right corner to fork a copy of the MaixPy code repository to your own account. * Then clone a copy of the code from your account to your local machine. * After modifying the code, commit it to your repository. * Then find the \"Pull requests\" button in your repository and click to create a new Pull request. * In the pop up page, fill in the modification description and click \"Submit Pull request\". Others and administrators can then see your modifications on the [Pull requests page](https://github.com/sipeed/MaixPy/pulls). * Wait for the administrator to review and approve, and your modifications will be merged into the MaixPy source code repository. > Note that most of the MaixPy code is automatically generated from [MaixCDK](https://github.com/sipeed/MaixCDK), so if you modify the C/C++ source code, you may need to modify this repository first."},"/maixpy/doc/en/source_code/faq.html":{"title":"MaixCAM MaixPy Source Code FAQ","content":"MaixCAM MaixPy Source Code FAQ ## subprocess.CalledProcessError: Command '('lsb_release', ' a')' returned non zero exit status 1. Edit `/usr/bin/lsb_release` as root, change the first line from `#!/usr/bin/python3` to `python3`. Then compile again and it should work. ## ImportError: arg(): could not convert default argument 'format: maix::image::Format' in method '<class 'maix._maix.camera.Camera'>.__init__' into a Python object (type not registered yet?) Pybind11 need you to register `image::Format` first, then you can use it in `camera::Camera`, to we must fist define `image::Format` in generated `build/maixpy_wrapper.cpp` source file. To achieve this, edit `components/maix/headers_priority.txt`, the depended on should be placed before the one use it. e.g. ``` maix_image.hpp maix_camera.hpp ``` ## /usr/bin/ld: /lib/libgdal.so.30: undefined reference to `std::condition_variable::wait(std::unique_lock<std::mutex>&)@GLIBCXX_3.4.30' collect2: error: ld returned 1 exit status This issue commonly arises when building for Linux and using a conda environment, due to some libraries in the conda environment having compilation parameter problems. The solution is to not use conda, or to individually locate the problematic library within conda and replace it with the system's version or simply delete it (the system will then locate the necessary library)."},"/maixpy/doc/en/source_code/maixcdk.html":{"title":"MaixCAM Switching to MaixCDK for C/C++ Application Development","content":" title: MaixCAM Switching to MaixCDK for C/C++ Application Development In addition to developing with MaixPy, there is also a corresponding C/C++ SDK available, called [MaixCDK](https://github.com/sipeed/MaixCDK). ## Introduction to MaixCDK MaixPy is built on top of MaixCDK, and most of MaixPy's APIs are automatically generated based on MaixCDK's APIs. Therefore, any functionality available in MaixPy is also included in MaixCDK. If you are more familiar with C/C++ programming or require higher performance, you can use MaixCDK for development. ## Using MaixCDK The MaixCDK code repository is located at [github.com/sipeed/MaixCDK](https://github.com/sipeed/MaixCDK), where you can find the MaixCDK code and documentation."},"/maixpy/doc/en/README_no_screen.html":{"title":"MaixCAM MaixPy Screenless Edition Quick Start","content":" title: MaixCAM MaixPy Screenless Edition Quick Start ## About This Document As mentioned in the [Quick Start Guide](./index.html), it is **strongly recommended** to purchase the version with a screen for development, as it provides a better development experience, including using the built in APP, accessing apps from the MaixHub App Store, and easier debugging (e.g., common settings can be completed directly by touching the screen interface, and images can be viewed in real time). However, if you are unable to purchase the version with a screen or require a screenless version for mass production, please refer to this document. ## Getting a MaixCAM Device * **MaixCAM**: Purchase it from the [Sipeed Taobao Store](https://item.taobao.com/item.htm?id 784724795837) or the [Sipeed Aliexpress Store](https://www.aliexpress.com/store/911876460). You can find more information about MaixCAM [here](https://wiki.sipeed.com/maixcam). ## Initial Setup ### Preparing the TF Image Card and Inserting it into the Device If your package includes a TF card, it already contains the factory image. If the TF card was not installed in the device during manufacturing, carefully open the case (be careful not to disconnect any cables inside) and insert the TF card. Additionally, since the factory firmware may be outdated, it is **essential** to update the system to the latest version by following the [Upgrade and Flash System](https://wiki.sipeed.com/maixpy/doc/zh/basic/os.html) instructions; otherwise, some applications and APIs may not function properly. If you did not purchase a TF card, you will need to flash the system onto your own TF card. Follow the [Upgrade and Flash System](./basic/os.html) guide, then install the card into the board. ### Powering On Use a `Type C` data cable to connect the `MaixCAM` device to provide power and wait for the device to boot. **Firstly**: Ensure that the USB cable is of good quality and that the USB port on your computer is reliable (power supply > 5V 500mA, normal interference resistance). The first boot may take about 20 seconds, after which your computer will detect one or two virtual network adapters (visible in your computer's network manager). If the virtual network adapter is not detected: * Ensure that you purchased the TF card package. If you have confirmed that the TF card is inserted into the device, try [updating to the latest system](./basic/os.html). * If you did not purchase the TF card package, you need to flash the latest system onto the TF card following the [Upgrade and Flash System](./basic/os.html) guide. * Check if the USB connection is loose and whether the USB cable is of good quality; you can try using a better quality cable. * Ensure that the USB port provides sufficient power. You can try another USB port or even another computer if possible. ## Preparing to Connect the Computer and Device To enable communication between your computer (PC) and the device (MaixCAM), they need to be on the same local area network. Two methods are provided; we will first use Method 1: * **Method 1**: Wired connection. The device connects to the computer via a USB cable, and it will be recognized as a virtual USB network adapter, placing it on the same local area network as the computer. If you encounter issues, refer to the [FAQ](./faq.html) for common problems. .. details::Method 2 involves driver installation on different computer systems: :open: true There are two default USB virtual network adapter drivers (NCM and RNDIS) to meet the needs of different systems: * **Windows**: All Windows systems will automatically install the RNDIS driver. Only Win11 will automatically install the NCM driver. **Either one that works is fine** (NCM is faster than RNDIS). * Open Task Manager > Performance, and you will see a virtual Ethernet connection with an IP, for example, `10.131.167.100` is the computer's IP, and the device's IP is the same except the last digit changed to `1`, i.e., `10.131.167.1`. If it's Win11, you will see two virtual network adapters; you can use any one of the IPs. * Additionally, you can open the `Device Manager` on your computer (search `Device Manager` in the search bar). If the RNDIS and NCM drivers are correctly installed, **either one that works is fine**: ![RNDIS ok](../../static/image/rndis_windows.jpg) ![NCM ok](../../static/image/windows_ncm_ok.png) * **Linux**: No extra setup is required. Just plug in the USB cable. Use `ifconfig` or `ip addr` to see `usb0` and `usb1` network adapters, and you can use either IP. **Note** that the IP, for example, `10.131.167.100`, is the computer's IP, and the device's IP is the same except the last digit changed to `1`, i.e., `10.131.167.1`. * **MacOS**: Check the `usb` network adapter in `System Settings` > `Network`. **Note** that the IP, for example, `10.131.167.100`, is the computer's IP, and the device's IP is the same except the last digit changed to `1`, i.e., `10.131.167.1`. * **Method 2**: Wireless connection. The device connects to the same router or WiFi hotspot that the computer is connected to (if you experience screen lag or high latency with WiFi, use a wired connection). There are two methods for connecting to a wireless hotspot: * Modify the `wifi.ssid` and `wifi.pass` files in the TF card's boot partition and reboot to connect. Modification methods: * If you are familiar with SSH, you can connect to the device via SSH (if wired connection is available) and modify the files in the `/boot` directory. * You can also enter upgrade mode as described in the previous section, after which a USB drive will appear on the computer. Modify the files in it, ensuring to safely eject the drive before rebooting. * You can also use a card reader, and a USB drive will appear on the computer. Modify the `wifi.ssid` and `wifi.pass` files in it, ensuring to safely eject the drive before rebooting. * If the wired connection is already available, you can follow the next step and use MaixVision to run code. Modify the `tools/wifi_connect.py` script with your SSID and PASSWORD, then run it. ## Preparing the Development Environment * First, ensure that the computer and device are on the same local area network. * Download and install [MaixVision](https://wiki.sipeed.com/maixvision). * Use a Type C cable to connect the device and computer, open MaixVision, and click the `Connect` button at the bottom left. The software will automatically search for the device. Wait a moment until the device appears, then click the device to connect. If **the device is not detected**, you can find solutions in the [FAQ](./faq.html). Here is a video tutorial on using MaixVision: <video style \"width:100%\" controls muted preload src \"/static/video/maixvision.mp4\"></video> ### Connecting to the Internet The first run requires a network connection to activate the device and install the runtime library. If you do not have a router, you can use your phone to create a hotspot. In MaixVision, modify the `tools/wifi_connect.py` script with your SSID and PASSWORD, then run it. For other WiFi connection methods, see the previous section. ### Upgrading the Runtime Library **This step is very important!!!** If this step is not completed, other applications and features may not function properly (e.g., crashing). * First, ensure that the WiFi connection from the previous step is completed and that you have an IP address with internet access. * Run the `tools/install_runtime.py` script from the MaixVision examples to install the latest runtime library. If `Request failed` or a similar error appears, please check if the network is connected and able to access the internet. If the problem persists, take a photo and contact customer service for assistance. ## Running Examples Click on the `Example Code` on the left side of MaixVision, select an example, and click the `Run` button at the bottom left to send the code to the device for execution. For example: * `hello_maix.py`, click the `Run` button, and you will see messages printed by the device in the MaixVision terminal, and an image will appear in the top right corner. * `camera_display.py`, this example opens the camera and displays the camera feed on the screen. ```python from maix import camera, display, app disp display.Display() # Create a display object and initialize the screen cam camera.Camera(640, 480) # Create a camera object, manually setting the resolution to 640x480, and initialize the camera while not app.need_exit(): # Keep looping until the program exits (can exit by pressing the device's function button or clicking the stop button in MaixVision) img cam.read() # Read the camera feed into the img variable, print(img) can be used to print img details disp.show (img) # Display img on the screen ``` * `yolov5.py` detects objects in the camera feed, draws bounding boxes around them, and displays them on the screen. It supports detecting 80 different objects. For more details, see [YOLOv5 Object Detection](./vision/yolov5.html). You can try other examples on your own. > If you experience image lag when using the camera examples, it may be due to poor network connection, low quality USB cable, or poor USB port quality on the host. Try changing the connection method or using a different cable, USB port, or computer. ## Installing Applications on the Device The above steps allow you to run code on the device. Once `MaixVision` is disconnected, the code will stop running. If you want the code to appear in the boot menu, you can package it as an application and install it on the device. Click the install application button at the bottom left of `MaixVision`, fill in the application information, and it will be installed on the device. You will then see the application on the device. You can also choose to package the application and share it on the [MaixHub App Store](https://maixhub.com/app). > The default examples do not include an explicit exit function. Press the device's function button to exit the application (for MaixCAM, it is the user button). If you want the program to start automatically at boot, you can modify and run the `tools/set_autostart.py` script. ## Next Steps If you like what you've seen so far, **please make sure to visit [GitHub](https://github.com/sipeed/MaixPy) and give the MaixPy open source project a star (you need to log in to GitHub first). Your star and support are our motivation to keep maintaining and adding new features!** You have now completed a basic usage and development process. Next, you can learn more about `MaixPy` syntax and features by following the directory on the left. If you encounter any issues with the `API`, you can find help in the [API Documentation](/api/). It's best to learn with a specific goal in mind, such as working on an interesting project. This will improve your learning experience. You can also share your projects and experiences on the [MaixHub Sharing Platform](https://maixhub.com/share) to earn cash rewards! ## Frequently Asked Questions (FAQ) If you encounter any issues, first check the [FAQ](./faq.html). If you can't find a solution, you can ask questions in the forum or group below, or submit a code issue on [MaixPy issue](https://github.com/sipeed/MaixPy/issues). ## Share and Communicate * **[MaixHub Project and Experience Sharing](https://maixhub.com/share)**: Share your projects and experiences to earn cash rewards. To receive official rewards, your content should meet the following criteria: * **Reproducibility**: A fairly complete project reproduction process. * **Showcase**: Projects without a detailed reproduction process but with an attractive presentation. * Bug Solution Experience: Share your process and specific solution to a difficult problem. * [MaixPy Official Forum](https://maixhub.com/discussion/maixpy) (for questions and discussions) * QQ Group: (It's recommended to post first before asking in the QQ group so others can quickly understand your problem and reproduction process) * MaixPy (v4) AI Vision Group: 862340358 * Telegram: [MaixPy](https://t.me/maixpy) * MaixPy Code Issues: [MaixPy issue](https://github.com/sipeed/MaixPy/issues) * For business cooperation or bulk purchases, please contact support@sipeed.com."},"/maixpy/doc/en/projects/line_tracking_robot.html":{"title":"MaixCAM MaixPy Line Tracking Robot (/Car)","content":" title: MaixCAM MaixPy Line Tracking Robot (/Car) update: date: 2024 05 09 author: lxowalle version: 1.0.0 content: Initial documentation Before reading this article, make sure you know how to develop with MaixCAM. For details, please read [Quick Start](../index.html). ## Introduction This article describes how to implement a line tracking robot using MaixPy. ## How to implement line tracking robot using MaixPy 1. Preparation of MaixCAM and trolley 2. Implementing the line tracking function 3. Implement the trolley control function ### Preparation of MaixCAM and trolley TODO ### Implementing the line tracking function You can quickly find straight lines using the `get_regression` of the `image` module, see [Line tracking](. /line_tracking.html). Code： ```python from maix import camera, display, image cam camera.Camera(320, 240) disp display.Display() # thresholds [[0, 80, 40, 80, 10, 80]] # red thresholds [[0, 80, 120, 10, 0, 30]] # green # thresholds [[0, 80, 30, 100, 120, 60]] # blue while 1: img cam.read() lines img.get_regression(thresholds, area_threshold 100) for a in lines: img.draw_line(a.x1(), a.y1(), a.x2(), a.y2(), image.COLOR_GREEN, 2) theta a.theta() rho a.rho() if theta > 90: theta 270 theta else: theta 90 theta img.draw_string(0, 0, \"theta: \" + str(theta) + \", rho: \" + str(rho), image.COLOR_BLUE) disp.show(img) ``` The above code implements the function of finding a straight line, note: Use `a.theta()` to get the angle of the line. Use `a.rho()` to get the distance between the line and the origin (the origin is in the upper left corner). After find the straight line with reference to the above code, you can use `a.theta()` and `a.rho()` to control the direction of the cart. ### Implement the trolley control function TODO"},"/maixpy/doc/en/projects/index.html":{"title":"Practical Projects with MaixCAM MaixPy, Introduction and Collection","content":" title: Practical Projects with MaixCAM MaixPy, Introduction and Collection ## Introduction Here we provide some common practical project examples for community members to refer to and replicate for use. This also helps to inspire everyone to create more and better applications and projects. There are several ways to find projects implemented with MaixPy: ## MaixPy Official Documentation You can find practical projects in the documentation on the left, such as \"Line Following Car.\" If you have a good project or a recommended project, you can also contribute by adding it to the documentation. ## MaixHub Project Sharing Square Projects can be found in the [MaixHub Project Sharing](https://maixhub.com/share?type project) section. High quality shares will also be linked to the MaixPy official documentation. You can also share your project making methods, which will receive official rewards (guaranteed) and cash tips from community members (usually, high quality projects that meet urgent needs are more likely to be tipped). Recommend Projects: * maixcam deploy yolov5s model: https://maixhub.com/share/23 ## MaixHub App Sharing In addition to project sharing, you can also find directly runnable applications at the [MaixHub App Store](https://maixhub.com/app), some of which might be written in MaixPy. If the author has provided the source code or written detailed tutorials, these can also be referred to. Recommend Projects: * Simple HTTP Streaming Server: https://maixhub.com/app/19 * Desktop Computer Performance Monitor: https://maixhub.com/app/13 * Safety Helmet Detection Model Application: https://maixhub.com/app/10"},"/maixpy/doc/en/projects/face_tracking.html":{"title":"MaixCAM MaixPy Face Tracking 2 axis servo gimbal","content":" title: MaixCAM MaixPy Face Tracking 2 axis servo gimbal update: date: 2024 06 11 author: iawak9lkm version: 1.0.0 content: Initial documentation Before reading this article, make sure you know how to develop with MaixCAM. For details, please read [Quick Start](../index.html). [Source Code](https://github.com/sipeed/MaixPy/blob/main/projects/app_face_tracking) [Download APP](https://maixhub.com/app/31) ## Description Face recognition and tracking is accomplished using a gimbal consisting of two servos and MaixCAM. ![](../../assets/face_tracking1.jpg) ![](../../assets/face_tracking2.jpg) ## Usage of this example program * Assemble your Gimbal and MaixCAM. * Modify the parameters in `main.py`. Modify the MaixCAM pins used for each servo. The specified pins must have PWM capability.The `servos.Servos` constructor then configures the pin for PWM functionality. ```python ROLL_PWM_PIN_NAME \"A17\" PITCH_PWM_PIN_NAME \"A16\" ``` Modify the initial positions of the two servos. ```python init_pitch 80 # init position, value: [0, 100], means minimum angle to maxmum angle of servo init_roll 50 # 50 means middle ``` You need to modify the min max PWM duty cycle for the active range of each of the two servos. NOTE: Certain Gimbal configurations may have unintended consequences when servos exceed their physically limited maximum range of motion. Ensure that there is no obstruction within the range of motion of the servos corresponding to the following setpoints. ```python PITCH_DUTY_MIN 3.5 # The minimum duty cycle corresponding to the range of motion of the y axis servo. PITCH_DUTY_MAX 9.5 # Maximum duty cycle corresponding to the y axis servo motion range. ROLL_DUTY_MIN 2.5 # Minimum duty cycle for x axis servos. ROLL_DUTY_MAX 12.5 # Maxmum duty cycle for x axis servos. ``` You need to select the direction of motion of the servos. ```python pitch_reverse False # reverse out value direction roll_reverse True # reverse out value direction ``` * Just execute the code at the end. If you installed the application from MaixHub, click face_tracking in the launcher to execute the program. If you got the source code from Github, you can import the project folder in [MaixVision](https://wiki.sipeed.com/maixvision) and execute the whole project. Please refer to [MaixVision Description](https://wiki.sipeed.com/maixpy/doc/zh/basic/maixvision.html) for more information about MaixVision. Of course, you can also copy the whole project folder to our MaixCAM in your favorite way and execute it with python. * If you want to exit the program, just press the button in the upper left corner. ![](../../../../projects/app_face_tracking/assets/exit.jpg) ### FAQs * The face tracking is not ideal. Different Gimbal use different PID parameters, you can adjust the PID value to make the effect better. ```python pitch_pid [0.3, 0.0001, 0.0018, 0] # [P I D I_max] roll_pid [0.3, 0.0001, 0.0018, 0] # [P I D I_max] ``` * After completing the tracking, the gimbal jerks small left and right for a period of time against a motionless face. You can usually make this effect as small as possible by adjusting the PID; however, there is no way to avoid the jitter caused by the physical structure of the gimbal. You can try to adjust the deadband to minimize the jitter. ```python target_ignore_limit 0.08 # when target error < target_err_range*target_ignore_limit , set target error to 0 ``` * The display shows or the terminal prints `PIN: XXX does not exist`. This is because the pin does not exist in the pinout of the MaixCAM board. Please select a pin with PWM function on MaixCAM. * The display shows or the terminal prints `Pin XXX doesn't have PWM function`. This is because the pin does not have a PWM function, you need to select a pin with a PWM function. ## How to track other objects * In `main.py` there exists a class `Target` which is used to customize the target to be tracked. * In `__init__`, initialize the objects you need to use, such as the camera. * In `__get_target()`, you need to calculate the center point of the tracked object, and if the tracked object does not exist in the frame, return 1, 1 to make sure that the program does not do anything for a while if the target is not found. You also need to call `self.__exit_listener(img)` and `self.disp.show(img)` before returning to the point to make sure that the program can interact with you properly."},"/maixpy/doc/en/vision/apriltag.html":{"title":"MaixCAM MaixPy Apriltag Recognition","content":" title: MaixCAM MaixPy Apriltag Recognition update: date: 2024 04 03 author: lxowalle version: 1.0.0 content: Initial documentation Before reading this article, make sure you are familiar with how to develop with MaixCAM. For more details, please read [Quick Start](../index.html). ## Introduction This article introduces how to use MaixPy to recognize Apriltag labels. ## Using MaixPy to Recognize Apriltag Labels MaixPy's `maix.image.Image` provides the `find_apriltags` method, which can be used to recognize Apriltag labels. ### How to Recognize Apriltag Labels A simple example of recognizing Apriltag labels and drawing bounding boxes: ```python from maix import image, camera, display cam camera.Camera() disp display.Display() families image.ApriltagFamilies.TAG36H11 x_scale cam.width() / 160 y_scale cam.height() / 120 while 1: img cam.read() new_img img.resize(160, 120) apriltags new_img.find_apriltags(families families) for a in apriltags: corners a.corners() for i in range(4): corners[i][0] int(corners[i][0] * x_scale) corners[i][1] int(corners[i][1] * y_scale) x int(a.x() * x_scale) y int(a.y() * y_scale) w int(a.w() * x_scale) h int(a.h() * y_scale) for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_RED) img.draw_string(x + w, y, \"id: \" + str(a.id()), image.COLOR_RED) img.draw_string(x + w, y + 15, \"family: \" + str(a.family()), image.COLOR_RED) disp.show(img) ``` Steps: 1. Import the image, camera, and display modules ```python from maix import image, camera, display ``` 2. Initialize the camera and display ```python cam camera.Camera() disp display.Display() ``` 3. Get the image from the camera and display it ```python while 1: img cam.read() disp.show(img) ``` 4. Call the `find_apriltags` method to recognize Apriltag labels in the camera image ```python new_img img.resize(160, 120) apriltags new_img.find_apriltags(families families) ``` `img` is the camera image obtained through `cam.read()` `img.resize(160, 120)` is used to scale down the image to a smaller size, allowing the algorithm to compute faster with a smaller image `new_img.find_apriltags(families families)` is used to find Apriltag labels, and the query results are saved in `apriltags` for further processing. The `families` parameter is used to select the Apriltag family, defaulting to `image.ApriltagFamilies.TAG36H11` 5. Process the recognized label results and display them on the screen ```python for a in apriltags: # Get position information (and map coordinates to the original image) x int(a.x() * x_scale) y int(a.y() * y_scale) w int(a.w() * x_scale) corners a.corners() for i in range(4): corners[i][0] int(corners[i][0] * x_scale) corners[i][1] int(corners[i][1] * y_scale) # Display for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_RED) img.draw_string(x + w, y, \"id: \" + str(a.id()), image.COLOR_RED) img.draw_string(x + w, y + 15, \"family: \" + str(a.family()), image.COLOR_RED) img.draw_string(x + w, y + 30, \"rotation : \" + str(180 * a.rotation() // 3.1415), image.COLOR_RED) ``` Iterate through the members of `apriltags`, which is the result of scanning Apriltag labels through `img.find_apriltags()`. If no labels are found, the members of `apriltags` will be empty. `x_scale` and `y_scale` are used to map coordinates. Since `new_img` is a scaled down image, the coordinates of the Apriltag need to be mapped to be drawn correctly on the original image `img`. `a.corners()` is used to get the coordinates of the four vertices of the detected label, and `img.draw_line()` uses these four vertex coordinates to draw the shape of the label. `img.draw_string` is used to display the label content, where `a.x()` and `a.y()` are used to get the x and y coordinates of the top left corner of the label, `a.id()` is used to get the label ID, `a.family()` is used to get the label family type, and `a.rotation()` is used to get the rotation angle of the label. ### Common Parameter Explanations Here are explanations for common parameters. If you can't find parameters to implement your application, you may need to consider using other algorithms or extending the required functionality based on the current algorithm's results. Parameter Description Example roi Set the rectangular region for the algorithm to compute. roi [x, y, w, h], where x and y represent the coordinates of the top left corner of the rectangle, and w and h represent the width and height of the rectangle. The default is the entire image. Compute the region with coordinates (50,50) and a width and height of 100:<br />```img.find_apriltags(roi [50, 50, 100, 100])``` families Apriltag label family type Scan for labels from the TAG36H11 family:<br />```img.find_apriltags(families image.ApriltagFamilies.TAG36H11)``` This article introduces common methods. For more API information, please refer to the [image](../../../api/maix/image.html) section of the API documentation."},"/maixpy/doc/en/vision/maixhub_train.html":{"title":"Using MaixHub to Train AI Models for MaixCAM MaixPy","content":" title: Using MaixHub to Train AI Models for MaixCAM MaixPy update: date: 2024 04 03 author: neucrack version: 1.0.0 content: Initial document ## Introduction MaixHub offers the functionality to train AI models online, directly within a browser. This eliminates the need for expensive hardware, complex development environments, or coding skills, making it highly suitable for beginners as well as experts who prefer not to delve into code. ## Basic Steps to Train a Model Using MaixHub ### Identify the Data and Model Types To train an AI model, you first need to determine the type of data and model. As of April 2024, MaixHub provides models for image data including `Object Classification Models` and `Object Detection Models`. Object classification models are simpler than object detection models, as the latter require marking the position of objects within images, which can be more cumbersome. Object classification merely requires identifying what is in the image without needing coordinates, making it simpler and recommended for beginners. ### Collect Data As discussed in AI basics, training a model requires a dataset for the AI to learn from. For image training, you need to create a dataset and upload images to it. Ensure the device is connected to the internet (WiFi). Open the MaixHub app on your device and choose to collect data to take photos and upload them directly to MaixHub. You need to create a dataset on MaixHub first, then click on device upload data, which will display a QR code. Scan this QR code with your device to connect to MaixHub. It's important to distinguish between training and validation datasets. To ensure the performance during actual operation matches the training results, the validation dataset must be of the same image quality as those taken during actual operation. It's also advisable to use images taken by the device for the training set. If using internet images, restrict them to the training set only, as the closer the dataset is to actual operational conditions, the better. ### Annotate Data For classification models, images are annotated during upload by selecting the appropriate category for each image. For object detection models, after uploading, you need to manually annotate each image by marking the coordinates, size, and category of the objects to be recognized. This annotation process can also be done offline on your own computer using software like labelimg, then imported into MaixHub using the dataset import feature. Utilize shortcuts during annotation to speed up the process. MaixHub will also add more annotation aids and automatic annotation tools in the future (there is already an automatic annotation tool available for videos that you can try). ### Train the Model Select training parameters, choose the corresponding device platform, select maixcam, and wait in the training queue. You can monitor the training progress in real time and wait for it to complete. ### Deploy the Model Once training is complete, you can use the deploy function in the MaixHub app on your device to scan a code and deploy. The device will automatically download and run the model, storing it locally for future use. If you find the recognition results satisfactory, you can share the model to the model library with a single click for others to use. ## How to Use Please visit [MaixHub](https://maixhub.com) to register an account, then log in. There are video tutorials on the homepage for learning. Note that if the tutorial uses the M2dock development board, the process is similar for MaixCAM, although the MaixHub application on the device might differ slightly. The overall process is the same, so please apply the knowledge flexibly."},"/maixpy/doc/en/vision/face_recognition.html":{"title":"MaixCAM MaixPy Face Recognition","content":" title: MaixCAM MaixPy Face Recognition ## Introduction to Face Recognition ![face_recognize](../../assets/face_recognize.jpg) Face recognition involves identifying the location of faces in the current view and who they are. Thus, in addition to detecting faces, face recognition typically involves a database to store known and unknown individuals. ## Recognition Principles * Use AI models to detect faces, obtaining coordinates and features of facial components. * Use the coordinates of these features for affine transformation to align the face in the image to a standard face orientation, facilitating the extraction of facial features by the model. * Employ a feature extraction model to derive facial feature values. * Compare these features with those stored in the database (by calculating the cosine distance between the saved and the current facial features, identifying the face in the database with the smallest distance; if it's below a predefined threshold, it is recognized as the person in the database). ## Using MaixPy MaixPy's `maix.nn` module provides a face recognition API, ready to use with built in models. Additional models can also be downloaded from the [MaixHub model repository](https://maixhub.com/model/zoo) (select the appropriate hardware platform, such as maixcam). Recognition: ```python from maix import nn, camera, display, image import os import math recognizer nn.FaceRecognizer(detect_model \"/root/models/yolov8n_face.mud\", feature_model \"/root/models/insghtface_webface_r50.mud\", dual_buff True) # recognizer nn.FaceRecognizer(detect_model \"/root/models/retinaface.mud\", feature_model \"/root/models/face_feature.mud\", dual_buff True) if os.path.exists(\"/root/faces.bin\"): recognizer.load_faces(\"/root/faces.bin\") cam camera.Camera(recognizer.input_width(), recognizer.input_height(), recognizer.input_format()) dis display.Display() while 1: img cam.read() faces recognizer.recognize(img, 0.5, 0.45, 0.85) for obj in faces: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) radius math.ceil(obj.w / 10) img.draw_keypoints(obj.points, image.COLOR_RED, size radius if radius < 5 else 4) msg f'{recognizer.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) dis.show(img) ``` When you first run this code, it can detect faces but will not recognize them. We need to enter a mode to learn faces. > Here `recognizer.labels[0]` is by default `unknown`, and every new face added will automatically append to `labels`. For example, you can learn faces when a user presses a button: ```python faces recognizer.recognize(img, 0.5, 0.45, 0.85, True) for face in faces: print(face) # This accounts for the scenario where multiple faces are present in one scene; obj.class_id of 0 means the face is not registered # Write your own logic here # For instance, based on face’s class_id and coordinates, you can decide whether to add it to the database and facilitate user interaction, like pressing a button to register recognizer.add_face(face, label) # label is the name you assign to the face recognizer.save_faces(\"/root/faces.bin\") ``` Here, `0.5` is the threshold for face detection, where a higher value indicates stricter detection. `0.45` is the `IOU` threshold, used to filter overlapping face results. `0.85` is the threshold for face comparison, indicating similarity with stored faces in the database. If a face comparison score exceeds this threshold, it is considered a match. A higher threshold improves filtering accuracy, while a lower threshold increases the risk of misidentification and can be adjusted according to practical needs. The detection model here supports three types: `yolov8n_face`, `retinaface`, and `face_detector`, each differing slightly in speed and accuracy, allowing for selection based on specific requirements. ## Complete Example A complete example is provided for recording unknown faces and recognizing faces with a button press. This can be found in the [MaixPy example directory](https://github.com/sipeed/MaixPy/tree/main/examples) under `nn_face_recognize.py`. ## dual_buff Dual Buffer Acceleration You may have noticed that the model initialization uses `dual_buff` (which defaults to `True`). Enabling the `dual_buff` parameter can improve running efficiency and increase the frame rate. For detailed principles and usage notes, see [dual_buff Introduction](./dual_buff.html). ## Replacing Other Default Recognition Models The recognition model (for distinguishing different individuals) uses `mobilenetv2` and the [insight face resnet50](https://maixhub.com/model/zoo/462) model. If these do not meet accuracy requirements, other models can be substituted. You may need to train a new model or find a pre trained model compatible with MaixCAM, such as other models from [insightface](https://github.com/deepinsight/insightface). For conversion instructions, refer to the [MaixCAM model conversion documentation](../ai_model_converter/maixcam.html), and follow existing `.mud` files as examples."},"/maixpy/doc/en/basic/maixvision.html":{"title":"MaixVision -- MaixCAM MaixPy Programming IDE + Graphical Block Programming","content":" title: MaixVision MaixCAM MaixPy Programming IDE + Graphical Block Programming ## Introduction [MaixVision](https://wiki.sipeed.com/maixvision) is a development tool specifically designed for the Maix ecosystem, supporting MaixPy programming and graphical block programming. It allows for online operation and debugging, real time image preview, and synchronizing images from device displays, which is convenient for debugging and development. It also supports packaging and installing applications on devices, allowing users to easily generate and install applications with one click. In addition, it integrates several handy tools for development, such as file management, threshold editor, QR code generator, and more. ## Download Visit the [MaixVision homepage](https://wiki.sipeed.com/maixvision) to download. ## Using MaixPy Programming and Online Running Follow the steps in [Quick Start](../index.html) to connect your device, and you can easily use MaixPy programming and run it online. ## Real time Image Preview MaixPy provides a `display` module that can show images on the screen. Also, when the `show` method of the `display` module is called, it sends the image to be displayed on MaixVision, for example: ```python from maix import display, camera cam camera.Camera(640, 480) disp display.Display() while 1: disp.show(cam.read()) ``` Here we use the camera to capture an image, then display it on the screen using the `disp.show()` method, and also send it to MaixVision for display. When we click the 'pause' button in the top right corner, it will stop sending images to MaixVision. ## Code Auto Completion Code suggestions depend on local Python packages installed on your computer. To enable code suggestions, you need to install Python on your computer and the required Python packages. * To install Python, visit the [Python official website](https://python.org/). * To install the required packages, for MaixPy, for instance, you need to install the MaixPy package on your computer using `pip install MaixPy`. If `MaixPy` gets updated, you should update it on both your computer and device. On your computer, manually execute `pip install MaixPy U` in the terminal. For device updates, update directly in the `Settings` application. > Users in China can use a local mirror `pip install i https://pypi.tuna.tsinghua.edu.cn/simple MaixPy`. * Restart MaixVision to see the code suggestions. > If suggestions still do not appear, you can manually set the path to the Python executable in settings and restart. >! Note that installing Python packages on your computer is just for code suggestions. The actual code runs on the device (development board), and the device must also have the corresponding packages to run properly. > Additionally, while you have the MaixPy package installed on your computer, due to our limited resources, we cannot guarantee that you can directly use the Maix package in your computer's Python. Please run it on supported devices. ## Calculating the Image Histogram In the previous step, we could see the image in real time in MaixVision. By selecting an area with the mouse, we can view the histogram for that area at the bottom of the screen, displaying different color channels. This feature is helpful when finding suitable parameters for some image processing algorithms. ## Distinguishing Between `Device File System` and `Computer File System` Here we have an important concept to grasp: **distinguish between the `Device File System` and the `Computer File System`**. * **Computer File System**: Operates on the computer. Opening a file or project in MaixVision accesses files on the computer, and saving is automatically done to the computer's file system. * **Device File System**: The program sends the code to the device for execution, so the files used in the code are read from the device's file system. A common issue is when students save a file on the computer, such as `D:\\data\\a.jpg`, and then use this file on the device with `img image.load(\"D:\\data\\a.jpg\")`. Naturally, the file cannot be found because the device does not have `D:\\data\\a.jpg`. For specifics on how to send files from the computer to the device, refer to the following section. ## Transferring Files to the Device First, connect to the device, then click the button to browse the device file system, as shown below. Then you can upload files to the device or download files to the computer. ![maixvision_browser2](../../assets/maixvision_browser2.jpg) ![maixvision_browser](../../assets/maixvision_browser.jpg) .. details:: Alternatively, other tools can be used, click to expand First, know the device's IP address or name, which MaixVision can find, or see in the device's `Settings >System Information`, such as `maixcam xxxx.local` or `192.168.0.123`. The username and password are `root`, using the `SFTP` protocol for file transfer, and the port number is `22`. There are many useful tools available for different systems: ### Windows Use [WinSCP](https://winscp.net/eng/index.php) or [FileZilla](https://filezilla project.org/) to connect to the device and transfer files, choosing the `SFTP` protocol and entering the device and account information to connect. Specific instructions can be searched online. ### Linux In the terminal, use the `scp` command to transfer files to the device, such as: ```bash scp /path/to/your/file.py root@maixcam xxxx.local:/root ``` ### Mac * **Method 1**: In the terminal, use the `scp` command to transfer files to the device, such as: ```bash scp /path/to/your/file.py root@maixcam xxxx.local:/root ``` * **Method 2**: Use [FileZilla](https://filezilla project.org/) or other tools to connect to the device and transfer files, choosing the `SFTP` protocol and entering the device and account information to connect. ## Using Graphical Block Programming Under development, please stay tuned."},"/maixpy/doc/en/basic/view_src_code.html":{"title":"MaixCAM MaixPy How to Find the Source Code Corresponding to MaixPy API","content":" title: MaixCAM MaixPy How to Find the Source Code Corresponding to MaixPy API ## Introduction MaixPy is implemented based on Python, with some functions written in Python and most of the underlying code written in C/C++. This ensures efficient performance. If you have questions while using a function, you can consult this document and the API documentation. If your doubts are still unresolved, you can find the underlying implementation source code using the method described in this article. **You are also welcome to contribute to the documentation or code, and become a MaixPy developer!** ## Check the Documentation First Always check the documentation first: [https://wiki.sipeed.com/maixpy/](https://wiki.sipeed.com/maixpy/), then check the API documentation: [https://wiki.sipeed.com/maixpy/api/index.html](https://wiki.sipeed.com/maixpy/api/index.html). The API documentation is only available in English because it is generated from the comments in the code, which are all in English. If you can't understand English, you can use a translation tool. ## How to Find the Source Code Corresponding to the API There are two open source repositories: [MaixPy](https://github.com/sipeed/MaixPy) and [MaixCDK](https://github.com/sipeed/MaixCDK). MaixPy is the project repository containing part of the MaixPy source code, all documents, and examples; MaixCDK contains most of the underlying C/C++ implementations of MaixPy APIs. You can download these two repositories or view them directly on the web. **Don't forget to give them a star so more people can see it!** ### Finding C/C++ Written APIs Assume we want to find the `maix.image.Image.find_blobs` function as an example. First, let's try to find it manually: * Since this is a vision related API, we look in the `components/vision/include` directory of [MaixCDK](https://github.com/sipeed/MaixCDK) and see a `maix_image.hpp` header file, where we might find it. * Searching for `find_blobs` in `maix_image.hpp`, we immediately find the function declaration: ```c++ std::vector<image::Blob> find_blobs(std::vector<std::vector<int>> thresholds std::vector<std::vector<int>>(), bool invert false, std::vector<int> roi std::vector<int>(), int x_stride 2, int y_stride 1, int area_threshold 10, int pixels_threshold 10, bool merge false, int margin 0, int x_hist_bins_max 0, int y_hist_bins_max 0); ``` * We also notice that there are comments before the function declaration, from which the API documentation is automatically generated. If you compare the API documentation with this comment, you will find them identical. Modifying this comment and recompiling will generate updated API documentation. * This is just the function declaration. We find that there is no such function in `components/vision/src/maix_image.cpp`. However, we see `components/vision/src/maix_image_find_blobs.cpp`, indicating that the function is written in a separate `cpp` file. Here, we can see the function's source code. ### Finding APIs Written with Pybind11 If you can't find it in MaixCDK, look in [MaixPy/components](https://github.com/sipeed/MaixPy/tree/main/components). > In the above code, you'll notice that the first parameter we use in `find_blobs` is of type `list`, i.e., `[[...]]`, while the C/C++ definition is `std::vector<std::vector<int>>`. This is because we use `pybind11` to automatically convert the `std::vector` type to `list` type. For some types like `numpy`'s `array`, which are inconvenient to define in MaixCDK, we use the `pybind11` definitions in [MaixPy/components](https://github.com/sipeed/MaixPy/tree/main/components). For example, the `maix.image.image2cv` method uses `pybind11` related code here. ## How to Modify the Code After finding the code, modify it directly and compile the firmware following the [build documentation](../source_code/build.html). ## How to Add Code Copy other APIs, write a function, and add complete comments. Include an extra `@maixpy maix.xxx.xxx` tag in the comments, where `xxx` is the module and API name you want to add. Then compile the firmware. Refer to [MaixCDK/components/basic/includemaix_api_example.hpp](https://github.com/sipeed/MaixCDK/blob/master/components/basic/include/maix_api_example.hpp). API parameters and return values automatically convert from basic `C++` types to Python types, making it very simple. See the [pybind11 automatic type conversion list](https://pybind11.readthedocs.io/en/stable/advanced/cast/overview.html#conversion table) for details. For example, to add `maix.my_module.my_func`, create a header file in the appropriate place in MaixCDK (preferably following the current folder classification) and add the code: ```cpp namespace maix::my_module { /** * My function, add two integers. * @param a arg a, int type * @param b arg b, int type * @return int type, will return a + b * @maixpy maix.my_module.my_func */ int my_func(int a, int b); } ``` Then add a `cpp` file: ```cpp int my_func(int a, int b) { return a + b; } ``` Compile MaixPy to generate the `whl` file and install it on the device to use the `maix.my_module.my_func` function. ## How to Contribute Code If you find any unfinished APIs or bugs in MaixPy, feel free to submit a PR (Pull Request) to the MaixPy repository. For detailed submission methods, see [Contributing Documentation and Code](../source_code/contribute.html)."},"/maixpy/doc/en/basic/python.html":{"title":"Basic Knowledge of Python","content":" title: Basic Knowledge of Python The tutorial documentation of MaixPy does not delve into specific Python syntax tutorials because there are already too many excellent Python tutorials available. Here, we only introduce what needs to be learned, provide guidance on directions and paths. ## Introduction to Python Python is an interpreted, object oriented, dynamically typed high level programming language. * Interpreted: It does not require compilation, runs directly. The advantage is rapid development, while a minor drawback is the slower execution speed due to code interpretation on each run. However, most often, the bottleneck lies in the developer's code rather than the language itself. * Object oriented: It supports object oriented programming, allowing the definition of classes and objects. Compared to procedural languages, it is easier to organize code. For more details, please search independently. * Dynamically typed: Variables do not need to declare types, can be assigned directly, and the type will be automatically determined based on the assignment. This reduces code volume, but can also lead to type errors, requiring the developer's attention. In conclusion, for developers unfamiliar with Python, it is very easy to get started as Python offers plenty of ready to use libraries, a large developer community, short application development cycles, making it highly worthwhile to learn! ## Python Environment Setup You can install Python on your computer according to the Python tutorial you are following for learning. Alternatively, you can connect to a device via MaixVision on MaixVision and then run the program on the development board. ## What Python Basics are Needed to Use MaixPy? * Basic concepts of Python. * Basic concepts of object oriented programming. * Basic syntax of Python, including: * Tab indentation alignment syntax. * Variables, functions, classes, objects, comments, etc. * Control statements such as if, for, while, etc. * Modules and importing modules. * Basic data types such as int, float, str, list, dict, tuple, etc. * Difference between bytes and str, and conversion. * Exception handling, try except. * Common built in functions like print, open, len, range, etc. * Common built in modules like os, sys, time, random, math, etc. Mastering the above foundational knowledge will enable you to smoothly program with MaixPy. With the help of subsequent tutorials and examples, if unsure, you can refer to search engines, official documentation, or ask ChatGPT to successfully complete your development tasks. ## For Developers Experienced in Another Object Oriented Programming Language If you are already proficient in an object oriented language like C++/Java/C#, you simply need to quickly review Python syntax before starting to use it. You can refer to resources like [Runoob Tutorial](https://www.runoob.com/python3/python3 tutorial.html) or the [Python Official Tutorial](https://docs.python.org/3/tutorial/index.html). Alternatively, you can explore individual developers' blogs, such as [Wow! It's Python](https://neucrack.com/p/59). ## For Developers with C Language Experience but No Object Oriented Programming Experience If you only know C and lack understanding of object oriented concepts, you can start by learning about object oriented programming concepts before diving into Python. It's relatively quick and you can search for video tutorials for entry level guidance. After following introductory video tutorials, you can then refer to documentation tutorials such as [Runoob Tutorial](https://www.runoob.com/python3/python3 tutorial.html) or the [Python Official Tutorial](https://docs.python.org/3/tutorial/index.html) to get started! Once you have acquired the basic knowledge, you can start using MaixPy for programming based on the documentation and examples. ## For Programming Beginners If you have never dealt with programming before, you will need to start learning Python from scratch. Python is also quite suitable as an introductory language. You can search for video tutorials for specific guidance. After mastering the basic syntax, you will be able to use MaixPy for programming by following examples provided."},"/maixpy/doc/en/audio/recognize.html":{"title":"MaixCAM MaixPy Real-time voice recognition","content":" title: MaixCAM MaixPy Real time voice recognition update: date: 2024 10 08 author: 916BGAI version: 1.0.0 content: Initial document ## Introduction `MaixCAM` has ported the `Maix Speech` offline speech library, enabling continuous Chinese numeral recognition, keyword recognition, and large vocabulary speech recognition capabilities. It supports audio recognition in `PCM` and `WAV` formats, and can accept input recognition via the onboard microphone. ## Maix Speech [`Maix Speech`](https://github.com/sipeed/Maix Speech) is an offline speech library specifically designed for embedded environments. It features deep optimization of speech recognition algorithms, achieving a significant lead in memory usage while maintaining excellent WER. For more details on the principles, please refer to the open source project. ## Continuous Large Vocabulary Speech Recognition ```python from maix import app, nn speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") def callback(data: tuple[str, str], len: int): print(data) lmS_path \"/root/models/lmS/\" speech.lvcsr(lmS_path + \"lg_6m.sfst\", lmS_path + \"lg_6m.sym\", \\ lmS_path + \"phones.bin\", lmS_path + \"words_utf.bin\", \\ callback) while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") speech.deinit() break ``` ### Usage 1. Import the `app` and `nn` modules ```python from maix import app, nn ``` 2. Load the acoustic model ```python speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") ``` You can also load the `am_7332` acoustic model; larger models provide higher accuracy but consume more resources. 3. Choose the corresponding audio device ```python speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") ``` This uses the onboard microphone and supports both `WAV` and `PCM` audio as input devices. ```python speech.init(nn.SpeechDevice.DEVICE_WAV, \"path/audio.wav\") # Using WAV audio input ``` ```python speech.init(nn.SpeechDevice.DEVICE_PCM, \"path/audio.pcm\") # Using PCM audio input ``` Note that `WAV` must be `16KHz` sample rate with `S16_LE` storage format. You can use the `arecord` tool for conversion. ```shell arecord d 5 r 16000 c 1 f S16_LE audio.wav ``` When recognizing `PCM/WAV` , if you want to reset the data source, such as for the next WAV file recognition, you can use the `speech.devive` method, which will automatically clear the cache: ```python speech.devive(nn.SpeechDevice.DEVICE_WAV, \"path/next.wav\") ``` 4. Set up the decoder ```python def callback(data: tuple[str, str], len: int): print(data) lmS_path \"/root/models/lmS/\" speech.lvcsr(lmS_path + \"lg_6m.sfst\", lmS_path + \"lg_6m.sym\", \\ lmS_path + \"phones.bin\", lmS_path + \"words_utf.bin\", \\ callback) ``` Users can register several decoders (or none), which decode the results from the acoustic model and execute the corresponding user callback. Here, a `lvcsr` decoder is registered to output continuous speech recognition results (for fewer than 1024 Chinese characters). For other decoder usages, please refer to the sections on continuous Chinese numeral recognition and keyword recognition. When setting up the `lvcsr` decoder, you need to specify the paths for the `sfst` file, the `sym` file (output symbol table), the path for `phones.bin` (phonetic table), and the path for `words.bin` (dictionary). Lastly, a callback function must be set to handle the decoded data. After registering the decoder, use the `speech.deinit()` method to clear the initialization. 5. Recognition ```python while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") speech.deinit() break ``` Use the `speech.run` method to run speech recognition. The parameter specifies the number of frames to run each time, returning the actual number of frames processed. Users can choose to run 1 frame each time and then perform other processing, or run continuously in a single thread, stopping it with an external thread. ### Recognition Results If the above program runs successfully, speaking into the onboard microphone will yield real time speech recognition results, such as: ```shell ### SIL to clear decoder! ('今天天气 怎么样 ', 'jin1 tian1 tian1 qi4 zen3 me yang4 ') ```"},"/maixpy/doc/en/audio/record.html":{"title":"MaixCAM MaixPy Audio Record","content":" title: MaixCAM MaixPy Audio Record update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: Initial document ## Introduction This document provides the usage of audio recording and supports recording audio in `PCM` and `WAV` formats. The `MaixCAM` has a microphone on board, so you can use the recording function directly. ### How to use #### Getting `PCM` data If you don't pass `path` when constructing a `Recorder` object, it will only record audio and not save it to a file, but you can save it to a file manually. ```python from maix import audio, time, app r audio.Recorder() r.volume(12) print(\"sample_rate:{} format:{} channel:{}\".format(r.sample_rate(), r.format(), r.channel())) while not app.need_exit(): data r.record() print(\"data size\", len(data)) time.sleep_ms(10) print(\"record finish!\") ``` Steps： 1. Import the audio, time and app modules: ```python from maix import audio, time, app ``` 2. Initialize Recorder ```python r audio.Recorder() r.volume(12) ``` Note that the default sample rate is 48k, the sample format is little endian format signed 16 bit, and the sample channel is 1. You can also customise the parameters like this `r audio.Recorder(sample_rate 48000, format audio.Format.FMT_S16_LE, channel 1)`. So far only tested with sample rate 48000, format `FMT_S16_LE`, and number of sampling channels 1. `r.volume(12)` is used to set the volume, the volume range is [0,100] 3. Start recording ```python data r.record() ``` `data` is `bytes` type data in `PCM` format that holds the currently recorded audio. The `PCM` format is set when initialising the `Recorder` object, see step 2. Note that if the recording is too fast and there is no data in the audio buffer, it is possible to return an empty `bytes` of data. 4. Done, you can do voice processing on the `PCM` data returned by `r.record()` when doing your own applications. #### Records audio and saves it in `WAV` format. If you pass `path` when constructing a `Recorder` object, the recorded audio will be saved to a `path` file, and you can also get the currently recorded `PCM` data via the `record` method. `path` only supports paths with `.pcm` and `.wav` suffixes, and the `record` method does not return `WAV` headers when recording `.wav`, it only returns `PCM` data. ```python from maix import audio, time, app r audio.Recorder(\"/root/output.wav\") r.volume(12) print(\"sample_rate:{} format:{} channel:{}\".format(r.sample_rate(), r.format(), r.channel())) while not app.need_exit(): data r.record() print(\"data size\", len(data)) time.sleep_ms(10) print(\"record finish!\") ``` The code means basically the same as above. #### Record audio and save to `WAV` format (blocking) If the `record_ms` parameter is set during recording, recording audio will block until the time set by `record_ms` is reached, unit: ms. ```python from maix import audio, time, app r audio.Recorder(\"/root/output.wav\") r.volume(12) print(\"sample_rate:{} format:{} channel:{}\".format(r.sample_rate(), r.format(), r.channel())) r.record(5000) print(\"record finish!\") ``` The above example will keep recording `5000`ms and save it to `WAV` format, during the recording period it will block in `record` method, note that `PCM` data will not be returned when `record` is set to `record_ms`. ### Other The `Player` and `Recorder` modules have some `bugs` to be worked out, make sure they are created before other modules (`Camera` module, `Display` module, etc.). For example: ```python # Create Player and Recorder first. p audio.Player() r audio.Recorder() # Then create the Camera c camera.Camera() ```"},"/maixpy/doc/en/audio/synthesis.html":{"title":"MaixCAM MaixPy speech synthesis","content":" title: MaixCAM MaixPy speech synthesis TODO: comming soon~"},"/maixpy/doc/en/audio/digit.html":{"title":"MaixCAM MaixPy Continuous Chinese digit recognition","content":" title: MaixCAM MaixPy Continuous Chinese digit recognition update: date: 2024 10 08 author: 916BGAI version: 1.0.0 content: Initial document ## Introduction `MaixCAM` has ported the `Maix Speech` offline speech library, enabling continuous Chinese numeral recognition, keyword recognition, and large vocabulary speech recognition capabilities. It supports audio recognition in `PCM` and `WAV` formats, and can accept input recognition via the onboard microphone. ## Maix Speech [`Maix Speech`](https://github.com/sipeed/Maix Speech) is an offline speech library specifically designed for embedded environments. It features deep optimization of speech recognition algorithms, achieving a significant lead in memory usage while maintaining excellent WER. For more details on the principles, please refer to the open source project. ## Continuous Chinese digit recognition ```python from maix import app, nn speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") def callback(data: str, len: int): print(data) speech.digit(640, callback) while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") speech.deinit() break ``` ### Usage 1. Import the `app` and `nn` modules ```python from maix import app, nn ``` 2. Load the acoustic model ```python speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") ``` You can also load the `am_7332` acoustic model; larger models provide higher accuracy but consume more resources. 3. Choose the corresponding audio device ```python speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") ``` This uses the onboard microphone and supports both `WAV` and `PCM` audio as input devices. ```python speech.init(nn.SpeechDevice.DEVICE_WAV, \"path/audio.wav\") # Using WAV audio input ``` ```python speech.init(nn.SpeechDevice.DEVICE_PCM, \"path/audio.pcm\") # Using PCM audio input ``` Note that `WAV` must be `16KHz` sample rate with `S16_LE` storage format. You can use the `arecord` tool for conversion. ```shell arecord d 5 r 16000 c 1 f S16_LE audio.wav ``` When recognizing `PCM/WAV` , if you want to reset the data source, such as for the next WAV file recognition, you can use the `speech.devive` method, which will automatically clear the cache: ```python speech.devive(nn.SpeechDevice.DEVICE_WAV, \"path/next.wav\") ``` 4. Set up the decoder ```python def callback(data: str, len: int): print(data) speech.digit(640, callback) ``` Users can register several decoders (or none), which decode the results from the acoustic model and execute the corresponding user callback. Here, a `digit` decoder is registered to output the Chinese digit recognition results from the last 4 seconds. The returned recognition results are in string format and support `0123456789 .(dot) S(ten) B(hundred) Q(thousand) W(thousand)`. For other decoder usages, please refer to the sections on Real time voice recognition and keyword recognition. When setting the `digit` decoder, you need to specify a `blank` value; exceeding this value (in ms) will insert a `_` in the output results to indicate idle silence. After registering the decoder, use the `speech.deinit()` method to clear the initialization. 5. Recognition ```python while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") speech.deinit() break ``` Use the `speech.run` method to run speech recognition. The parameter specifies the number of frames to run each time, returning the actual number of frames processed. Users can choose to run 1 frame each time and then perform other processing, or run continuously in a single thread, stopping it with an external thread. ### Recognition Results If the above program runs successfully, speaking into the onboard microphone will yield continuous Chinese digit recognition results, such as: ```shell _0123456789 ```"},"/maixpy/doc/en/audio/keyword.html":{"title":"MaixCAM MaixPy Keyword recognition","content":" title: MaixCAM MaixPy Keyword recognition update: date: 2024 10 08 author: 916BGAI version: 1.0.0 content: Initial document ## Introduction `MaixCAM` has ported the `Maix Speech` offline speech library, enabling continuous Chinese numeral recognition, keyword recognition, and large vocabulary speech recognition capabilities. It supports audio recognition in `PCM` and `WAV` formats, and can accept input recognition via the onboard microphone. ## Maix Speech [`Maix Speech`](https://github.com/sipeed/Maix Speech) is an offline speech library specifically designed for embedded environments. It features deep optimization of speech recognition algorithms, achieving a significant lead in memory usage while maintaining excellent WER. For more details on the principles, please refer to the open source project. ## Keyword recognition ```python from maix import app, nn speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") kw_tbl ['xiao3 ai4 tong2 xue2', 'ni3 hao3', 'tian1 qi4 zen3 me yang4'] kw_gate [0.1, 0.1, 0.1] def callback(data:list[float], len: int): for i in range(len): print(f\"\\tkw{i}: {data[i]:.3f};\", end ' ') print(\"\\n\") speech.kws(kw_tbl, kw_gate, callback, True) while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") speech.deinit() break ``` ### Usage 1. Import the `app` and `nn` modules ```python from maix import app, nn ``` 2. Load the acoustic model ```python speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") ``` You can also load the `am_7332` acoustic model; larger models provide higher accuracy but consume more resources. 3. Choose the corresponding audio device ```python speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") ``` This uses the onboard microphone and supports both `WAV` and `PCM` audio as input devices. ```python speech.init(nn.SpeechDevice.DEVICE_WAV, \"path/audio.wav\") # Using WAV audio input ``` ```python speech.init(nn.SpeechDevice.DEVICE_PCM, \"path/audio.pcm\") # Using PCM audio input ``` Note that `WAV` must be `16KHz` sample rate with `S16_LE` storage format. You can use the `arecord` tool for conversion. ```shell arecord d 5 r 16000 c 1 f S16_LE audio.wav ``` When recognizing `PCM/WAV` , if you want to reset the data source, such as for the next WAV file recognition, you can use the `speech.devive` method, which will automatically clear the cache: ```python speech.devive(nn.SpeechDevice.DEVICE_WAV, \"path/next.wav\") ``` 4. Set up the decoder ```python kw_tbl ['xiao3 ai4 tong2 xue2', 'ni3 hao3', 'tian1 qi4 zen3 me yang4'] kw_gate [0.1, 0.1, 0.1] def callback(data:list[float], len: int): for i in range(len): print(f\"\\tkw{i}: {data[i]:.3f};\", end ' ') print(\"\\n\") speech.kws(kw_tbl, kw_gate, callback, True) ``` Users can register several decoders (or none), which decode the results from the acoustic model and execute the corresponding user callback. Here, a `kws` decoder is registered to output a list of probabilities for all registered keywords from the last frame. Users can observe the probability values and set their own thresholds for activation. For other decoder usages, please refer to the sections on Real time voice recognition and continuous Chinese numeral recognition. When setting up the `kws` decoder, you need to provide a `keyword list` separated by spaces in Pinyin, a `keyword probability threshold list` arranged in order, and specify whether to enable `automatic near sound processing`. If set to `True`, different tones of the same Pinyin will be treated as similar words to accumulate probabilities. Finally, you need to set a callback function to handle the decoded data. Users can also manually register near sound words using the `speech.similar` method, with a maximum of `10` near sound words registered for each Pinyin. (Note that using this interface to register near sound words will override the near sound table generated by enabling `automatic near sound processing`.) ```python similar_char ['zhen3', 'zheng3'] speech.similar('zen3', similar_char) ``` After registering the decoder, use the `speech.deinit()` method to clear the initialization. 5. Recognition ```python while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") speech.deinit() break ``` Use the `speech.run` method to run speech recognition. The parameter specifies the number of frames to run each time, returning the actual number of frames processed. Users can choose to run 1 frame each time and then perform other processing, or run continuously in a single thread, stopping it with an external thread. ### Recognition Results If the above program runs successfully, speaking into the onboard microphone will yield keyword recognition results, such as: ```shell kws log 2.048s, len 24 decoder_kws_init get 3 kws 00, xiao3 ai4 tong2 xue2 01, ni3 hao3 02, tian1 qi4 zen3 me yang4 find shared memory(491520), saved:491520 kw0: 0.959; \tkw1: 0.000; \tkw2: 0.000; # xiao3 ai4 tong2 xue2 kw0: 0.000; \tkw1: 0.930; \tkw2: 0.000; # ni3 hao3 kw0: 0.000; \tkw1: 0.000; \tkw2: 0.961; # tian1 qi4 zen3 me yang4 ```"},"/maixpy/doc/en/audio/play.html":{"title":"MaixCAM MaixPy Playback Audio","content":" title: MaixCAM MaixPy Playback Audio update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: Initial document ## Introduction This document provides instructions on how to play audio ## How to use ### Hardware operation ![image 20240520134637905](../../../static/image/maixcam_hardware_back.png) The `MaixCAM` does not have a built in speaker, so you will need to solder a `1W` speaker yourself. The pins for soldering the speaker are shown in the diagram above on the `VOP` and `VON` pins corresponding to the Speaker. Note: If the `MaixCAM` has copper posts attached to these pins, they can be soldered directly to the posts, or on the other side of the board for aesthetic reasons. ### Code #### Playing a `WAV` file ```python from maix import audio, time, app p audio.Player(\"/root/output.wav\") p.play() while not app.need_exit(): time.sleep_ms(10) print(\"play finish!\") ``` Steps： 1. Import the audio, time and app modules: ```python from maix import audio, time, app ``` 2. Initialize the player: ```python p audio.Player(\"/root/output.wav\") ``` Note that the default sample rate is 48k, the sample format is little endian format signed 16 bit, and the sample channel is 1. You can also customise the parameters like this `p audio.Player(sample_rate 48000, format audio.Format.FMT_S16_LE, channel 1)`. So far only tested with sample rate 48000, format `FMT_S16_LE`, and number of sampling channels 1. If it is a `.wav` file, the sample rate, sample format and sample channel are automatically obtained. 3. Playing audio ```python p.play() ``` This will block until all audio data is written, but not until all audio data is actually played. If you exit the programme after calling `play()`, some of the audio data to be played may be lost. 4. Done #### Playback with `PCM` data ```python from maix import audio, time, app p audio.Player() with open('/root/output.pcm', 'rb') as f: ctx f.read() p.play(bytes(ctx)) while not app.need_exit(): time.sleep_ms(10) print(\"play finish!\") ``` Steps： 1. Import the audio, time and app modules: ```python from maix import audio, time, app ``` 2. Initialize the player: ```python p audio.Player() ``` Note that the default sample rate is 48k, the sample format is little endian format signed 16 bit, and the sample channel is 1. You can also customise the parameters like this `p audio.Player(sample_rate 48000, format audio.Format.FMT_S16_LE, channel 1)`. So far only tested with sample rate 48000, format `FMT_S16_LE`, and number of sampling channels 1. 3. Open and playback a PCM file ```python with open('/root/output.pcm', 'rb') as f: ctx f.read() p.play(bytes(ctx)) while not app.need_exit(): time.sleep_ms(10) ``` `with open(‘xxx’,‘rb’) as f:` open file `xxx` and get file object `f` `ctx f.read()` reads the contents of the file into `ctx` `p.play(bytes(ctx))` plays the audio, `p` is the opened player object, `ctx` is the `PCM` data converted to type bytes `time.sleep_ms(10)` Here there is a loop to wait for the playback to complete, as the playback operation is performed asynchronously, and if the program exits early, then it may result in the audio not being played completely. 4. Done ### Other The `Player` and `Recorder` modules have some `bugs` to be worked out, make sure they are created before other modules (`Camera` module, `Display` module, etc.). For example: ```python # Create Player and Recorder first. p audio.Player() r audio.Recorder() # Then create the Camera c camera.Camera() ```"},"/maixpy/doc/en/audio/ai_classify.html":{"title":"MaixCAM MaixPy AI voice classify","content":" title: MaixCAM MaixPy AI voice classify TODO: To be completed. If you need it urgently, you can first port the model yourself or process the audio into a spectrogram using FFT, and then train an AI classification model based on the image representation."},"/maixpy/doc/en/peripheral/pwm.html":{"title":"Using PWM in MaixCAM MaixPy","content":"# Using PWM in MaixCAM MaixPy ## Introduction To use `PWM` in MaixPy (v4), first set the pin function to `PWM` using `pinmap`. Each `PWM` corresponds to a specific pin, as shown in the pin diagram of MaixCAM: ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) ![maixcam_pro_io](/static/image/maixcam_pro_io.png) We recommend using `PWM6` and `PWM7`. For `MaixCAM`, since `WiFi` uses all pins of `SDIO1`, `PWM4~9` can only be used alternatively with `WiFi`. > TODO: Provide a method to disable WiFi (requires disabling the WiFi driver in the system, which is quite complex) ## Using PWM to Control a Servo in MaixPy Here we take controlling a servo as an example, using `PWM7` and the `A19` pin of `MaixCAM`: ```python from maix import pwm, time, pinmap SERVO_PERIOD 50 # 50Hz 20ms SERVO_MIN_DUTY 2.5 # 2.5% > 0.5ms SERVO_MAX_DUTY 12.5 # 12.5% > 2.5ms # Use PWM7 pwm_id 7 # !! set pinmap to use PWM7 pinmap.set_pin_function(\"A19\", \"PWM7\") def angle_to_duty(percent): return (SERVO_MAX_DUTY SERVO_MIN_DUTY) * percent / 100.0 + SERVO_MIN_DUTY out pwm.PWM(pwm_id, freq SERVO_PERIOD, duty angle_to_duty(0), enable True) for i in range(100): out.duty(angle_to_duty(i)) time.sleep_ms(100) for i in range(100): out.duty(angle_to_duty(100 i)) time.sleep_ms(100) ``` This code controls the servo to rotate from the minimum angle to the maximum angle and then back to the minimum angle."},"/maixpy/doc/en/peripheral/wdt.html":{"title":"Using Watchdog Timer in MaixCAM MaixPy","content":"# Using Watchdog Timer in MaixCAM MaixPy ## Introduction To prevent program issues, a watchdog timer (WDT) is often used to automatically restart the system when the program encounters a problem. The principle is that there is a countdown timer that we need to periodically reset within the program logic (also called \"feeding the dog\"). If our program gets stuck and fails to reset the countdown timer, the hardware will trigger a system reboot when the timer reaches 0. ## Using WDT in MaixPy ```python from maix import wdt, app, time w wdt.WDT(0, 1000) while not app.need_exit(): w.feed() # Here, sleep operation is our task # 200 ms is normal; if it exceeds 1000 ms, it will cause a system reset time.sleep_ms(200) ``` This code sets up a watchdog timer that requires feeding every 1000 ms. If the program fails to feed the watchdog within this period, the system will reset."},"/maixpy/doc/en/peripheral/uart.html":{"title":"Introduction to Using MaixCAM MaixPy UART Serial Port","content":" title: Introduction to Using MaixCAM MaixPy UART Serial Port ## Introduction to Serial Ports A serial port is a communication method that includes the definitions of both hardware and communication protocols. * Hardware includes: * 3 pins: `GND`, `RX`, `TX`, with cross connection for communication. `RX` and `TX` should be cross connected, meaning one side's `TX` should connect to the other side's `RX`, and both sides' `GND` should be connected together. * Controller, usually inside the chip, also known as the `UART` peripheral. Generally, a chip can have one or more `UART` controllers, each with corresponding pins. * Serial communication protocol: To ensure smooth communication between both parties, a set of protocols is established, specifying how communication should occur, including common parameters like baud rate and parity bit. Baud rate is the most commonly used parameter. Using the serial port of the board, you can communicate data with other microcontrollers or SOCs. For example, human detection can be implemented on MaixCAM, and the detected coordinates can be sent to STM32/Arduino microcontrollers via the serial port. ## Using Serial Port in MaixPy MaixCAM's default configuration exposes a serial port through the USB port. By plugging in the Type C adapter board, you can directly use the serial port pins. Alternatively, you can use the `A16(TX)` and `A17(RX)` pins directly on the board, which are equivalent to those exposed via the USB port, refer to IO interface image: ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) ![maixcam_pro_io](/static/image/maixcam_pro_io.png) When using the serial port exposed through USB on MaixCAM, note that the `RX` and `TX` pins on the Type C adapter board will swap between regular and reverse insertions (assuming the **Type C female port is facing forward** and matching the silk screen). If communication fails, try flipping the Type C connection to see if it resolves the issue. Although this is a design flaw, frequent plug/unplug operations are rare, so adapting to it is acceptable. After connecting the two communicating boards (cross connecting `RX` and `TX` and connecting both `GND`), you can use software for communication. Using the serial port with MaixPy is simple: ```python from maix import uart device \"/dev/ttyS0\" # ports uart.list_devices() # List available serial ports serial uart.UART(device, 115200) serial.write_str(\"hello world\") print(\"received:\", serial.read(timeout 2000)) ``` Here, we use the first serial port `/dev/ttyS0`, which is the serial port exposed via `Type C` mentioned above. More serial port APIs can be found in the [UART API documentation](../../../api/maix/peripheral/uart.html). ## MaixCAM Serial Port Usage Notes ### TX Pin Notes MaixCAM's `TX` (`UART0`) pin must not be in a pulled down state during boot up, or the device will fail to start. This is a characteristic of the chip. If you are designing a 3.3v to 5v level shifting circuit, be sure not to default it to a pulled down state and keep it floating (consider using a level shifting chip). If the device fails to boot, also check whether the `TX` pin is pulled down. ## Connecting to a Computer via Serial Port Developers may ask: Why doesn't the serial port device appear on the computer when the USB is plugged in? The answer is that the USB on the device defaults to a virtual USB network card without serial port functionality. To access the device's terminal, use SSH connection. For MaixCAM, the `serial port 0` from the Type C adapter board is directly connected to the `A16(TX)` and `A17(RX)` pins. It can be connected directly to other devices, such as microcontrollers' serial port pins. To communicate with a computer, use a USB to serial converter board (such as [this one](https://item.taobao.com/item.htm?spm a1z10.5 c s.w4002 24984936573.13.73cc59d6AkB9bS&id 610365562537)). ## Boot Log Output It is important to note that **MaixCAM's `serial port 0` will output some boot logs during startup**. After startup, the message `serial ready` will be printed. When communicating with a microcontroller, discard this information. If there are system startup issues, the boot log from `serial port 0` can help diagnose the problem. ## Sending Data There are mainly two functions for sending data: `write_str` and `write`. The `write_str` function is used to send strings, while `write` is used to send byte streams, i.e., `str` and `bytes` types, which can be converted to each other. For example: * `\"A\"` can be converted to `b\"A\"` using the `encode()` method, and vice versa, `b\"A\"` can be converted back to `\"A\"` using the `decode()` method. * `str` cannot display some invisible characters, such as the ASCII value `0`, which is generally `\\0` in strings and serves as a terminator. In `bytes` type, it can be stored as `b\"\\x00\"`. * This is more useful for non ASCII encoded strings. For example, the Chinese character `好` in `UTF 8` encoding is represented by three bytes `\\xe5\\xa5\\xbd`. We can use `\"好\".encode(\"utf 8\")` to get `b\"\\xe5\\xa5\\xbd\"`, and `b'\\xe5\\xa5\\xbd'.decode(\"utf 8)` to get `\"好\"`. So if we need to send byte data, we can use the `write()` method to send it. For example: ```python bytes_content b'\\x01\\x02\\x03' serial.write(bytes_content) ``` Therefore, for the `str` type, you can use `serial.write(str_content.encode())` instead of `write_str` to send it. If you have other data types that you want to convert into a **string to send**, you can use `Python string formatting` to create a string. For example, to send `I have xxx apple`, where `xxx` is an integer variable, you can do: ```python num 10 content \"I have {} apple\".format(num) content2 f\"I have {num} apple\" content3 \"I have {:04d} apple\".format(num) content4 f\"I have {num:d} apple\" print(content) print(content2) print(content3) print(content4) print(type(content)) serial.write_str(content) ``` Additionally, you can encode the data into a **binary stream to send**. For example, the first 4 bytes are hexadecimal `AABBCCDD`, followed by an `int` type value, and finally a `0xFF` at the end. You can use `struct.pack` to encode it (if this is unclear, you can read the explanation later): ```python from struct import pack num 10 bytes_content b'\\xAA\\xBB\\xCC\\xDD' bytes_content + pack(\"<i\", num) bytes_content + b'\\xFF' print(bytes_content, type(bytes_content)) serial.write(bytes_content) ``` Here, `pack(\"<i\", num)` encodes `num` as an `int` type, which is a 4 byte signed integer. The `<` symbol indicates little endian encoding, with the low byte first. Here, `num 10`, the 4 byte hexadecimal representation is `0x0000000A`, and little endian encoding puts the low byte `0x0A` first, resulting in `b'\\x0A\\x00\\x00\\x00'`. > Here, we use `i` to encode `int` type data as an example. Other types, such as `B` for `unsigned char`, etc., can also be used. More `struct.pack` formatting options can be searched online with `python struct pack`. In this way, the final data sent is `AA BB CC DD 0A 00 00 00 FF` as binary data. ## Receiving Data Use the `read` method to read data directly: ```python while not app.need_exit(): data serial.read() if data: print(data) time.sleep_ms(1) ``` Similarly, the data obtained by the `read` method is also of the `bytes` type. Here, `read` reads a batch of data sent by the other party. If there is no data, it returns `b''`, which is an empty byte. Here, `time.sleep_ms(1)` is used to sleep for `1ms`, which frees up the CPU so that this thread does not occupy all CPU resources. `1ms` does not affect the program's efficiency, especially in multithreading. In addition, the `read` function has two parameters: * `len`: Represents the maximum length you want to receive. The default is ` 1`, meaning it will return as much as there is in the buffer. If you pass a value `>0`, it means it will return data up to that length. * `timeout`: * The default `0` means it will return immediately with whatever data is in the buffer. If `len` is ` 1`, it returns all data; if a length is specified, it returns data not exceeding that length. * `<0` means it waits until data is received before returning. If ` len` is ` 1`, it waits until data is received and returns (blocking read for all data); if a length is specified, it waits until it reaches `len` before returning. * `>0` means it will return after this time, regardless of whether data is received. It may seem complex, but here are some common parameter combinations: * `read()`: Which is `read( 1, 0)`, reads the data received in the buffer, usually a batch of data sent by the other party. It returns immediately when the other party has stopped sending (within one character's sending time). * `read(len 1, timeout 1)`: Blocking read for a batch of data, waits for the other party to send data and returns only when there is no more data within one character's sending time. * `read(len 10, timeout 1000)`: Blocking read for 10 characters, returns when 10 characters are read or 1000ms has passed without receiving any data. ## Setting a Callback Function for Receiving Data In MCU development, a serial port interrupt event usually occurs when data is received. MaixPy has already handled the interrupt at the bottom layer, so developers don't need to handle the interrupt themselves. If you want to call a callback function upon receiving data, you can use `set_received_callback` to set the callback function: ```python from maix import uart, app, time def on_received(serial : uart.UART, data : bytes): print(\"received:\", data) # send back serial.write(data) device \"/dev/ttyS0\" serial uart.UART(device, 115200) serial.set_received_callback(on_received) serial0.write_str(\"hello\\r\\n\") print(\"sent hello\") print(\"wait data\") while not app.need_exit(): time.sleep_ms(100) # sleep to make CPU free ``` When data is received, the set callback function will be called in **another thread**. Since it's called in another thread, unlike an interrupt function, you don't have to exit the function quickly. You can handle some tasks in the callback function before exiting, but be aware of common multithreading issues. If you use the callback function method to receive data, do not use the `read` function to read it, or it will read incorrectly. ## Using Other Serial Ports Each pin may correspond to different peripheral functions, which is also known as pin multiplexing. As shown below, each pin corresponds to different functions. For example, pin `A17` (silkscreen identification on the board) corresponds to `GPIOA17`, `UART0_RX`, and `PWM5` functions. The default function is `UART0_RX`. ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) ![maixcam_pro_io](/static/image/maixcam_pro_io.png) By default, you can directly use `UART0` as shown above. For other serial port pins, they are not set to the serial peripheral function by default, so you need to set the mapping to use other serial ports. Use `pinmap.set_pin_function` to set it. Let's take `UART1` as an example. First, set the pin mapping to choose the serial port function, then use the device number `/dev/ttyS1`. Note that `uart.list_devices()` will not return manually mapped serial ports by default, so you can directly pass the parameters manually: ```python from maix import app, uart, pinmap, time pinmap.set_pin_function(\"A18\", \"UART1_RX\") pinmap.set_pin_function(\"A19\", \"UART1_TX\") device \"/dev/ttyS1\" serial1 uart.UART(device, 115200) ``` ## Application Layer Communication Protocol ### Concept and Character Protocol Serial ports only define the hardware communication timing. To let the receiver understand the meaning of the character stream sent by the sender, an application communication protocol is usually established. For example, if the sender needs to send coordinates containing two integer values `x, y`, the following protocol is established: * **Frame Header**: When I start sending the `$` symbol, it means I'm about to start sending valid data. > **Content**: Designing a start symbol is because serial communication is stream based. For example, sending `12345` twice may result in receiving `12345123` at some moment. The `45` from the second frame has not been received. We can determine a complete data frame based on start and end symbols. * The value range of `x, y` is 0~65535, i.e., an unsigned short integer (`unsigned short`). I'll first send `x` then `y`, separated by a comma, such as `10,20`. * **Frame Tail**: Finally, I'll send a `*` to indicate that I've finished sending this data. In this way, sending a data packet looks like `$10,20*` as a string. The other party can receive and parse it using C language: ```c // 1. Receive data // 2. Determine if the reception is complete based on the frame header and tail, and store the complete frame data in the buff array // 3. Parse a frame of data uint16_t x, y; sscanf(buff, \"$%d,%d*\", &x, &y); ``` Thus, we have defined a simple character communication protocol with a certain degree of reliability. However, since we usually use parameters like `115200 8 N 1` for serial ports, where `N` means no parity check, we can add a **checksum** to our protocol at the end. For example: * Here, we add a checksum value after `x, y`, ranging from 0 to 255. It is the sum of all previous characters modulo 255. * Taking `$10,20` as an example, in `Python`, you can simply use the `sum` function: `sum(b'$10,20') % 255 > 20`, and send `$10,20,20*`. * The receiver reads the checksum `20`, calculates it in the same way as `$10,20`, and if it is also `20`, it means no transmission error occurred. Otherwise, we assume a transmission error and discard the packet to wait for the next one. In MaixPy, encoding a character protocol can be done using Python's string formatting feature: ```python x 10 y 20 content \"${},{}*\".format(x, y) print(content) ``` ### Binary Communication Protocol The character protocol above has a clear characteristic of using visible characters to transmit data. The advantage is simplicity and human readability. However, it uses an inconsistent number of characters and larger data volumes. For example, `$10,20*` and `$1000,2000*` have varying lengths, with `1000` using 4 characters, which means 4 bytes. We know an unsigned short integer (`uint16`) can represent values ranging from `0~65535` using only two bytes. This reduces the transmission data. We also know visible characters can be converted to binary via ASCII tables, such as `$1000` being `0x24 0x31 0x30 0x30 0x30` in binary, requiring 5 bytes. If we directly encode `1000` in binary as `0x03E8`, we can send `0x24 0x03 0xE8` in just 3 bytes, reducing communication overhead. Additionally, `0x03E8` is a 2 byte representation with `0xE8` as the low byte, transmitted first in little endian encoding. The opposite is big endian encoding. Both are fine as long as both parties agree on one. In MaixPy, converting a number to bytes is simple with `struct.pack`. For example, `0x03E8` (decimal `1000`): ```python from struct import pack b pack(\"<H\", 1000) print(b) ``` Here, `<H` indicates little endian encoding, with `H` denoting a `uint16` data type, resulting in `b'\\xe8\\x03'` as bytes. Similarly, binary protocols can have a frame header, data content, checksum, frame tail, or a frame length field instead of a frame tail, based on preference. ### Built in MaixPy Communication Protocol MaixPy also includes a built in communication protocol. This communication protocol defines the format for communication between parties, making it easier to parse and recognize information. It's a binary protocol that includes a frame header, data content, and checksum. The complete protocol is defined in the [Maix Serial Communication Protocol Standard](https://github.com/sipeed/MaixCDK/blob/master/docs/doc/convention/protocol.md). Those unfamiliar with communication protocols may find it challenging at first, but reviewing the example below multiple times can help with understanding. For instance, if we have object detection, and we want to send the detected objects' information, such as coordinates, to another device (like STM32 or Arduino microcontrollers) via serial port: Complete example: [MaixPy/examples/protocol/comm_protocol_yolov5.py](https://github.com/sipeed/MaixPy/tree/main/examples/protocol/comm_protocol_yolov5.py). First, we need to detect objects. Refer to the `yolov5` object detection example. Here, we omit other details and focus on the detection results: ```python while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj .h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) dis.show(img) ``` You can see `objs` are multiple detection results. Here, we're drawing boxes on the screen, and we can find a way to send these results via the serial port. We don't need to manually initialize the serial port, just use the built in `maix.comm, maix.protocol` modules. Calling `comm.CommProtoco` will automatically initialize the serial port, with a default baud rate of `115200`. The serial port protocol can be set in the device's `System Settings >Communication Protocol`. The system settings may have other communication methods, such as `tcp`, with `uart` as the default. You can also use `maix.app.get_sys_config_kv(\"comm\", \"method\")` to check if `uart` is currently set. ```python from maix import comm, protocol, app from maix.err import Err import struct def encode_objs(objs): ''' encode objs info to bytes body for protocol 2B x(LE) + 2B y(LE) + 2B w(LE) + 2B h(LE) + 2B idx ... ''' body b\"\" for obj in objs: body + struct.pack(\"<hhHHH\", obj.x, obj.y, obj.w, obj.h, obj.class_id) return body APP_CMD_ECHO 0x01 # Custom command 1, for testing, not used here, reserved APP_CMD_DETECT_RES 0x02 # Custom command 2, send detected object information # You can define more commands based on your application p comm.CommProtocol(buff_size 1024) while not app.need_exit(): # ... objs detector.detect(img, conf_th 0.5, iou_th 0.45) if len(objs) > 0: body encode_objs(objs) p.report(APP_CMD_DETECT_RES, body) # ... ``` Here, the `encode_objs` function packages all detected object information into `bytes` type data, and the `p.report` function sends the result. The content of `body` is simply defined as `2B x(LE) + 2B y(LE) + 2B w(LE) + 2B h(LE) + 2B idx ...`, meaning: * In this image, multiple objects are detected and arranged in order in `body`. Each target takes up `2+2+2+2+2 10` bytes, with `body_len / 10` objects in total. * The 1st and 2nd bytes represent the `x` coordinate of the top left corner of the detected object, in pixels. Since the yolov5 result can have negative values for this coordinate, we use a `short` type to represent it, with little endian encoding (LE). > Little endian here means the low byte is in front. For example, if the `x` coordinate is `100`, hexadecimal `0x64`, we use a two byte `short` to represent it as `0x0064`. Little endian encoding puts `0x64` first, resulting in `b'\\x64\\x00'`. * Similarly, encode the subsequent data in sequence, resulting in `10` bytes of `bytes` type data for each object. * Iterate through and encode all object information into a single `bytes` string. When calling the `report` function, the protocol header, checksum, etc., are automatically added according to the protocol, allowing the other end to receive a complete data frame. On the other end, data should be decoded according to the protocol. If the receiving end is also using MaixPy, you can directly do: ```python while not app.need_exit(): msg p.get_msg() if msg and msg.is_report and msg.cmd APP_CMD_DETECT_RES: print(\"receive objs:\", decode_objs(msg.get_body())) p.resp_ok(msg.cmd, b'1') ``` If the other device is something like `STM32` or `Arduino`, you can refer to the C language functions in the appendix of the [Maix Serial Communication Protocol Standard](https://github.com/sipeed/MaixCDK/blob/master/docs/doc/convention/protocol.md) for encoding and decoding. ## Other Tutorials * [【MaixPy/MaixCAM】Visual Tool MaixCAM Beginner Tutorial 2](https://www.bilibili.com/video/BV1vcvweCEEe/?spm_id_from 333.337.search card.all.click) Watch the serial port explanation section * [How to Communicate via Serial Port between Visual Module and STM32](https://www.bilibili.com/video/BV175vWe5EfV/?spm_id_from 333.337.search card.all.click&vd_source 6c974e13f53439d17d6a092a499df304) * [[MaixCam] Experience 2: UART Serial Communication](https://blog.csdn.net/ButterflyBoy0/article/details/140577441) * For more, search online for resources."},"/maixpy/doc/en/peripheral/adc.html":{"title":"Using ADC in MaixCAM MaixPy","content":" title: Using ADC in MaixCAM MaixPy update: date: 2024 06 11 author: iawak9lkm version: 1.0.0 content: Initial document ## ADC Introduction An ADC, which can also be called an analog to digital converter, converts an input voltage signal into an output digital signal. As the ADC converted digital signal itself does not have practical significance, only represents a relative size. Therefore, any ADC needs a reference analog as a conversion standard, the reference standard is generally the largest convertible signal size. The digital output of the ADC indicates the size of the input signal relative to the reference signal. ADC peripherals generally have two main parameters: resolution and reference voltage. * Resolution: The resolution of an ADC is expressed as the number of bits in a binary (or decimal) number. It describes the ability of the A/D converter to discriminate the input signal. Generally speaking, an A/D converter with n bit output can distinguish 2^n different levels of input analog voltage, and the minimum value of input voltage that can be distinguished is 1/(2^n) of the full scale input. For a given maximum input voltage, the more output bits, the higher the resolution. * Reference Voltage: The ADC peripheral reference voltage is the voltage that is compared to a known voltage during AD conversion to find the value of the unknown voltage. The reference voltage can be thought of as the highest upper limit voltage and can be reduced to improve resolution when the signal voltage is low. With the board's ADC, it is possible to capture external voltages and have the board verify that the voltages are up to snuff or perform specific tasks when specific voltages are detected (e.g., the ADC detects multiple buttons). ## Using ADC in MaixPy Using ADC with MaixPy is easy: ```python from maix.peripheral import adc from maix import time a adc.ADC(0, adc.RES_BIT_12) raw_data a.read() print(f\"ADC raw data:{raw_data}\") time.sleep_ms(50) vol a.read_vol() print(f\"ADC vol:{vol}\") ``` Use ADC0 to read the raw conversion data from it, or read the voltage data directly from it. See the ADC [API documentation](../../../api/maix/peripheral/adc.html) for a detailed description of the ADC API. ## Some notes on MaixCAM's ADC MaixCAM elicits an IO that connects to the ADC, this IO is GPIO B3（For MaixCAM Pro, B3 connected light LED, so ADC can't directly use）. ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) This IO is ADC by default and does not require additional configuration. MaixCAM's ADC peripheral has a sampling accuracy of 12 bits, which means that the sampling output range is from 0 to 4095. The sampling accuracy is 1/4096 of the reference voltage. The MaixCAM's ADC peripheral cannot scan at a frequency higher than 320K/s, which is the reason for the additional wait time between ADC samples in the previous example. The MaixCAM's ADC peripheral has an internal reference voltage of 1.5V, which may vary slightly in actual use.Since the typical internal reference voltage is 1.5 V, the ADC range of Soc is 0 to 1.5 V. Since the ADC range of this range is small, MaixCAM has designed a voltage divider circuit for the ADC peripheral to increase the ADC range. The reference voltage Vin_max of this voltage divider circuit is about 4.6~5.0V, due to the error of resistor resistance in the circuit, the impedance of ADC external device, and the deviation of internal reference voltage. A higher precision default value has been chosen in the API, and there is generally no need to pass this parameter. ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/peripheral/adc.png) If you need high ADC accuracy, you can calculate the reference voltage for this voltage divider circuit by following the steps below: * You need to first measure to get the actual input voltage of ADC_PIN, which we call Vin. * Then you need to measure to get the actual input voltage at ADC1, which we call Vadc. The location of resistor R10 can be found in this BOM file. * You need to keep the same voltage input to ADC_PIN as in step 1 and then execute these commands in the shell: ```shell echo 1 > /sys/class/cvi saradc/cvi saradc0/device/cv_saradc cat /sys/class/cvi saradc/cvi saradc0/device/cv_saradc ``` This gives you the raw measured value of the ADC, which we call adc_data. * You need to know the resistance values of the resistors R6 and R10 in the picture, record them.Typically, the MaixCAM has a resistance value of 10KΩ (10 000Ω) for R6 and 5.1KΩ (5 100Ω) for R10. * Finally, you need to pass the results from the above steps to these python codes to get the range [0,Vin_max] of the ADC_PIN port. ```python def maixcam_get_vin_max(Vin:float, Vadc:float, adc_data:int, r6:int, r10:int, adc_max:int 4095): Vref (Vadc/adc_data)*(adc_max+1) r3 Vadc*r6/(Vin Vadc) Vin_max (Vref/r3)*(r6+r3) return Vin_max Vin 3.3\t\t# step 1 Vadc 1.06\t\t# step 2 adc_data 2700\t# step 3 r6 10000\t\t# step 4 r10 5100\t\t# step 4 if __name__ '__main__': print(maixcam_get_vin_max(Vin, Vadc, adc_data, r6, r10)) ``` Now pass the result to the third parameter of `adc.ADC()` and you will get a highly accurate ADC."},"/maixpy/doc/en/peripheral/hid.html":{"title":"Introduction to Using MaixCAM MaixPy HID Device","content":" title: Introduction to Using MaixCAM MaixPy HID Device ## 简介 MaixPy currently supports the use of keyboards, mice, and touchscreens, and the following is a guide on how to use maixPy to control your PC via HID. ## Preparation > MaixPy firmware version should be > 4.5.1. You must enable the HID device before operating HID, there are two ways: 1. Open the `Settings` application that comes with MaixCAM, click `USB Settings` in turn > tick the required HID devices, such as `Keyboard`, `Mouse`, `Touchscreen`, and then click `Confirm` , then restart MaixCAM. 2. Through the `Examples/tools/maixcam_switch_usb_mode.py` in MaixVision, modify the HID devices that need to be switched on in the `device_list`, run it and restart MaixCAM. Note: Since only 4 USB devices are supported, only 4 devices can be started at the same time among `ncm`, `rndis`, `keyboard`, `mouse`, `touchpad`, choose according to the actual demand, among them, `ncm` and `rndis` are the USB network protocol devices, you can turn them off if you don't need them, by default, they are turned on. ## Write a keyboard in MaixPy. You need to enable `HID Keyboard` to run it. The following example sends `rstuv` four characters through the keyboard and then releases the key. ```python from maix import hid, time keyboard hid.Hid(hid.DeviceType.DEVICE_KEYBOARD) # Refer to the `Universal Serial Bus HID Usage Tables` section of the [USB HID Documentation](https://www.usb.org) for key numbers. keys [21, 22, 23, 24, 25, 0] # means [r, s, t, u, v, 0], 0 means release key. for key in keys: keyboard.write([0, 0, key, 0, 0, 0, 0, 0]) ``` ## Write a mouse in MaixPy. You need to enable `HID Mouse` to run it. The following example moves the mouse 5 pixels every 100ms. ```python from maix import hid, time mouse hid.Hid(hid.DeviceType.DEVICE_MOUSE) button 0 # button state, 0 means release, 1 means left button pressed, 2 means right button pressed, 4 means wheel button pressed x_oft 0 # offset relative to current position, value range is 127~127 y_oft 0 # offset relative to current position, value range is 127~127 wheel_move 0 # The distance the wheel has moved, the range of values is 127~127 count 0 while True: x_oft + 5 y_oft + 5 mouse.write([button, x_oft, y_oft, wheel_move]) time.sleep_ms(100) count + 1 if count > 50: break ``` ## Write a touchpad in MaixPy. The `HID Touchpad` needs to be enabled to run. In the following example, move the touchscreen 150 units every 100ms. Note that the coordinate system of the touchscreen is absolute, not relative, and that you need to map the actual size of the screen to the interval [1, 0x7FFF], the coordinates (1,1) means the upper left corner, the coordinates (0x7FFF,0x7FFF) means the lower right corner. ```python from maix import hid, time touchpad hid.Hid(hid.DeviceType.DEVICE_TOUCHPAD) def touchpad_set(button, x_oft, y_oft, wheel_move): touchpad.write([button, # button state, 0 means release, 1 means left button pressed, 2 means right button pressed, 4 means wheel button pressed x_oft & 0xff, (x_oft >> 8) & 0xff, # Absolute position, the leftmost is 1, the rightmost is 0x7fff, 0 means no operation, the value range is 0 to 0x7fff. y_oft & 0xff, (y_oft >> 8) & 0xff, # Absolute position, the topmost is 1, the bottom is 0x7fff, 0 means no operation, the value range is 0 to 0x7fff wheel_move]) # wheel move distance, value range is 127~127 button 0 x_oft 0 y_oft 0 wheel_move 0 count 0 while True: x_oft + 150 y_oft + 150 touchpad_set(button, x_oft, y_oft, wheel_move) time.sleep_ms(100) count + 1 if count > 50: break ```"},"/maixpy/doc/en/peripheral/gpio.html":{"title":"MaixCAM MaixPy Using GPIO","content":"# MaixCAM MaixPy Using GPIO ## Introduction Using GPIO allows you to control pins for input or output high and low levels, which is commonly used to read signals or output control signals. **Note:** The pins on the `MaixCAM` are tolerant to `3.3V`. Do not input `5V` voltage. ## Using GPIO in MaixPy > MaixPy Firmware should > 4.1.2(not include) First, we need to know which pins and GPIOs the device has. For MaixCAM, each pin corresponds to a GPIO controller, as shown in the figure: ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) ![maixcam_pro_io](/static/image/maixcam_pro_io.png) It is important to note that pins can be used not only as GPIOs but also for other functions like PWM. Before using them, we need to set the pin function to GPIO. For example, on MaixCAM, **some pins are already occupied by other functions by default, such as UART0 and WiFi (SDIO1 + A26), so it is not recommended to use them.** Other pins can be used, and the A14 pin is connected to the onboard LED, which is used as a system load indicator by default. If initialized, it will automatically disable the system indicator function and can be used as a regular GPIO (note that `A14` can only be used as an output). This way, you can control the LED's on and off state. Here is the English translation of your text: The circuit diagram of the LED is shown in the figure. Therefore, we only need to provide a high signal to pin A14, and the LED will conduct and light up: ![](../../assets/gpio_led.png) ```python from maix import gpio, pinmap, time pinmap.set_pin_function(\"A14\", \"GPIOA14\") led gpio.GPIO(\"GPIOA14\", gpio.Mode.OUT) led.value(0) while 1: led.toggle() time.sleep_ms(500) ``` Here, we first use `pinmap` to set the function of the `A14` pin to `GPIO`. Of course, for `A14`, since it only has the `GPIO` function, it can be omitted. For the sake of generality, other pins may need to be set, so it is set in this example. For more APIs, please refer to the [GPIO API Documentation](https://wiki.sipeed.com/maixpy/api/maix/peripheral/gpio.html) ## GPIO in Input Mode ```python from maix import gpio, pinmap, time pinmap.set_pin_function(\"A19\", \"GPIOA19\") led gpio.GPIO(\"GPIOA19\", gpio.Mode.IN) while 1: print(led.value()) time.sleep_ms(1) # sleep to make cpu free ``` Here is the English translation of the text: ## MaixCAM Pro Uses Illumination LED Both MaixCAM and MaixCAM Pro have a small LED light connected to pin `A14`. Additionally, the MaixCAM Pro has an onboard illumination LED connected to pin `B3`, which is turned on by a high signal and off by a low signal: ```python from maix import gpio, pinmap, time pinmap.set_pin_function(\"B3\", \"GPIOB3\") led gpio.GPIO(\"GPIOB3\", gpio.Mode.OUT) led.value(0) while 1: led.toggle() time.sleep_ms(500) ```"},"/maixpy/doc/en/peripheral/spi.html":{"title":"Using SPI in MaixCAM MaixPy","content":" title: Using SPI in MaixCAM MaixPy update: date: 2024 06 11 author: iawak9lkm version: 1.0.0 content: Initial document ## SPI Introduction SPI (Serial Peripheral Interface) is a synchronous peripheral interface that enables the SoC to communicate serially with various peripheral devices to exchange information. Common peripherals are Flash RAM, network controllers, LCD display drivers, and A/D converters. SPI uses Master Slave mode, which supports one or more Slave devices. On a hardware circuit, SPI usually consists of 4 wires which are: * `MISO`(Master Output Slave Input): This pin sends data in slave mode or receives data in master mode. * `MOSI`(Master Input Slave Output): This pin sends data in master mode or receives data in slave mode. * `SCK`: Serial bus clock, output by the master device and input by the slave device. * `NSS/CS`: Slave Device Selection. It acts as a chip select pin, allowing the master device to communicate with specific slave devices individually, avoiding conflicts on the bus. In terms of communication protocols, SPI behavior is generally like this: * SPI supports one master device and multiple slave devices. When the master device needs to communicate with a specific slave device, it selects the CS pin connected to that slave device to enable this transfer.This means that a slave device has only one CS pin for the master device to select itself, and the number of chip select pins for the master device depends on how many slave devices are connected to its SPI bus. * SPI has four modes, depending on the configuration of polarity (CPOL) and phase (CPHA). Polarity affects the level of the clock signal when the SPI bus is idle. 1. CPOL 1, it indicates a high level at idle. 2. CPOL 0, it indicates a low level at idle. The phase determines the edge at which the SPI bus acquires data. There are two types of edges, rising edge and falling edge. 1. CPHA 0, it indicates that sampling starts from the first edge. 2. CPHA 1, it indicates that sampling starts from the second edge. Polarity and phase are combined to form the four modes of SPI: Mode CPOL CPHA 0 0 0 1 0 1 2 1 0 3 1 1 * SPI typically supports both full duplex transmission and half duplex transmission. * SPI does not specify a maximum transmission rate, it does not have an address scheme; SPI does not specify a communication response mechanism, it does not specify flow control rules. ## Using SPI in MaixPy This is the pinout of MaixCAM. ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) ![maixcam_pro_io](/static/image/maixcam_pro_io.png) You need to use `maix.peripheral.pinmap` to complete the pin mapping for SPI before use. **Note: The MaixCAM's SPI can only be used as an SPI master device. MaixCAM's SPI does not support modifying the valid level of the hardware CS pins at this time. The active level of all SPI hardware CS is low. If you need to use other CS active levels, configure the software CS pins and their active levels in the SPI API. SPI4 is the software simulated SPI, the measured maximum rate is 1.25MHz, and the usage is the same as hardware SPI.** Using SPI with MaixPy is easy: ```python from maix import spi, pinmap pin_function { \"A24\": \"SPI4_CS\", \"A23\": \"SPI4_MISO\", \"A25\": \"SPI4_MOSI\", \"A22\": \"SPI4_SCK\" } for pin, func in pin_function.items(): if 0 ! pinmap.set_pin_function(pin, func): print(f\"Failed: pin{pin}, func{func}\") exit( 1) spidev spi.SPI(4, spi.Mode.MASTER, 1250000) ### Example of full parameter passing. # spidev spi.SPI(id 4, # SPI ID # mode spi.Mode.MASTER, # SPI mode # freq 1250000, # SPI speed # polarity 0, # CPOL 0/1, default is 0 # phase 0, # CPHA 0/1, default is 0 # bits 8, # Bits of SPI, default is 8 # cs_enable True, # Use soft CS pin? True/False, default is False # cs 'GPIOA19') # Soft cs pin number, default is 'GPIOA19' b bytes(range(0, 8)) res spidev.write_read(b, len(b)) if res b: print(\"loopback test succeed\") else: print(\"loopback test failed\") print(f\"send:{b}\\nread:{res}\") ``` You need to connect the `MOSI` and `MISO` of this SPI first. Configure the required pins with `pinmap` and then enable full duplex communication, the return value will be equal to the sent value. See the [SPI API documentation]((../../../api/maix/peripheral/spi.md)) for a more detailed description of the SPI API."},"/maixpy/doc/en/peripheral/i2c.html":{"title":"Using I2C with MaixCAM MaixPy","content":" title: Using I2C with MaixCAM MaixPy > Note: Requires MaixPy image and firmware > 4.2.1 The `I2C` and corresponding pins of `MaixCAM` can be seen in the diagram: ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) ![maixcam_pro_io](/static/image/maixcam_pro_io.png) For MaixCAM, due to limited pin resources, the pins for `I2C1` and `I2C3` overlap with those of the WiFi module (SDIO1). Therefore, you can only use either WiFi or hardware I2C, but not both. Additionally, there is an `I2C5`, which is simulated by software at the lower driver level. It is recommended to use this one, as the drivers are already set up, and its use is the same as using hardware `I2C`. By default, the pins for `I2C5` are configured as `GPIO`. Therefore, before using the `i2c` module, you should first use the `pinmap` module to set the pin functions to `I2C5` as follows: ```python from maix import i2c, pinmap pinmap.set_pin_function(\"A15\", \"I2C5_SCL\") pinmap.set_pin_function(\"A27\", \"I2C5_SDA\") bus1 i2c.I2C(5, i2c.Mode.MASTER) slaves bus1.scan() print(\"find slaves:\", slaves) ``` For more APIs, see [i2c API documentation](https://wiki.sipeed.com/maixpy/api/maix/peripheral/i2c.html). As mentioned above, for the `MaixCAM`, you must choose between using hardware `I2C` and `WiFi`. If you need to use `I2C`, you must disable `WiFi` and use the `pinmap` module to set the pin functions for `I2C`, then operate using the `maix.i2c` module. > TODO: Provide a method to disable WiFi (requires disabling the WiFi driver in the system, which is more complex). ```python from maix import i2c, pinmap pinmap.set_pin_function(\"P18\", \"I2C1_SCL\") pinmap.set_pin_function(\"P21\", \"I2C1_SDA\") bus1 i2c.I2C(1, i2c.Mode.MASTER) slaves bus1.scan() print(\"find slaves:\", slaves) ```"},"/maixpy/doc/en/peripheral/pinmap.html":{"title":"Using PINMAP in MaixCAM MaixPy","content":" title: Using PINMAP in MaixCAM MaixPy update: date: 2024 06 11 author: iawak9lkm version: 1.0.0 content: Initial document ## Pinmap Introduction In System on Chip (SoC) design, a pin usually has more than one function, and this design method is called pin multiplexing. There are several main reasons for this: * It saves the number of SoC pins. SoCs integrate a large number of functional modules, such as CPUs, GPUs, memory controllers, I/O interfaces, communication modules, and so on. Assigning separate pins for each function would result in a very large number of pins being required, increasing the complexity and cost of the package. Through pin multiplexing, one pin can support different functions in different modes, thus significantly reducing the total number of pins. * It reduces the cost of chip packaging and manufacturing. Designers can choose smaller package sizes by reducing the number of pins, thus reducing packaging and manufacturing costs. Smaller packages not only reduce material costs, but also reduce the amount of space the chip takes up on the board, facilitating the design of more compact electronic products. * It improves design flexibility. Pin multiplexing provides greater design flexibility. Different combinations of pin functions may be required in different application scenarios, and different pin functions can be enabled according to specific needs through software configuration. For example, the same pin can be used as a UART interface in one practical application and an SPI bus interface in another. * It simplifies the PCB layout. Reducing the number of pins simplifies the layout design of a printed circuit board (PCB). Fewer pins mean fewer wiring layers and vias, which simplifies PCB design and reduces manufacturing challenges and costs. * Optimize performance. In some cases, signal paths and performance can be optimized by multiplexing pins. For example, by selecting the proper combination of pin functions, interference and noise in the signal transmission path can be reduced, improving the overall performance and reliability of the system. Pinmap displays and manages the individual pin configurations of the chip, which typically include the name of each pin and its function (usually multiple functions). We use the MaixCAM GPIO A28 as an example. * `A28` is the pin name. * `GPIOA28`/`UART2_TX`/`JTAG_TDI` are the functions supported by this pin as listed in the Soc manual, and the function of this pin at the same time can only be one of these three functions. With Pinmap, we can set the specified chip pin for the specified function. ## Using Pinmap in MaixPy The following diagram lists the pin numbers and their functions on the MaixCAM board. ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) ![maixcam_pro_io](/static/image/maixcam_pro_io.png) Or read the [SG2002 Chip Manual](https://cn.dl.sipeed.com/fileList/LICHEE/LicheeRV_Nano/07_Datasheet/SG2002_Preliminary_Datasheet_V1.0 alpha_CN.pdf) Pinmux section for the remaining pin numbers and functions. It's actually quite easy to use Pinmap to manage pin functions through MaixPy. ```python from maix.peripheral import pinmap print(pinmap.get_pins()) f pinmap.get_pin_functions(\"A28\") print(f\"GPIO A28 pin functions:{f}\") print(f\"Set GPIO A28 to {f[0]} function\") pinmap.set_pin_function(\"A28\", f[0]) ``` In the example, we start by listing all the pins available for management. Then we query `GPIO A28` for all the functions available. Finally the function of the pin is set to the first function listed (GPIO). For a more detailed description of the Pinmap API, see the [Pinmap API documentation](../../../api/maix/peripheral/pinmap.html)."},"/maixpy/doc/en/pro/compile_os.html":{"title":"Compiling a System for MaixCAM MaixPy","content":" title: Compiling a System for MaixCAM MaixPy ## Why Customize the System? Typically, you can download the latest system for MaixCAM directly from [this link](https://github.com/sipeed/MaixPy/releases). However, there are some scenarios where you might need to customize the system: * For example, if you are mass producing 1,000 products and want each to have your own application that automatically starts on boot, without configuring each one individually, you can modify the `builtin_files` and package a system. Once this system is flashed onto the boards, they will all include your custom files, eliminating the need to copy them again after booting. * If the official system does not include the software packages or drivers you need, you can compile your own system and select the packages you want to include. ## Obtaining the Base System The principle is to use a system from [this link](https://github.com/sipeed/LicheeRV Nano Build/releases) as the base (note that this system cannot be directly flashed onto MaixCAM as it may damage the screen), then copy the MaixCAM specific files into the base system and repackage it into a system usable by MaixCAM. If you don't need to customize the base system, you can directly download the latest system image from [here](https://github.com/sipeed/LicheeRV Nano Build/releases). If the base system doesn't meet your requirements, such as needing to add or remove some software packages and drivers, follow the instructions in the [LicheeRV Nano Build repository](https://github.com/sipeed/LicheeRV Nano Build) README to compile the system. It's recommended to use Docker for compilation to avoid environment issues and to use `bash` instead of `zsh`. Remember, the compiled system should not be flashed directly onto MaixCAM, as it might damage the screen. ## Copying Files for MaixCAM Prepare the following: * The base system, which is a `.img` or `.img.xz` file. * Additional files for MaixCAM can be downloaded from the [MaixPy release page](https://github.com/sipeed/MaixPy/releases). Download the latest `builtin_files.tar.xz`. > If you need to add custom files to the system, you can extract the files and add them to the appropriate directory. For example, if you want a `cat.jpg` file to be in the `/root` directory after flashing, simply place `cat.jpg` in the `root` directory. * Download or clone the MaixPy source code locally. * Compile MaixPy to obtain the `.whl` installation package, or you can download the latest installation package from the [MaixPy release page](https://github.com/sipeed/MaixPy/releases). In the `MaixPy/tools/os` directory, run the following command: ```shell ./gen_os.sh <base_os_filepath> <maixpy_whl_filepath> <builtin_files_dir_path> [skip_build_apps] [device_name] ``` Here’s what each parameter means: * **base_os_filepath**: The path to the base system, in `.img` or `.img.xz` format. * **maixpy_whl_filepath**: The MaixPy package, in `.whl` format. * **builtin_files_dir_path**: The custom files for MaixCAM, which can be downloaded from the MaixPy release page. * **skip_build_apps**: Skip compiling built in applications, optional arg. Set to 1 to skip, no this arg it will compile and copy apps from MaixCDK and MaixPy into the system. * **device name**: Can be `maixcam` or `maixcam pro` Example command: ```shell ./gen_os.sh '/home/xxx/.../LicheeRV Nano Build/install/soc_sg2002_licheervnano_sd/images/2024 08 13 14 43 0de38f.img' ../../dist/MaixPy 4.4.21 py3 none any.whl '/home/xxx/.../sys_builtin_files' 0 maixcam pro ``` After waiting for the built in apps to compile and copy, you should find a `maixcam pro 2024 08 15 maixpy v4.4.21.img.xz` system image in the `MaixPy/tools/os/tmp` directory."},"/maixpy/doc/en/gui/i18n.html":{"title":"MaixPy MaixCAM i18n (Internationalization) Multi-Language Implementation","content":" title: MaixPy MaixCAM i18n (Internationalization) Multi Language Implementation ## Introduction to i18n (Internationalization) i18n is an abbreviation for internationalization, which aims to switch languages according to the user's region or preference. Commonly used languages, such as Chinese and English, have corresponding region codes (LCID). For example, the region code for Chinese is `zh`, English is `en`, and Japanese is `ja`. There are also secondary region codes, like Simplified Chinese corresponding to `zh cn`. Generally, implementing `zh` is sufficient. For region codes, you can refer to [Windows Locale Codes](https://www.science.co.il/language/Locale codes.php) or check [Wikipedia](https://en.wikipedia.org/wiki/Language_localisation). ## Using i18n in MaixPy MaixCAM The general user process is as follows: * Initially, users can select the system language in the system settings, with the factory default being `en` (English). * Then, the program can get the current system locale using `maix.i18n.get_locale()`. * The program displays the corresponding language strings based on the system locale. For applications, the tricky part is the third step, which involves looking up the corresponding strings based on the locale settings. Here are two methods to achieve this, depending on your needs: ### Using a Dictionary Directly Without Translation Files If your program only has a few strings, you can manually specify the translation dictionary: ```python from maix import i18n trans_dict { \"zh\": { \"hello\": \"你好\" }, \"en\": { } } trans i18n.Trans(trans_dict) tr trans.tr trans.set_locale(\"zh\") print(tr(\"hello\")) print(tr(\"my friend\")) ``` Here, `trans.set_locale(\"zh\")` temporarily sets the language to Chinese. Running this will print `你好` and `my friend`, since there is no translation for `my friend`, it returns as is. ### Automatically Scanning and Generating a Dictionary, and Loading from Translation Files This method is more suitable for scenarios with many strings to translate. In the previous method, we manually specified string translations, which is convenient for simple scenarios. However, if there are too many strings, manually editing the dictionary can easily result in omissions. Therefore, we need the program to automatically find the strings that need translation and generate translation files, which we only need to translate. In MaixPy, the `maix.i18n.Trans` class is provided to load translation files in multiple languages. By calling its `tr()` function and passing in the text to be translated, you can get the translation. For example: ```python from maix import i18n, err trans i18n.Trans() tr trans.tr e trans.load(\"locales\") err.check_raise(e, \"load translation yamls failed\") print(tr(\"hello\")) ``` Here, the translation files are loaded from the `locales` folder in the current directory, and the system prints `hello` according to the language settings, such as `你好` for Chinese. **Translation Files**: Since translation files are used here, how are these files created? First, we need to know which text needs translation, which are the strings called by the `tr` function. So we just need to search for all strings that use the `tr` function in the source code to find all the strings that need translation. The usage process is as follows: * Create a project folder to store the code entry `main.py`, and open this project folder with `MaixVision` for easy operation. * Write `main.py`, using the `tr` function to call the strings that need translation. * MaixPy provides a scanning tool. First, make sure `maixtool` is installed (`pip install maixtool U` on the computer terminal to install or upgrade). * Then, in the directory, use the computer terminal to execute `maixtool i18n d . r` to scan for strings that need translation and generate a `locales` directory containing translation files for Chinese and English. For more languages, execute `maixtool i18n h` for help. * The generated files are key value pairs, for example, in `zh.yaml`, `hello: hello` means the Chinese translation of `hello` is `hello`. This is incorrect and needs manual translation, changing `hello: hello` to `hello: 你好`. Make sure to use a text editor that supports `UTF 8` encoding, especially on Windows, avoid changing the file to `GBK` encoding to prevent errors. You can use MaixVision or VsCode for editing. * Then run the project, or package the project into an installation package, remember to include the `locales` directory. * If the source code is updated later, execute the `maixtool` command again to update the files. It will update the previously translated files. If you are worried about accidental overwriting, you can back up the files first and then delete the backup after confirming everything is correct. This way, your program will change the language according to the system settings. You can also manually call `trans.set_locale(\"zh\")` to temporarily switch the language for debugging. ## Displaying Translations on the Interface The previous examples used the `print` function to display translations. If you want to display them on the interface, you need font support. For English, it is supported by default, but for languages with large font libraries like Chinese, it is not supported by default. For example: ```python from maix import i18n, image, display, app, time trans_dict { \"zh\": { \"hello\": \"你好\" }, \"en\": { } } trans i18n.Trans(trans_dict) tr trans.tr trans.set_locale(\"zh\") disp display.Display() img image.Image(disp.width(), disp.height()) img.draw_string(10, 10, tr(\"hello\"), image.COLOR_WHITE, scale 2) disp.show(img) while not app.need_exit(): time.sleep_ms(100) ``` Running this will show a bunch of `?` because there is no Chinese font library. For the `image` module, you can load a font library. The system has a built in Chinese font library, or you can use your own font library: ```python from maix import i18n, image, display, app, time trans_dict { \"zh\": { \"hello\": \"你好\" }, \"en\": { } } trans i18n.Trans(trans_dict) tr trans.tr trans.set_locale(\"zh\") disp display.Display() image.load_font(\"sourcehansans\", \"/maixapp/share/font/SourceHanSansCN Regular.otf\", size 24) image.set_default_font(\"sourcehansans\") img image.Image(disp.width(), disp.height()) img.draw_string(10, 10, tr(\"hello\"), image.COLOR_WHITE, scale 2) disp.show(img) while not app.need_exit(): time.sleep_ms(100) ```"},"/maixpy/doc/en/index.html":{"title":"MaixCAM MaixPy Quick Start","content":" title: MaixCAM MaixPy Quick Start <style> #head_links table { width: 100%; display: table; } @media screen and (max width: 900px){ #head_links th, #head_links td { /* padding: 8px; */ font size: 0.9em; padding: 0.1em 0.05em; } } </style> <div id \"head_links\"> Resource Summary Link : : : : Tutorial Documentation 📖 [wiki.sipeed.com/maixpy/en/](https://wiki.sipeed.com/maixpy/en/) Examples and Source Code <img src \"/static/image/github fill.svg\" style \"height: 1.5em;vertical align: middle;\"> [github.com/sipeed/MaixPy](https://github.com/sipeed/MaixPy) MaixCAM Hardware 📷 [wiki.sipeed.com/maixcam](https://wiki.sipeed.com/maixcam) / [wiki.sipeed.com/maixcam pro](https://wiki.sipeed.com/maixcam pro) API Documentation 📚 [wiki.sipeed.com/maixpy/api/](https://wiki.sipeed.com/maixpy/api/index.html) MaixHub App Store 📦 [maixhub.com/app](https://maixhub.com/app) MaixHub Sharing Square 🎲 [maixhub.com/share](https://maixhub.com/share) </div> <div style \"font size: 1.2em;padding:1em; text align:center; color: white\"> <div style \"padding: 1em 0 0 0\"> <a target \"_blank\" style \"color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em; background color: #c33d45\" href \"https://item.taobao.com/item.htm?id 784724795837\">Taobao(MaixCAM)</a> <a target \"_blank\" style \"color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em; background color: #c33d45\" href \"https://item.taobao.com/item.htm?id 846226367137\">Taobao(MaixCAM Pro)</a> <a target \"_blank\" style \"color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em; background color: #c33d45\" href \"https://www.aliexpress.com/store/911876460\">AliExpress</a> </div> </div> <br> > For an introduction to MaixPy, please see the [MaixPy official website homepage](../../index.html) > Please give the [MaixPy project](https://github.com/sipeed/MaixPy) a Star ⭐️ to encourage us to develop more features if you like MaixPy. ## Before Start * Please **carefully** follow the steps outlined in this document. Do not skip any sections, and compare your actions accordingly. * **Pay close attention** to the table of contents on the left. Be sure to read through the basic sections thoroughly and patiently. * **Before asking questions**, first search the documentation in the left hand table of contents and review the [FAQ](./faq.html). * This document is the `MaixPy v4 Tutorial`. Be mindful not to confuse it with the [MaixPy v1](https://wiki.sipeed.com/soft/maixpy/zh/index.html) (K210 series), and ensure you are referring to the correct documentation. ## Get a MaixCAM Device ![maixcam_pro](../../static/image/maixcam_pro.png) * **MaixCAM**: Purchase the <a href \"https://wiki.sipeed.com/maixcam\" target \"_blank\">MaixCAM</a> development board from the [Sipeed Taobao](https://item.taobao.com/item.htm?id 784724795837) or [Sipeed AliExpress](https://www.aliexpress.com/store/911876460) store. * **MaixCAM Pro**: Purchase the <a href \"https://wiki.sipeed.com/maixcam\" target \"_blank\">MaixCAM</a> development board from the [Sipeed Taobao](https://item.taobao.com/item.htm?id 846226367137) or [Sipeed AliExpress](https://www.aliexpress.com/store/911876460) store. **It is recommended to purchase the bundle with a `TF card`, `camera`, `2.3 inch touchscreen`, `case`, `Type C data cable`, `Type C one to two mini board`, and `4P serial port socket+cable`**, which will be convenient for later use and development. **The following tutorials assume that you already have these accessories** (including the screen). **It is highly recommended to purchase a package that includes a screen, as it greatly enhances the development experience.** If you do not need a screen for actual deployment in a production environment, you can start with a screen included kit for initial development, and then either remove the screen or purchase a screenless version for mass production later on. * **Power Supply**: A stable power supply is crucial. MaixCAM requires a steady `5V 500mA` power supply. Insufficient power can result in failure to boot or crashes during operation. This is especially true for some computer USB ports, which may provide unstable power. * **TF Card Reader**: Used for flashing the system, essential. * **USB to serial port module**: If you want to debug serial communication with PC, it is recommended to prepare one. You can buy any one from Taobao or buy them together at Sipeed store, such as this [dual serial port to USB module](https://item.taobao.com/item.htm?spm a1z10.5 c s.w4002 24984936573.13.73cc59d6AkB9bS&id 610365562537). >! Note that currently only the MaixCAM development board is supported. Other development boards with the same chip are not supported, including Sipeed's development boards with the same chip. Please be careful not to purchase the wrong board, which could result in unnecessary waste of time and money. ## For no screen devies If you use screenless version, please refer to the [Quick Start (Screenless Version)](./README_no_screen.html) document. ## Getting Started ### Prepare the TF Image Card and Insert it into the Device If the package you purchased includes a TF card, it already contains the factory image. If the TF card was not installed in the device at the factory, you will first need to carefully open the case (be careful not to tear the ribbon cables inside) and then insert the TF card. Additionally, since the firmware from the factory may be outdated, it is highly recommended to follow the instructions on [Upgrading and Flashing the System](./basic/os.html) to upgrade the system to the latest version. If you did not purchase a TF card, you need to flash the system onto a self provided TF card. Please refer to [Upgrading and Flashing the System](./basic/os.html) for the flashing method, and then install it on the board. ### Power On Use a `Type C` data cable to connect the `MaixCAM` device and power it on. Wait for the device to boot up and enter the function selection interface. ![maixcam_font](../../static/image/maixcam_font.png) If the screen does not display: * Please confirm that you purchased the bundled TF card. If you confirm that you have a TF card and it is inserted into the device, you can try [updating to the latest system](./basic/os.html). * If you did not purchase the TF card bundle, you need to follow the instructions in [Upgrading and Flashing the System](./basic/os.html) to flash the latest system onto the TF card. * Also, ensure that the screen and camera cables are not loose. The screen cable can easily come off when opening the case, so be careful. ### Connect to the Network For the first run, you need to connect to the network, as you will need it later to activate the device and use the IDE. If you don't have a router, you can use your phone to open a hotspot. Click `Settings` on the device and select `WiFi`. There are two ways to connect to the `WiFi` hotspot: * Scan the WiFi sharing code: * Use your phone to share the `WiFi` hotspot QR code, or go to [maixhub.com/wifi](https://maixhub.com/wifi) to generate a QR code. * Click the `Scan QR code` button, the camera screen will appear, scan the QR code generated previously to connect. * Search for hotspots: * Click the `Scan` button to start scanning the surrounding `WiFi`, you can click multiple times to refresh the list. * Find your WiFi hotspot. * Enter the password and click the `Connect` button to connect. Then wait for the `IP` address to be obtained, which may take `10` to `30` seconds. If the interface does not refresh, you can exit the `WiFi` function and re enter to view it, or you can also see the `IP` information in `Settings` > `Device Information`. ### Update the Runtime Libraries **This step is very important!!!** If this step is not done properly, other applications and functions may not work (e.g., they may crash). * First, ensure that you have completed the previous step of connecting to WiFi and have obtained an IP address to access the internet. * On the device, click `Settings`, and select `Install Runtime Libraries`. * After the installation is complete, you will see that it has been updated to the latest version. Then exit. If it shows `Request failed` or `请求失败` (Request failed), please first check if the network is connected. You need to be able to connect to the internet. If it still doesn't work, please take a photo and contact customer service for assistance. ### Use Built in Applications Many applications are built in, such as Find Blobs, AI Detector, Line Follower, etc. For example, Find Blobs: <video playsinline controls autoplay loop muted preload class \"pl 6 pb 4 self end\" src \"/static/video/self_learn_tracker.mp4\" type \"video/mp4\"> Classifier Result video </video> Please explore other applications on your own. More applications will be updated in the future. For usage documentation and application updates, please see the [MaixHub App Store](https://maixhub.com/app). **Note: The applications only include a part of the functionality that MaixPy can achieve. Using MaixPy, you can create even more features.** ## Use as a Serial Module > If you want to use the device as the main controller (or if you don't understand what a serial module is), you can skip this step. The built in applications can be used directly as serial modules, such as `Find Blobs`, `Find Faces`, `Find QR Codes`, etc. Note that the serial port can only directly connect to other microcontrollers. **If you want to communicate with a computer via a serial port, you must provide a USB to serial module yourself.** Usage: * Hardware connection: You can connect the device to the `Type C one to two mini board`(For MaixCAM Pro is 6Pin interface), which allows you to connect the device via serial to your main controller, such as `Arduino`, `Raspberry Pi`, `STM32`, etc. * Open the application you want to use, such as QR code recognition. When the device scans a QR code, it will send the result to your main controller via serial. > The serial baud rate is `115200`, the data format is `8N1`, and the protocol follows the [Maix Serial Communication Protocol Standard](https://github.com/sipeed/MaixCDK/blob/master/docs/doc/convention/protocol.md). You can find the corresponding application introduction on the [MaixHub APP](https://maixhub.com/app) to view the protocol. > If APP no serial output, you can also do it by yourself, follow function examples and [UART usage doc](./peripheral/uart.html) to add function and serial output. ## Preparing to Connect Computer and Device To enable communication between the computer (PC) and the device (MaixCAM), we need to ensure they are on the same local area network. There are two methods to achieve this: * **Method 1 (Highly Recommended)**: Wireless Connection. Connect the device to the same router or Wi Fi hotspot that the computer is connected to via Wi Fi. Go to the device's `Settings > WiFi Settings` and connect to your Wi Fi. (If you experience **screen lag or high latency** with Wi Fi, you can try Method 2 for a wired connection.) Here is the translation: * **Method Two**: Wired Connection. The device connects to the computer via a USB cable, and the device will emulate as a USB network adapter. This way, the device and the computer will be on the same local network through the USB connection. It is recommended to start with WiFi because although a wired connection offers stable transmission, it may encounter issues such as faulty cables, poor connection, or driver problems. If you encounter any issues, you can refer to the common problems in the [FAQ](./faq.html). .. details::Method Two: Driver Installation on Different Computer Systems: :open: true By default, there are two types of USB virtual network adapter drivers (NCM and RNDIS drivers) to meet the needs of different systems. You can also disable the unused virtual network adapter on the device under `Settings` > `USB Settings`: * **Windows**: All Windows systems will automatically install the RNDIS driver, while only Windows 11 will automatically install the NCM driver. As long as **one of the drivers works**, it is sufficient. * Open Task Manager > Performance, and you should see a virtual Ethernet with an IP address such as `10.131.167.100`, which is the computer's IP address. The device's IP address is the same but with the last digit changed to `1`, i.e., `10.131.167.1`. If you are using Windows 11, you will see two virtual network adapters; you can use either IP address. * Additionally, you can open `Device Manager` (search for `Device Manager` in the search bar). The RNDIS and NCM drivers should be correctly installed, as shown below: ![RNDIS ok](../../static/image/windows_rndis_ok.png) ![NCM ok](../../static/image/windows_ncm_ok.png) * **Linux**: No additional setup is required. Simply plug in the USB cable. Use `ifconfig` or `ip addr` to see the `usb0` and `usb1` network interfaces, and either IP address can be used. **Note**: The IP address you see, such as `10.131.167.100`, is the computer's IP address, and the device's IP address is the same but with the last digit changed to `1`, i.e., `10.131.167.1`. * **MacOS**: Check for the `usb` network adapter under `System Settings` > `Network`. **Note**: The IP address you see, such as `10.131.167.100`, is the computer's IP address, and the device's IP address is the same but with the last digit changed to `1`, i.e., `10.131.167.1`. ## Preparing the Development Environment * First, ensure that the computer and the device are on the same local network as per the previous step. * Download and install [MaixVision](https://wiki.sipeed.com/maixvision). * Connect the device and the computer using a Type C cable. Open MaixVision, click the `“Connect”` button in the lower left corner, and it will automatically search for the device. Wait for a moment until the device appears, then click the connection button next to the device to connect. If **no device is detected**, you can also manually enter the device's IP address in the **device**'s `Settings > Device Info`. You can also find solutions in the [FAQ](./faq.html). **After a successful connection, the function selection interface on the device will disappear, and the screen will turn black, releasing all hardware resources. If there is still an image displayed, you can disconnect and reconnect.** Here is a video example of using MaixVision: <video style \"width:100%\" controls muted preload src \"/static/video/maixvision.mp4\"></video> ## Run Examples Click `Example Code` on the left side of MaixVision, select an example, and click the `Run` button in the bottom left to send the code to the device for execution. For example: * `hello_maix.py`: Click the `Run` button, and you will see messages printed from the device in the MaixVision terminal, as well as an image in the upper right corner. * `camera_display.py`: This example will open the camera and display the camera view on the screen. ```python from maix import camera, display, app disp display.Display() # Construct a display object and initialize the screen cam camera.Camera(640, 480) # Construct a camera object, manually set the resolution to 640x480, and initialize the camera while not app.need_exit(): # Keep looping until the program exits (you can exit by pressing the function key on the device or clicking the stop button in MaixVision) img cam.read() # Read the camera view and save it to the variable img, you can print(img) to print the details of img disp.show(img) # Display img on the screen ``` * `yolov5.py` will detect objects in the camera view, draw bounding boxes around them, and display them on the screen. It supports detection of 80 object types. For more details, please see [YOLOv5 Object Detection](./vision/yolov5.html). You can try other examples on your own. > If you encounter image display stuttering when using the camera examples, it may be due to poor network connectivity, or the quality of the USB cable or the host's USB being too poor. You can try changing the connection method or replacing the cable, host USB port, or computer. ## Install Applications on the Device The above examples run code on the device, but the code will stop running when `MaixVision` is disconnected. If you want the code to appear in the boot menu, you can package it as an application and install it on the device. Click the `Install App` button in the bottom left corner of `MaixVision`, fill in the application information, and the application will be installed on the device. Then you will be able to see the application on the device. You can also choose to package the application and share your application to the [MaixHub App Store](https://maixhub.com/app). > The default examples do not explicitly write an exit function, so you can exit the application by pressing the function key on the device. (For MaixCAM, it is the user key.) If you want the program to start automatically on boot, you can set it in `Settings > Boot Startup`. More MaixVision usage refer to [MaixVision documentation](./basic/maixvision.html)。 ## Next Steps If you like what you've seen so far, **please be sure to give the MaixPy open source project a star on [GitHub](https://github.com/sipeed/MaixPy) (you need to log in to GitHub first). Your star and recognition is the motivation for us to continue maintaining and adding new features!** Up to this point, you've experienced the usage and development workflow. Next, you can learn about `MaixPy` syntax and related features. Please follow the left sidebar to learn. If you have any questions about using the API, you can look it up in the [API documentation](/api/). It's best to learn with a specific purpose in mind, such as working on an interesting small project. This way, the learning effect will be better. You can share your projects and experiences on the [MaixHub Share Plaza](https://maixhub.com/share) and receive cash rewards! ## Frequently Asked Questions (FAQ) If you encounter any problems, please check the [FAQ](./faq.html) first. If you cannot find a solution there, you can ask in the forums or groups below, or submit a source code issue on [MaixPy issue](https://github.com/sipeed/MaixPy/issues). ## Share and Discuss * **[MaixHub Project and Experience Sharing](https://maixhub.com/share)**: Share your projects and experiences, and receive cash rewards. The basic requirements for receiving official rewards are: * **Reproducible**: A relatively complete process for reproducing the project. * **Showcase**: No detailed project reproduction process, but an attractive project demonstration. * **Bug solving experience**: Sharing the process and specific solution for resolving a particular issue. * [MaixPy Official Forum](https://maixhub.com/discussion/maixpy) (for asking questions and discussion) * Telegram: [MaixPy](https://t.me/maixpy) * MaixPy Source Code Issues: [MaixPy issue](https://github.com/sipeed/MaixPy/issues) * For business cooperation or bulk purchases, please contact support@sipeed.com."},"/maixpy/doc/en/network/socket.html":{"title":"Using Socket for TCP/UDP Communication with MaixPy MaixCAM","content":" title: Using Socket for TCP/UDP Communication with MaixPy MaixCAM ## Introduction to Sockets Sockets are software abstractions for TCP/UDP communication. Through socket interfaces, we can perform TCP/UDP communication. Since MaixPy is based on Python, we can directly use the built in `socket` library for communication. For more documentation and tutorials, please search online. Here, we introduce simple usage methods. With these example codes, you can perform basic TCP and UDP communication on MaixPy MaixCAM. Remember to modify the IP address and port number according to your actual situation. ## Socket TCP Client This example requests a TCP server, sends a message, waits for a response, and then closes the connection. ```python import socket def tcp_client(ip, port): client_socket socket.socket(socket.AF_INET, socket.SOCK_STREAM) server_address (ip, port) client_socket.connect(server_address) try: # Send data to the server message 'Hello, Server!' print(\"Send:\", message) client_socket.sendall(message.encode('utf 8')) # Receive the server's response data client_socket.recv(1024) print('Received:', data.decode('utf 8')) finally: # Close the connection client_socket.close() if __name__ \"__main__\": tcp_client(\"10.228.104.1\", 8080) ``` ## Socket TCP Server This example creates a socket server that continuously waits for client connections. Once a client connects, a thread is created to communicate with the client, reading the client's message and echoing it back. ```python import socket import threading local_ip \"0.0.0.0\" local_port 8080 def receiveThread(conn, addr): while True: print('Reading...') client_data conn.recv(1024) if not client_data: break print(client_data) conn.sendall(client_data) print(f\"Client {addr} disconnected\") ip_port (local_ip, local_port) sk socket.socket(socket.AF_INET, socket.SOCK_STREAM) sk.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sk.bind(ip_port) sk.listen(50) print(\"Waiting for clients...\") while True: conn, addr sk.accept() print(f\"Client {addr} connected\") # Create a new thread to communicate with this client t threading.Thread(target receiveThread, args (conn, addr)) t.daemon True t.start() ``` ## Socket UDP Client ```python import socket def udp_send(ip, port): # Create a socket object udp_socket socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # Define the server's IP address and port number server_address (ip, port) try: # Send data to the server message 'Hello, Server!' udp_socket.sendto(message.encode('utf 8'), server_address) finally: # Close the connection udp_socket.close() # Call the function udp_send(\"10.228.104.1\", 8080) ``` ## Socket UDP Server ```python import socket def udp_receive(ip, port): # Create a socket object udp_socket socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # Define the server's IP address and port number server_address (ip, port) # Bind the port udp_socket.bind(server_address) print('Waiting for a message...') while True: data, address udp_socket.recvfrom(1024) print('Received:', data.decode('utf 8')) print('From:', address) # Close the connection udp_socket.close() # Call the function udp_receive('0.0.0.0', 8080) ```"},"/maixpy/doc/en/network/websocket.html":{"title":"Using WebSocket with MaixPy MaixCAM","content":" title: Using WebSocket with MaixPy MaixCAM ## Introduction Similar to sockets, WebSocket enables long lived communication connections and supports communication with web pages. Since MaixPy is based on Python, you can use the commonly available Python `websockets` and `asyncio` modules. For more detailed information, please refer to the documentation and tutorials available online. ## WebSocket Client The following example connects to a server, sends a message 10 times, and then ends the connection: ```python import asyncio import websockets import time async def send_msg(websocket): count 1 while count < 10: msg f\"hello {count}\" await websocket.send(msg) recv_text await websocket.recv() print(f\"Received: {recv_text}\", end \"\\n\") count + 1 time.sleep(1) await websocket.close(reason \"client exit\") async def main_logic(ip, port): async with websockets.connect(f'ws://{ip}:{port}') as websocket: await send_msg(websocket) ip \"10.228.104.100\" port 5678 asyncio.get_event_loop().run_until_complete(main_logic(ip, port)) ``` ## WebSocket Server The following example accepts client connections and responds with `ack for msg:` followed by the received message. ```python import asyncio import websockets import functools async def recv_msg(websocket): print(\"New client connected, recv_msg start\") while True: try: recv_text await websocket.recv() except Exception as e: print(\"Receive failed\") break print(\"Received:\", recv_text) response_text f\"ack for msg: {recv_text}\" await websocket.send(response_text) print(\"recv_msg end\") async def main_logic(websocket, path, other_param): await recv_msg(websocket) ip \"0.0.0.0\" port 5678 start_server websockets.serve(functools.partial(main_logic, other_param \"test_value\"), ip, port) print(\"Start server\") asyncio.get_event_loop().run_until_complete(start_server) print(\"Start server loop\") asyncio.get_event_loop().run_forever() ```"},"/maixpy/doc/en/network/flask.html":{"title":"Using Flask to Build an HTTP Web Server with MaixPy MaixCAM","content":" title: Using Flask to Build an HTTP Web Server with MaixPy MaixCAM ## Introduction MaixPy is based on Python, so you can use the Python library Flask to quickly set up a web server. As it is a common Python library, you can find specific uses and methods online, so they won't be elaborated on here. If you only want to create a page that displays camera images, you can also refer to the HTTP image server method in [JPEG Streaming](../video/jpeg_streaming.html). ## Simple HTTP Service Example After running the following program, accessing `http://device_ip:8000` in a computer browser will display the \"hello world\" text and an image. ```python from flask import Flask, request, send_file import maix # we not use it but we import it to listen for key events to exit this program app Flask(__name__) @app.route(\"/\", methods [\"GET\", \"POST\"]) def root(): print(\" \") print(request.remote_addr) print(f'headers:\\n{request.headers}') print(f'data: {request.data}') print(\" \") return 'hello world<br><img src \"/img\" style \"background color: black\">' @app.route(\"/<path:path>\") def hello(path): print(path) print(f'headers:\\n{request.headers}') print(f'data: {request.data}') print(\" \\n\\n\") return f\"hello from {path}\" @app.route(\"/img\") def img(): return send_file(\"/maixapp/share/icon/detector.png\") if __name__ \"__main__\": app.run(host \"0.0.0.0\", port 8000) ```"},"/maixpy/doc/en/network/network_settings.html":{"title":"Network Settings for MaixPy MaixCAM WiFi Configuration","content":" title: Network Settings for MaixPy MaixCAM WiFi Configuration ## Introduction To enable MaixCAM to use the network, it first needs to connect to the network via WiFi. MaixCAM provides several methods to connect to a WiFi hotspot. ## Using the Built in Settings Application After powering on, enter the `Settings` application and select the `WiFi` function. You can connect by sharing a `WiFi QR code` from your phone or by generating a QR code at [maixhub.com/wifi](https://maixhub.com/wifi) and scanning it. Alternatively, you can manually scan for `WiFi` hotspots and enter the password to connect. Once connected successfully and the DHCP assigns an IP address, the IP will be displayed on the screen. ## Connecting via MaixPy ```python from maix import network, err w network.wifi.Wifi() print(\"IP:\", w.get_ip()) SSID \"Sipeed_Guest\" PASSWORD \"qwert123\" print(\"Connecting to\", SSID) e w.connect(SSID, PASSWORD, wait True, timeout 60) err.check_raise(e, \"Failed to connect to WiFi\") print(\"IP:\", w.get_ip()) ``` ## DNS Server Configuration In practice, some users may find that their router's DNS resolution cannot resolve certain domain names. Therefore, the default system sets the DNS servers in the `/boot/resolv.conf` file: ```shell nameserver 114.114.114.114 # China nameserver 223.5.5.5 # Aliyun China nameserver 8.8.4.4 # Google nameserver 8.8.8.8 # Google nameserver 223.6.6.6 # Aliyun China ``` Generally, there is no need to modify this file. If you encounter DNS resolution issues, you can modify this file. The actual configuration file used by the system is located at `/etc/resolv.conf`. This file is automatically copied from `/boot/resolv.conf` at startup. Therefore, the simplest solution after modification is to reboot. If you prefer not to reboot, you need to modify both files simultaneously."},"/maixpy/doc/en/network/mqtt.html":{"title":"Using MQTT with MaixPy MaixCAM for Message Subscription and Publishing","content":" title: Using MQTT with MaixPy MaixCAM for Message Subscription and Publishing ## MQTT Introduction MQTT allows for quick and easy real time communication using a publish subscribe model. System components: * **MQTT Server (broker):** Responsible for forwarding messages. * **MQTT Clients:** Subscribe to topics from the server, receive messages, and publish messages to specific topics on the server. Communication process: * Clients connect to the MQTT server. * Clients subscribe to topics they are interested in, such as `topic1`. * When other clients or the server publish information on the `topic1` topic, it is pushed to the subscribing clients in real time. * Clients can also actively publish messages to specific topics. All clients subscribed to that topic will receive the messages. For example, if a client publishes a message to `topic1`, all clients subscribed to `topic1` will receive it, including the publishing client itself. ## Using MQTT in MaixPy MaixCAM The `paho mqtt` module can be used for this purpose. You can look up the usage of `paho mqtt` online or refer to the examples in the [MaixPy/examples](https://github.com/sipeed/MaixPy/tree/main/examples/network) repository. If you are using an older system, you might need to manually install the `paho mqtt` package. Installation instructions can be found in the [Adding Extra Python Packages](../basic/python_pkgs.html) guide."},"/maixpy/doc/en/network/http.html":{"title":"Using HTTP Network Communication with MaixPy MaixCAM","content":" title: Using HTTP Network Communication with MaixPy MaixCAM ## Introduction HTTP is an application layer network protocol based on TCP. Through it, we can send and receive information to and from network servers, such as retrieving webpage content from a web server. For more information, you can search for HTTP. ## Using HTTP Requests in MaixPy Since MaixPy is based on Python, you can directly use the built in `requests` library. The `requests` library is a very robust and user friendly library, so it won't be elaborated on here. Please search for related documentation and tutorials for more information. Here is an example of fetching the homepage content of `https://example.com`. ```python import requests url 'https://example.com' response requests.get(url) print(\"Response:\") print(\" status code:\", response.status_code) print(\"\") print(\" headers:\", response.headers) print(\"\") print(\" content:\", response.content) print(\"\") print(\" text:\", response.text) print(\"\") ```"},"/maixpy/doc/en/video/record.html":{"title":"MaixCAM MaixPy Video Record","content":" title: MaixCAM MaixPy Video Record update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: Initial document ## Introduction This document provides instructions on how to use the video recording feature ## Example 1 An example of recording a video in `h265` format. ```python from maix import video, image, camera, app, time cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) e video.Encoder() f open('/root/output.h265', 'wb') record_ms 2000 start_ms time.ticks_ms() while not app.need_exit(): img cam.read() frame e.encode(img) print(frame.size()) f.write(frame.to_bytes()) if time.ticks_ms() start_ms > record_ms: app.set_exit_flag(True) ``` 步骤： 1. import module and Initialize the camera ```python from maix import video, image, camera, app, time cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) ``` `camera.Camera()` is used to initialise the camera, here the camera resolution is initialised to `640x480`, currently the `Encoder` only supports the `NV21` format, so set the image format to `image.Format.FMT_YVU420SP`. 2. Initialise the `Encoder` module ```python e video.Encoder() ``` The `video.Encoder()` module currently only supports processing `image.Format.FMT_YVU420SP` format images, which supports `h265` and `h264` encoding, and defaults to `h265` encoding. If you want to use `h264` encoding, then you can change the initialisation parameter to ` video.Encoder(type video.VideoType.VIDEO_H264_CBR)`. Note that only one encoder can exist at the same time 3. Encoding the camera image ```python img cam.read() frame e.encode(img) ``` `img cam.read()` read camera image and save to `img` `frame e.encode(img)` encode `img` and save result to `frame` 4. Save the encoded result to file ```python f open('/root/output.h265', 'wb') f.write(frame.to_bytes(False)) ``` `f open(xxx)` opens and creates a file `f.write(frame.to_bytes(False))` converts the encoding result `frame` to type `bytes` and then calls `f.write()` to write the data to the file 5. Timed 2s exit ```python record_ms 2000 start_ms time.ticks_ms() while not app.need_exit(): if time.ticks_ms() start_ms > record_ms: app.set_exit_flag(True) ``` Here is the application logic for the timed exit, see the code for yourself 6. Done ## Example 2 An example of recording a video in `h265` format. ```python from maix import video, time, image, camera, app cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) e video.Encoder(capture True) e.bind_camera(cam) f open('/root/output.h265', 'wb') record_ms 2000 start_ms time.ticks_ms() while not app.need_exit(): frame e.encode() img e.capture() print(frame.size()) f.write(frame.to_bytes(True)) if time.ticks_ms() start_ms > record_ms: app.set_exit_flag(True) ``` Similar to example 1, the difference is that the `Encoder` object's `bind_camera` method is called, and the `Encoder` takes the initiative to get the camera image, which has the advantage of using the hardware features to increase the encoding speed. ``` e video.Encoder(capture True) e.bind_camera(cam) frame e.encode() img e.capture() ``` `e video.Encoder(capture True)` enables the `capture` parameter to allow encoding to capture encoded images when encoding `e.bind_camera(cam)` binds the camera to the `Encoder` object `frame e.encode()` Instead of passing in `img` when encoding, fetch the image from the camera internally `img e.capture()` captures the encoded image from the `Encoder` object, which can be used for image processing ## Convert to MP4 format If you want to record video in `mp4` format, you can record `H265` video first, and then use the `ffmpeg` tool in the system to convert to `mp4` format. ```python import os # Pack h265 to mp4 # /root/output.h265 is the h265 file path # /root/output.mp4 is the mp4 file path os.system('ffmpeg loglevel quiet i /root/output.h265 c:v copy c:a copy /root/output.mp4 y') ```"},"/maixpy/doc/en/video/rtsp_streaming.html":{"title":"MaixCAM MaixPy Video Streaming RTSP Push Streaming","content":" title: MaixCAM MaixPy Video Streaming RTSP Push Streaming update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: Initial documentation ## Introduction This document provides methods for pushing streaming camera image via RTSP ## How to use ```python from maix import time, rtsp, camera, image server rtsp.Rtsp() cam camera.Camera(2560, 1440, image.Format.FMT_YVU420SP) server.bind_camera(cam) server.start() print(server.get_url()) while True: time.sleep(1) ``` Steps: 1. Import the image、camera、image and rtsp modules: ```python from maix import time, rtsp, camera, image ``` 2. Initialize the camera: ```python cam camera.Camera(2560, 1440, image.Format.FMT_YVU420SP) # Initialise camera, output resolution 2560x1440 NV21 format ``` Note that the RTSP module currently only supports the NV21 format, so the camera needs to be configured to output in NV21 format. 3. Initialise and start the Rtsp object ```python server rtsp.Rtsp() server.bind_camera(cam) server.start() ``` ``server rtsp.Rtsp()`` used to create an ``Rtsp`` object `server.bind_camera(cam)` is used to bind a `Camera` object, after which the original `Camera` object can no longer be used. `server.start()` is used to start the `rtsp` push stream. 4. Print the URL of the current RTSP stream ``python print(server.get_url()) `` ``server.get_url()`` is used to get the ``playback address`` of ``RTSP``. 6. Finished, after running the above code, you can play the video stream through [VLC](https://www.videolan.org/vlc/) software, the tested version of `VLC` is `3.0.20`. The default playback address is `rtsp://device ip:8554/live`. ## OSD Drawing lines and frames via OSD TODO"},"/maixpy/doc/en/video/play.html":{"title":"MaixPy Playback Video","content":" title: MaixPy Playback Video update: date: 2024 08 19 author: lxowalle version: 1.0.0 content: Initial document ## Introduction This document provides instructions for using the Play Video feature. `MaixPy` supports playing `h264`, `mp4` and `flv` video formats, note that currently only `avc` encoded `mp4` and `flv` files are supported. ## Play `MP4` video An example of playing an `mp4` video, the path to the video file is `/root/output.mp4`. ```python from maix import video, display, app disp display.Display() d video.Decoder('/root/output.mp4') print(f'resolution: {d.width()}x{d.height()} bitrate: {d.bitrate()} fps: {d.fps()}') d.seek(0) while not app.need_exit(): ctx d.decode_video() if not ctx: d.seek(0) continue img ctx.image() disp.show(img) print(f'need wait : {ctx.duration_us()} us') ``` Steps: 1. Import the module and initialise the camera ```python from maix import video, display, app disp display.Display() ``` `disp display.Display()` is used to initialise the display to show the decoded image 2. Initialise the `Decoder` module ```python d video.Decoder('/root/output.mp4') ``` `d video.Decoder(‘/root/output.mp4’)` is used to initialise the decoder and set the path to the video file that needs to be played. If you need to play `flv` files, you can fill in the path of the file with `flv` suffix, such as `{your_file_path}.flv`, if you need to play `h264` files, you can fill in the path of the file with `h264` suffix, such as `{your_file_path}.h264` 3. Set the decoding location ```python d.seek(0) ``` can be used to set the position of the video to be played, in seconds. 4. Get the decoded image ```python ctx d.decode_video() img ctx.image() ``` Each call returns a frame context, and you can obtain img through `ctx.image()`. Currently the decoded output only supports the NV21 format. 5. Display the decoded image ```python disp.show(img) ``` When displaying images, `ctx.duration_us()` can be used to get the duration of each frame in microseconds. 6. Done, see [API documentation](https://wiki.sipeed.com/maixpy/api/maix/video.html) for more usage of `Decoder`."},"/maixpy/doc/en/video/rtmp_streaming.html":{"title":"MaixCAM MaixPy Video Streaming RTMP Push Streaming","content":" title: MaixCAM MaixPy Video Streaming RTMP Push Streaming update: date: 2024 05 31 author: lxowalle version: 1.0.0 content: initial document ## Introduction This document provides methods for pushing H264 video streams via RTMP ## How to use The following example shows pushing an h264 video stream to `rtmp://192.168.0.30:1935/live/stream` ```python from maix import camera, time, rtmp, image cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) # rtmp://192.168.0.30:1935/live/stream host '192.168.0.30' port 1935 app 'live' stream 'stream' bitrate 1000_000 r rtmp.Rtmp(host, port, app, stream, bitrate) r.bind_camera(cam) r.start() while True: time.sleep(1) ``` Steps: 1. Import the camera、rtmp、time and image modules: ```python from maix import camera, time, rtmp, image ``` 2. Initialize the camera: ```python cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) # Initialise camera, output resolution 640x480 NV21 format ``` Note that the RTMP module currently only supports the NV21 format, so the camera needs to be configured to output in NV21 format. 3. Initialise and start the Rtmp object ```python r rtmp.Rtmp(host, port, app, stream, bitrate) r.bind_camera(cam) r.start() ``` `r rtmp.Rtmp(host, port, app, stream, bitrate)` is used to create an `Rtmp` object, where `host` refers to the ip address or domain of the rtmp server, `app` refers to the name of the application that is open to the rtmp server, and `stream` refers to the name of the rtmp stream, which can also be used as the key for pushing the stream `r.bind_camera(cam)` is used to bind a `Camera` object, the original `Camera` object can not be used after binding. `r.start()` is used to start the `rtmp` stream. 4. Done ## Push streaming test to Bilibili ### Launch bilibili live stream 1. Click on Live Streaming ![](../../../static/image/bilibili_click_live.png) 2. Click on Live Streaming Settings ![](../../../static/image/bilibili_click_live_setting.png) 3. Find the live streaming address ![](../../../static/image/bilibili_check_live_link.png) 4. Scroll down, select a category, and click Start Live! ![](../../../static/image/bilibili_live_start.png) 5. Get the push stream address ![](../../../static/image/bilibili_check_rtmp_url.png) server address: `rtmp://live push.bilivideo.com/live bvc` key：`?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1` Push stream address: `rtmp://live push.bilivideo.com/live bvc/?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1` ### Run the RTMP client ```python from maix import camera, time, rtmp, image cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) # rtmp://live push.bilivideo.com/live bvc/?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1 host 'live push.bilivideo.com' port 1935 app 'live bvc' stream '?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1' bitrate 1000_000 r rtmp.Rtmp(host, port, app, stream, bitrate) r.bind_camera(cam) r.start() while True: time.sleep(1) ``` Above get bilibili's push stream address as `rtmp://live push.bilivideo.com/live bvc/?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1` Can be detached: 1. server address is `live push.bilivideo.com` 2. port is `1935`, if there is no port number, the default is `1935` 3. application name is `live bvc` 4. stream name is `?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1` Run the code and you will be able to see the `maixcam` screen in the live stream, if you find that the live stream is not displayed, try to close the live stream first, then reopen it and run the code again. Try it~!"},"/maixpy/doc/en/video/jpeg_streaming.html":{"title":"MaixCAM MaixPy Video Stream JPEG Streaming / Sending Images to Server","content":" title: MaixCAM MaixPy Video Stream JPEG Streaming / Sending Images to Server update: date: 2024 04 03 author: neucrack version: 1.0.0 content: Initial document date: 2024 05 20 author: lxowalle version: 1.0.1 content: update JPEG HTTP usage ## Introduction Sometimes it is necessary to send images to a server, or to push video from a webcam to a server, so here are two ways to do it. One of the simplest methods is to compress images into `JPEG` format and send them one by one to the server. Note, this is a very basic method and not a formal way to stream video. It is also not suitable for high resolution, high frame rate video streams, as it involves sending images one by one. For more efficient video streaming, please use the `RTSP` or `RTMP` modules discussed later. Set up an HTTP server, so that the PC side can be accessed directly through the browser. ## Methods for pushing streams as a client ```python from maix import image import requests # create image img image.Image(640, 480, image.Format.FMT_RGB) # draw something img.draw_rect(60, 60, 80, 80, image.Color.from_rgb(255, 0, 0)) # convert to jpeg jpeg img.to_format(image.Format.FMT_JPEG) # image.Format.FMT_PNG # get jpeg bytes jpeg_bytes jpeg.to_bytes() # faster way, borrow memory from jpeg object, # but be careful, when jpeg object is deleted, jpeg_bytes object MUST NOT be used, or program will crash # jpeg_bytes jpeg.to_bytes(copy False) # send image binary bytes to server url \"http://192.168.0.123:8080/upload\" res requests.post(url, data jpeg_bytes) print(res.status_code) print(res.text) ``` As you can see, the image is first converted into `JPEG` format, and then the binary data of the `JPEG` image is sent to the server via `TCP`. ## Methods for pushing streams as a server ```python from maix import camera, time, app, http html \"\"\"<!DOCTYPE html> <html> <head> <title>JPG Stream</title> </head> <body> <h1>MaixPy JPG Stream</h1> <img src \"/stream\" alt \"Stream\"> </body> </html>\"\"\" cam camera.Camera(320, 240) stream http.JpegStreamer() stream.set_html(html) stream.start() print(\"http://{}:{}\".format(stream.host(), stream.port())) while not app.need_exit(): t time.ticks_ms() img cam.read() jpg img.to_jpeg() stream.write(jpg) print(f\"time: {time.ticks_ms() t}ms, fps: {1000 / (time.ticks_ms() t)}\") ``` Steps: 1. Import the image, camera and http modules: ```python from maix import image, camera, http ``` 2. Initialize the camera: ```python cam camera.Camera(320, 240) ``` 3. Initialize Stream Object ```python stream http.JpegStreamer() stream.start() ``` `http.JpegStreamer()` is used to create a `JpegStreamer` object, which will start an `http server` that will be used to publish `jpeg` image streams to clients. `stream.start()` is used to start the `http server`. 4. Custom html styles (optional) ```python html \"\"\"<!DOCTYPE html> <html> <head> <title>JPG Stream</title> </head> <body> <h1>MaixPy JPG Stream</h1> <img src \"/stream\" alt \"Stream\"> </body> </html>\"\"\" stream.set_html(html) ``` `html xxx` is the `html` code that can be used to customise the style of your web page. Note that the core code is `<img src ‘/stream’ alt ‘Stream’>`, be sure not to miss this line of code. `stream.set_html(html)` is used to set the custom `html` code, this step is optional. The default browsing address is `http://device_ip:8000`. 5. Getting images from the camera and pushing streams ```python while 1: img cam.read() jpg img.to_jpeg() stream.write(jpg) ``` `img cam.read()` gets an image from the camera, when initialised as `cam camera.Camera(320, 240)` the `img` object is an RGB image with a resolution of 320x240. `jpg img.to_jpeg()` converts the image to `jpeg` format `stream.write(jpg)` writes the image format to the server and the `http` server will send this image to the `http` client. 6. 6. Done, after running the code above, you can see the video stream directly through your browser, the default address is `http://device_ip:8000`. Open your browser and take a look!"},"/maixpy/doc/en/faq.html":{"title":"MaixCAM MaixPy FAQ (Frequently Asked Questions)","content":" title: MaixCAM MaixPy FAQ (Frequently Asked Questions) >! This page lists common questions and solutions related to MaixPy. If you encounter any issues, please search for answers here first. > Additionally, there are other resources: > * [MaixHub Discussion Forum](https://maixhub.com/discussion): A platform for discussions, with support for tip rewards. > * [MaixPy Issues](https://github.com/sipeed/MaixPy/issues?q ): For source code related issues. > * [MaixCAM Hardware FAQ](https://wiki.sipeed.com/hardware/zh/maixcam/faq.html): Frequently asked questions about MaixCAM hardware. ## MaixVision cannot find the device? First, confirm whether the connection method is WiFi or USB cable. **WiFi**: * Ensure that WiFi is correctly connected and has obtained an IP address. You can view the `ip` in `Settings > Device Info` or `Settings > WiFi`. **USB Cable**: * Ensure that the device is connected to the computer via a Type C data cable, and the device is powered on and has entered the function selection interface. * Ensure that the device driver is installed: * On Windows, check if there is a USB virtual network adapter device in `Device Manager`. If there is an exclamation mark, it means the driver is not installed properly. Follow the instructions in [Quick Start](./index.html) to install the driver. * On Linux, you can check if there is a `usb0` device by running `ifconfig` or `ip addr`, or check all USB devices with `lsusb`. Linux already includes the driver, so if the device is not recognized, check the hardware connection, ensure the device system is up to date, and ensure the device has booted up properly. * On macOS, follow the same steps as Linux. * Additionally, check the quality of the USB cable and try using a high quality cable. * Additionally, check the quality of the computer's USB port. For example, some small form factor PCs have poor EMI design on their USB ports, and connecting a good quality USB hub may allow the device to work. You can also try a different USB port or a different computer. ## MaixVision camera example shows choppy video The default GC4653 camera has a maximum frame rate of 30 frames per second (FPS). Under normal circumstances, the MaixVision display should not appear choppy to the naked eye. If choppiness occurs, first consider transmission issues: * Check the network connection quality, such as WiFi. * If using a USB connection, check the USB cable quality, computer USB port quality, and try using a different computer, USB port, or USB cable for comparison. ## What is the difference between MaixPy v4 and v1/v3? * MaixPy v4 uses the Python language and is the culmination of the experiences from v1 and v3, offering better supporting software and ecosystem, more features, simpler usage, and more comprehensive documentation. While the hardware has significant improvements, the pricing is even more affordable compared to the other two versions. Additionally, it provides compatibility with the K210 user experience and API, making it easier for users to migrate quickly from v1 to v4. * v1 used the Micropython language and had many limitations, such as limited third party library support. Additionally, due to the hardware performance limitations of the Maix I (K210), there was not enough memory, limited AI model support, and lack of hardware acceleration for many codecs. * v3 also used the Python language and was based on the Maix II Dock (v831) hardware. However, the hardware had limited AI model support, and the Allwinner ecosystem was not open enough, with an incomplete API. This version was only intended for use with the Maix II Dock (v831) and will not receive further updates. ## Does MaixPy currently only support MaixCAM, or can it work with other boards using the same chipset? MaixPy currently only supports the MaixCAM series of boards. Other boards using the same chipset, including Sipeed's boards like the LicheeRV Nano, are not supported. It is strongly recommended not to attempt using MaixPy with other boards, as it may result in device damage (such as smoke or screen burn), for which you will be solely responsible. In the future, Sipeed's Maix series of products will continue to be supported by MaixPy. If you have any needs that cannot be met by MaixCAM, you can post your requirements on the [MaixHub Discussion Forum](https://maixhub.com/discussion) or send an email to support@sipeed.com. ## Can I use a camera or screen other than the officially bundled ones? It is not recommended to use cameras or screens other than the officially bundled ones, unless you have sufficient software and hardware knowledge and experience. Otherwise, it may result in device damage. The officially bundled accessories have been fine tuned for both software and hardware, ensuring the best performance and allowing for out of the box usage. Other accessories may have different interfaces, drivers, and software, requiring you to calibrate them yourself, which is an extremely complex process. However, if you are an expert, we welcome you to submit a pull request! ## Model running error: cvimodel built for xxxcv181x CANNOT run on platform cv181x. Failure to parse the model file is generally caused by file corruption. Ensure that your model file is not damaged. For example: * Editing a binary file with an editor caused the file to become corrupted. For example, opening a `cvimodel` file with MaixVision can corrupt the binary file due to MaixVision's auto save feature. Therefore, do not open and save binary files with text editors like MaixVision (this issue will be fixed in a future update of MaixVision by removing the auto save feature). * If it was downloaded from the internet, make sure the download was not corrupted. Typically, files on the internet provide sha256sum/md5 checksums. After downloading, you can compare these values; for specific methods, please search online or ask ChatGPT. * If it comes from a compressed archive, ensure that the decompression process was error free. You can decompress the archive again to make sure there were no errors in the process. * Ensure that the file was not damaged during the transfer to the device. You can compare the sha256sum values of the file on the device and on your computer; for specific methods, please search online or ask ChatGPT. ## Power on Black Screen, No Display on the Screen Refer to [MaixCAM FAQ](https://wiki.sipeed.com/hardware/zh/maixcam/faq.html) ## Why doesn’t the computer detect a serial port when connecting via USB to MaixCAM? The USB port on the MaixCAM is a USB 2.0 interface of the chip, not a USB to serial interface, so it is normal for no serial port to appear when connected to a computer. How do you communicate without a USB to serial connection? By default, the USB will simulate a USB network card. When you connect the USB to your computer, a virtual network card will appear. According to the instructions in the [Quick Start Guide](./index.html), you can use MaixVision to communicate with MaixCAM to run code, preview images, manage files, and other functions. Additionally, since the USB simulates a network card, you can also use standard SSH software to connect to MaixCAM for communication. Alternatively, you can connect via WiFi and communicate within the same local network. If you need to use the serial port, there are two situations: 1. **Serial communication with a computer**: You need to purchase any USB to serial module to connect the computer's USB port with the board's serial port (for MaixCAM, it's the UART0 pins A16 (TX) and A17 (RX), or you can use the TX and RX pins on the USB adapter board that comes with the MaixCAM package, which are also the A16 and A17 pins and are functionally equivalent). 2. **Serial communication with another MCU/SOC**: Directly connect MaixCAM's A16 (TX) and A17 (RX) to the MCU's RX and TX pins. ## Red Screen, Initialization Display Failed, Please Check FAQ The message indicates that the display driver initialization failed. As of July 2024, the underlying display driver for MaixCAM is initialized together with the camera driver. Therefore, this issue is most likely caused by a failure in the camera driver initialization. To resolve this issue: * Try updating to the latest system and install the latest runtime libraries (very important!!!). The runtime libraries need to work in conjunction with the system drivers, and version mismatches may cause errors. Updating to the latest system image and installing the latest runtime libraries should generally resolve the issue. * Maybe multiple process try to occupy driver, easiest way is reboot. * Check for hardware connection issues with the camera. Ensure that the camera is properly connected and not damaged. ## What are the differences between Runtime, MaixPy, and system image? Which one should I upgrade? * **Runtime** is the runtime environment. Many system functions depend on it, including MaixPy. If you encounter the problem of being unable to run the program, first check and update it online. * The system image includes the basic operating system, hardware drivers, built in applications, and MaixPy firmware, etc. It is the basic environment. It is best to keep it up to date, especially in the [Release](https://github.com/sipeed/MaixPy/releases) page. If the version update mentions that the system has been updated, it is strongly recommended to update the system, because some MaixPy functions may depend on the drivers in the system. > Updating the system will format all previous data. Please back up useful data in the device system before updating. * **MaixPy** is a dependent library for running the MaixPy program. If you do not need to update the system function, and the update log does not mention that the system has important updates such as drivers, you can update MaixPy alone. ## Error Loading MUD Model File: *****.cvimodel not exists, load model failed * Check if the .mud file you are trying to load really exists on the device (note, it should be on the device, not on the computer, it needs to be transferred to the device). * Verify that the model path you wrote is correct. * If you have changed the file name, note that the MUD file is a model description file and can be edited with a text editor. The actual model file is the .cvimodel file (for MaixCAM). The .mud file specifies the file name and path of the .cvimodel. Therefore, if you have changed the file name of `.cvimodel`, you also need to modify the `model` path in the `.mud` file. For example, here is the mud file for the Yolov5 model: ```ini [basic] type cvimodel model yolov5s_224_int8.cvimodel [extra] model_type yolov5 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 anchors 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair dryer, toothbrush ``` Here, the `model` is specified as the `yolov5s_224_int8.cvimodel` file relative to the directory of this `.mud` file. If you have changed `yolov5s_224_int8.cvimodel` to another name, you need to update it here as well. ## MaixVision Shows Red Wavy Line on `import maix` This error occurs because MaixVision's code hinting feature cannot find the `maix` module. It's important to understand that MaixVision's code hinting relies on the local Python packages on your computer, while the code execution depends on the Python packages on the device. To enable MaixVision's code hinting, you need to install Python and the `MaixPy` package on your computer. For more details, refer to the [MaixVision User Documentation](./basic/maixvision.html). ## MaixCAM starts very slowly, even exceeding 1 minute, or the screen flickers This is mostly due to insufficient power supply. MaixCAM requires a voltage of around 5V and a current between 150mA and 500mA. If you encounter this issue, you can use a USB to TTL module to connect MaixCAM's serial port to a computer. You may see a message like `Card did not respond to voltage select! : 110`, indicating insufficient power supply. Simply switch to a more stable power supply to resolve the problem. For MaixCAM, it draws 400mA during startup, 250mA in standby mode with the screen on, and 400mA~500mA when running AI models at full speed. Therefore, ensuring a stable power supply is very important! ## MaixCAM Black screen and not boot up, or stock in LOGO screen Refer to [MaixCAM FAQ](https://wiki.sipeed.com/hardware/en/maixcam/faq.html) ## MaixVision Program Stuck on \"start running ...\" When the MaixVision log output window prints the message `start running ...`, it indicates that the program has been sent to the device and has begun executing. What gets printed afterward depends on your program. For instance, if you call `print(\"hello\")`, it will print `hello`. If your program doesn't include any print statements, then there will be no logs displayed. So, the program isn't actually stuck; it's just that your program hasn't output anything, so no logs are shown. You can try adding `print(\"xxx\")` in your code to generate output, which is the simplest way to debug your program. ## Why Does the Hardware Have 256MB of Memory, But Only 128MB is Available in the System? The remaining memory is reserved for low level drivers and the kernel, which are used for operating the camera, display, hardware encoding/decoding, NPU, and other drivers. You can check the memory used by these drivers (known as ION memory in CVITEK systems) by running `cat /sys/kernel/debug/ion/cvi_carveout_heap_dump/summary`. For other memory usage, you can run `cat /proc/meminfo`. If you want to adjust the memory allocation, you would need to compile the system yourself and modify the `ION_SIZE` in the `memmap.py` file located in the `LicheeRV Nano Build/build/boards/sg200x/sg2002_licheervnano_sd/` directory(refer to [customize system doc](./pro/compile_os.html)). ## Why Am I Unable to Install the Runtime Library, and an Error \"Request Failed\" Is Displayed? * Ensure that the device is successfully connected to the internet. You can try connecting to a different mobile hotspot. * Verify that the system image you flashed is the latest version. * If you see an error related to DNS resolution failure, it might be due to DNS settings issues on your network. You can try connecting to a different mobile hotspot or manually modify the DNS server settings in `/boot/resolv.conf` (modifying this file requires a reboot) and `/etc/resolv.conf` (modifying this file does not require a reboot, but rebooting will overwrite it with the contents of the former). * Make sure you have purchased a genuine MaixCAM from Sipeed. * Contact customer service, providing the system version and device_key (which can be found after disconnecting from MaixVision or, if you have a screen, in `System Settings > System Information`). Translation: ## Compile error: type not registered yet? ``` from ._maix.peripheral.key import add_default_listener ImportError: arg(): could not convert default argument into a Python object (type not registered yet?). #define ``` The error indicates that an object has not been defined as a Python object. In MaixPy, this is usually caused by an issue with the order of automatic API generation. For example, if there is an API declared with `@maixpy` in `a.hpp`, and another API in `b.hpp` that uses a definition from `a.hpp` as a parameter, then `b.hpp` depends on `a.hpp`. However, the current MaixPy compilation script does not perform dependency scanning. To resolve this, you need to manually specify the scan order in the `components/maix/headers_priority.txt` file in the MaixPy project, ensuring that `a.hpp` is scanned before `b.hpp`. ## MaixVision Display Lag The lag is typically due to using WiFi transmission. When the signal is weak or the image resolution is too high, delays can occur. Here are solutions to reduce lag: * Switch to a wired connection; refer to the Quick Start Guide for details. * Lower the image resolution by reducing the size of `img` in the code with `disp.show(img)`."},"/maixpy/doc/en/basic/app_usage.html":{"title":"MaixCAM MaixPy Application User Guide","content":" title: MaixCAM MaixPy Application User Guide layout: redirect redirect_url: ./app.html "},"/maixpy/doc/en/basic/python_pkgs.html":{"title":"MaixCAM MaixPy Add extra Python packages.","content":" title: MaixCAM MaixPy Add extra Python packages. ## Introduction MaixPy is based on the Python language and provides a wide range of functionalities and APIs for embedded application development. In addition to this, you can also use other Python packages to extend its functionality. ## Installing Additional Python Packages > Please note that not all Python packages are supported. Generally, only pure Python packages are supported, not C extension packages. C extension packages may require you to manually cross compile them on a computer (which is quite complex and won't be covered here). ### Method 1: Installing Using Python Code You can install the package you need in MaixVision using Python code, for example: ```python import os os.system(\"pip install package_name\") ``` To update a package, you can use: ```python import os os.system(\"pip install upgrade package_name\") ``` ### Method 2: Installing Using the Terminal and pip Command Follow the terminal usage method introduced in [Linux Basics](./linux_basic.html) and use `pip install package_name` to install the package you need."},"/maixpy/doc/en/basic/app.html":{"title":"MaixCAM MaixPy App development and app stores","content":" title: MaixCAM MaixPy App development and app stores ## Where to Find Applications After powering on, the device will automatically enter the application selection interface. All built in applications are available on the [MaixHub App Store](https://maixhub.com/app), where you can find corresponding app descriptions and usage instructions. ## Where to Find Source Code You can find the source code links (if available) on the app pages in the App Store. The source code for official integrated applications is located in the [MaixPy/projects](https://github.com/sipeed/MaixPy/tree/main/projects) directory or the [MaixCDK/projects](https://github.com/sipeed/MaixCDK/tree/main/projects) directory. ## Installing Applications Frequently used settings include `Settings > Language` and `Settings > WiFi`. The `App Store` application can be used to upgrade and install apps. Once connected to a WiFi network with internet access, you can scan to install apps from the [MaixHub App Store](https://maixhub.com/app). ## Introduction to Application Ecosystem In order to make the development board ready to use out of the box, make it easy for users to use without barriers, enable developers to share their interesting applications, and provide effective channels for receiving feedback and even profits, we have launched a simple application framework, including: **[App Store](https://maixhub.com/app)**: Developers can upload and share applications, which users can download and use without needing to develop them. Developers can receive certain cash rewards (from MaixHub or user tips). **Pre installed Apps**: The official provides some commonly used applications, such as color block detection, AI object detection tracking, QR code scanning, face recognition, etc., which users can use directly or use as serial module. **MaixPy + MaixCDK Software Development Kit**: Using [MaixPy](https://github.com/sipeed/maixpy) or [MaixCDK](https://github.com/sipeed/MaixCDK), you can quickly develop embedded AI visual and audio applications in Python or C/C++, efficiently realizing your interesting ideas. **MaixVision Desktop Development Tool**: A brand new desktop code development tool for quick start, debugging, running, uploading code, installing applications to devices, one click development, and even support for graphical block based programming, making it easy for elementary school students to get started. Everyone is welcome to pay attention to the App Store and share their applications in the store to build a vibrant community together. ## Packaging Applications Using MaixPy + MaixVison makes it easy to develop, package, and install applications: Develop applications with MaixPy in MaixVision, which can be a single file or a project directory. Connect the device. Click the \"Install\" button at the bottom left corner of MaixVision, fill in the basic information of the application in the popup window, where the ID is used to identify the application. A device cannot simultaneously install different applications with the same ID, so the ID should be different from the IDs of applications on MaixHub. The application name can be duplicated. You can also upload an icon. Click \"Package Application\" to package the application into an installer. If you want to upload it to the [MaixHub App Store](https://maixhub./com/app), you can use this packaged file. Click \"Install Application\" to install the packaged application on the device. Disconnect from the device, and you will see your application in the device's app selection interface. Simply click on it to run the application. > If you develop with MaixCDK, you can use `maixcdk release` to package an application. Refer to the MaixCDK documentation for specifics. ## Exiting Applications If you have developed a relatively simple application without a user interface and a back button, you can exit the application by pressing the device's function button (usually labeled as USER, FUNC, or OK) or the back button (if available, MaixCAM does not have this button by default). ## Installing Applications * **Method 1**: Use the `App Store` application on the device. Find the application on the [App Store](https://maixhub.com/app), connect the device to the internet, and scan the code to install. * **Method 2**: Install using a local installation package. Transfer the package to the device's file system, for example, to `/root/my_app_v1.0.0.zip`, and then run the following code. Make sure to modify the `pkg_path` variable to the correct path, you can also find this script in `MaixPy`'s `examples/tools/install_app.py`: ```python import os def install_app(pkg_path): if not os.path.exists(pkg_path): raise Exception(f\"Package {pkg_path} not found\") cmd f\"/maixapp/apps/app_store/app_store install {pkg_path}\" err_code os.system(cmd) if err_code ! 0: print(\"[ERROR] Install failed, error code:\", err_code) else: print(f\"Install {pkg_path} success\") pkg_path \"/root/my_app_v1.0.0.zip\" install_app(pkg_path) ``` * **Method 3**: * For applications developed using `MaixPy`, run `maixtool deploy` in the project root directory (which contains `app.yaml` and `main.py`). A QR code will be displayed. Keep the device and computer on the same local network, and use the App Store on the device to scan the QR code corresponding to the local network address for online installation. * For applications developed using `MaixCDK`, run `maixcdk deploy` in the project root directory. A QR code will be displayed. Keep the device and computer on the same local network, and use the App Store on the device to scan the QR code corresponding to the local network address for online installation. ## Basic Guidelines for Application Development Since touchscreens are standard, it is recommended to create a simple interface with touch interaction. You can refer to examples for implementation methods. Avoid making interfaces and buttons too small, as MaixCAM default screen is 2.3 inches with 552x368 resolution and high PPI. Make sure fingers can easily tap without making mistakes. Implement a simple serial interaction for the main functionality of each application based on the [serial protocol](https://github.com/sipeed/MaixCDK/blob/master/docs/doc/convention/protocol.md) (see [example](https://github.com/sipeed/MaixPy/tree/main/examples/communication/protocol)). This way, users can directly use it as a serial module. For instance, in a face detection application, you can output coordinates via serial port when a face is detected."},"/maixpy/doc/en/basic/os.html":{"title":"MaixCAM MaixPy Upgrade and burn system.","content":" title: MaixCAM MaixPy Upgrade and burn system. ## Introduction If you have purchased the official (Sipeed) package with a TF card, typically the system has already been pre programmed at the factory and can be used directly without further steps. However, to avoid using an outdated version of the pre programmed system, it is <span style \"font size: 1.2em; color: red\">**highly recommended**</span> to first **upgrade to the latest system** following the tutorial. ## Obtaining the Latest System Visit the [MaixPy Release page](https://github.com/sipeed/MaixPy/releases) to find the latest system image file, such as `maixcam_os_20240401_maixpy_v4.1.0.xz`. Alternate link: [Sourceforge](https://sourceforge.net/projects/maixpy/files/) ## How to Confirm if System Upgrade is Needed * Upon booting up to the main menu, click on `Settings`, then `Device Info` to check the system's version number. * Visit the [MaixPy Release History page](https://github.com/sipeed/MaixPy/releases) to review the update logs, which contain information on MaixPy firmware and system image updates. If there are significant updates after your current version, it is advisable to upgrade. > If the latest system update only includes routine MaixPy firmware updates compared to your current system, you may choose not to upgrade. You can simply update `MaixPy` separately in `Settings` under `Update MaixPy`. ## Burning the System Image to MaixCAM Refer to the hardware documentation [MaixCAM System Burning](https://wiki.sipeed.com/hardware/zh/maixcam/os.html) tutorial. Note that if the conditions for `USB Burning` are met, it is recommended to use the `USB Burning` method. The USB burning method does not require removing the TF card."},"/maixpy/doc/en/basic/linux_basic.html":{"title":"Basic Knowledge of Linux","content":" title: Basic Knowledge of Linux ## Introduction For beginners just starting out, you can skip this chapter for now and come back to it after mastering the basics of MaixPy development. The latest MaixPy supports running Linux on the MaixCAM hardware, so the underlying MaixPy development is based on the Linux system. Although Sipeed has done a lot of work for developers with MaixPy, making it possible to enjoy using it without knowledge of the Linux system, there might be situations where some low level operations are necessary or for the convenience of developers unfamiliar with Linux. In this section, we will cover some basic Linux knowledge. ## Why Linux System is Needed Specific reasons can be researched individually. Here are a few examples in simplified terms that may not sound too technical but are easy for beginners to understand: * In microcontrollers, our program is usually a loop, but with Linux, we can run multiple programs simultaneously, each appearing to run independently, where the actual execution is handled by the operating system. * With a large community of Linux based developers, required functionalities and drivers can be easily found without the need to implement them from scratch. * Linux offers a rich set of accompanying software tools for convenient development and debugging. Some Linux common tools not mentioned in this tutorial can theoretically be used as well. ## File System What is a file system? * Similar to a computer's file system, Linux manages hardware disks using a file system, making it easy for us to read and write data to the disk. * For students who have learned about microcontrollers but not familiar with file system development, imagine having a Flash or TF card where data can be read and written through APIs even after power loss. However, Flash has read/write limitations, requiring a program to ensure its longevity. A file system is like a mature program that manages the Flash space and read/write operations. By calling the file system's APIs, we can significantly reduce development work and ensure stability and security with proven programs. ## Transferring Files between Computer and Device (Development Board) Since the device has Linux and a file system, how do we send files to it? For MaixPy, we offer MaixVision for file management in future versions. Before that, you can use the following method: Here we mainly discuss transferring files through the network. Other methods can be explored on your own by searching for \"transferring files to Linux\": * Ensure the device and computer are connected to the same local network, for example: * When the MaixCAM's USB port is connected to the computer, a virtual network card is created which can be seen in the device manager on the computer, and the device's IP can be found in the device's `Settings > Device Information`. * Alternatively, connect to the same local network on the device through `Settings > WiFi`. * Use SCP or SFTP protocols on the computer to transfer files to the device. There are many specific software options and methods, such as: * On Windows, you can use WinSCP, FileZilla, or the scp command. * On Linux, use FileZilla or the scp command. * On Mac, use FileZilla or the scp command. ## Terminal and Command Line The terminal is a tool for communicating with and operating the Linux system, similar to Windows' `cmd` or `PowerShell`. For example, we can enter `ssh root@maixcam xxxx.local` in the Terminal tool on a Windows system with PowerShell or on a Linux system. You can find the specific name in the device's `Settings >Device Information`, which allows us to connect to the device through the terminal (both username and password are `root`). Then, we can operate the device by entering commands. For instance, the `ls` command can list the files in the current directory of the device, while `cd` is used to switch to a different directory (similar to clicking folders in file management on a computer), ```shell cd / # Switch to the root directory ls # Display all files in the current directory (root directory) ``` This will display similar content as below: ```shell bin lib media root tmp boot lib64 mnt run usr dev linuxrc opt sbin var etc lost+found proc sys ``` For more command learning, please search for `Linux command line usage tutorials` on your own. This is just to introduce beginners to basic concepts so that when developers mention them, they can understand what they mean."},"/maixpy/doc/en/basic/maixpy_upgrade.html":{"title":"MaixCAM Update MaixPy.","content":" title: MaixCAM Update MaixPy. There are two methods to begin with. If you are new to this and want to keep things simple, you can try using the pre installed MaixPy firmware on the TF card that comes with the device. You can consider updating it later. However, since we don't know when the TF card you received was manufactured, it is recommended to update the system. ## Updating the System Directly(Highly Recommend) Follow the steps in [Upgrading and Flashing the System](./os.html) to upgrade to the latest system, which already includes the newest MaixPy firmware. ## Updating Only the MaixPy Firmware Check the latest version information and release notes in the [MaixPy repository release page](https://github.com/sipeed/MaixPy/releases). It includes details about the MaixPy firmware and the system information corresponding to each version. If you prefer not to update the system (since system changes are usually minimal, you can check if there are any system related changes in the MaixPy update notes before deciding whether to update the system), you can simply update the MaixPy firmware. * Set up WiFi in the settings to connect the system to the internet. * Click on `Update MaixPy` in the settings app to proceed with the update. You can also execute Python code to call system command to install: ```python import os os.system(\"pip install MaixPy U\") ``` > If you are comfortable using the terminal, you can also update MaixPy by using `pip install MaixPy U` in the terminal. And you can download `wheel` file (`.whl`format) manually, and send to device(transfer method see [MaixVision Usage](./maixvision.html)), then install by `pip install *****.whl` command."},"/maixpy/doc/en/basic/auto_start.html":{"title":"MaixPy/MaixCAM Application Auto-Start at Boot","content":" title: MaixPy/MaixCAM Application Auto Start at Boot Packaged applications can be set to automatically start when the device boots up, bypassing the application menu and directly launching the specified application. ## Method One for Setting Application Auto Start First, package and install the application, then go to `Settings > Auto Start` on your device to select the application you want to auto start. To cancel auto start, you can also adjust it here. ## Method Two for Setting Application Auto Start Run the Python script to set up, and modify the `new_autostart_app_id` variable in the script to the `app_id` you want to set. All installed `app_id`s will be printed out when you run the script, so you can run it once to find the desired `app_id`, modify the variable, and then run it again. To cancel the autostart setting, set it to `None`. This script can also be found in the `MaixPy` examples under `examples/tools` as `set_autostart.py`: ```python import configparser, os def parse_apps_info(): info_path \"/maixapp/apps/app.info\" conf configparser.ConfigParser() conf.read(info_path) version conf[\"basic\"][\"version\"] apps {} for id in list(conf.keys()): if id in [\"basic\", \"DEFAULT\"]: continue apps[id] conf[id] return apps def list_apps(): apps parse_apps_info() print(f\"APP num: {len(apps)}\") for i, (id, info) in enumerate(apps.items()): name_zh info.get(\"name[zh]\", \"\") print(f\"{i + 1}. [{info['name']}] {name_zh}:\") print(f\" id: {id}\") print(f\" exec: {info['exec']}\") print(f\" author: {info['author']}\") print(f\" desc: {info['desc']}\") print(f\" desc_zh: {info.get('desc', 'None')}\") print(\"\") def get_curr_autostart_app(): path \"/maixapp/auto_start.txt\" if os.path.exists(path): with open(path, \"r\") as f: app_id f.readline().strip() return app_id return None def set_autostart_app(app_id): path \"/maixapp/auto_start.txt\" if not app_id: if os.path.exists(path): os.remove(path) return with open(path, \"w\") as f: f.write(app_id) if __name__ \"__main__\": # new_autostart_app_id \"settings\" # change to app_id you want to set new_autostart_app_id None # remove autostart list_apps() print(\"Before set autostart appid:\", get_curr_autostart_app()) set_autostart_app(new_autostart_app_id) print(\"Current autostart appid:\", get_curr_autostart_app()) ``` ## Method Three for Setting Application Auto Start You can also modify the `/maixapp/auto_start.txt` file in your device to set it up. For methods on file transfer, refer to the previous documentation. * First, determine the `id` of the application you want to set. This is set when you package the application; if it's not an application you packaged yourself, you can install it on the device and check the folder names under the device's `/maixapp/apps/` directory, which are the application names (or you can download and check the device's `/maixapp/apps/app.info` file, where the application `id` is indicated inside the `[]` brackets). * Then write the `id` into the `/maixapp/auto_start.txt` file. (You can create the file locally on your computer, and then transfer it to the device using `MaixVision`.) * To cancel, delete the `/maixapp/auto_start.txt` file on the device. ## Other Methods For MaixCAM, since the underlying system is Linux, if you are familiar with Linux, you can edit the startup scripts in `/etc/rc.local` or `/etc/init.d`. However, it is important to note that this method may cause the application to continue running when MaixVision connects, thereby occupying resources (such as the screen and camera) which might prevent MaixVision from running programs normally. The first two methods allow MaixVision to terminate the program upon connection to run its own programs. Thus, this method is more suitable for running background processes that do not occupy screen and camera resources. Generally, if you are not familiar with Linux, it is not recommended to use this method."},"/maixpy/doc/en/vision/yolov5.html":{"title":"MaixPy MaixCAM Using YOLOv5 / YOLOv8 / YOLO11 for Object Detection","content":" title: MaixPy MaixCAM Using YOLOv5 / YOLOv8 / YOLO11 for Object Detection ## Object Detection Concept Object detection refers to detecting the position and category of objects in images or videos, such as identifying apples or airplanes in a picture and marking their locations. Unlike classification, object detection includes positional information. Therefore, the result of object detection is generally a rectangular box that marks the location of the object. ## Object Detection in MaixPy MaixPy provides `YOLOv5`, `YOLOv8`, and `YOLO11` models by default, which can be used directly: > YOLOv8 requires MaixPy > 4.3.0. > YOLO11 requires MaixPy > 4.7.0. ```python from maix import camera, display, image, nn, app detector nn.YOLOv5(model \"/root/models/yolov5s.mud\", dual_buff True) # detector nn.YOLOv8(model \"/root/models/yolov8n.mud\", dual_buff True) # detector nn.YOLO11(model \"/root/models/yolo11n.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) dis display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) dis.show(img) ``` Example video: <div> <video playsinline controls autoplay loop muted preload src \"/static/video/detector.mp4\" type \"video/mp4\"> </div> Here, the camera captures an image, passes it to the `detector` for detection, and then displays the results (classification name and location) on the screen. You can switch between `YOLO11`, `YOLOv5`, and `YOLOv8` simply by replacing the corresponding line and modifying the model file path. For the list of 80 objects supported by the model, see the appendix of this document. For more API usage, refer to the documentation for the [maix.nn](/api/maix/nn.html) module. ## dual_buff for Double Buffering Acceleration You may notice that the model initialization uses `dual_buff` (default value is `True`). Enabling the `dual_buff` parameter can improve efficiency and increase the frame rate. For more details and usage considerations, see the [dual_buff Introduction](./dual_buff.html). ## More Input Resolutions The default model input resolution is `320x224`, which closely matches the aspect ratio of the default screen. You can also download other model resolutions: YOLOv5: [https://maixhub.com/model/zoo/365](https://maixhub.com/model/zoo/365) YOLOv8: [https://maixhub.com/model/zoo/400](https://maixhub.com/model/zoo/400) YOLO11: [https://maixhub.com/model/zoo/453](https://maixhub.com/model/zoo/453) Higher resolutions provide more accuracy, but take longer to process. Choose the appropriate resolution based on your application. ## Which Model to Use: YOLOv5, YOLOv8, or YOLO11? We provide three models: `YOLOv5s`, `YOLOv8n`, and `YOLO11n`. The `YOLOv5s` model is larger, while `YOLOv8n` and `YOLO11n` are slightly faster. According to official data, the accuracy is `YOLO11n > YOLOv8n > YOLOv5s`. You can test them to decide which works best for your situation. Additionally, you may try `YOLOv8s` or `YOLO11s`, which will have a lower frame rate (e.g., `yolov8s_320x224` is 10ms slower than `yolov8n_320x224`), but offer higher accuracy. You can download these models from the model library mentioned above or export them yourself from the official `YOLO` repository. ## Different Resolutions for Camera and Model If the resolution of `img` is different from the model's resolution when using the `detector.detect(img)` function, the function will automatically call `img.resize` to adjust the image to the model's input resolution. The default `resize` method is `image.Fit.FIT_CONTAIN`, which scales while maintaining the aspect ratio and fills the surrounding areas with black. The detected coordinates will also be automatically mapped back to the original `img`. ## Training Your Own Object Detection Model on MaixHub If you need to detect specific objects beyond the 80 categories provided, visit [MaixHub](https://maixhub.com) to learn and train an object detection model. Select \"Object Detection Model\" when creating a project. Refer to the [MaixHub Online Training Documentation](./maixhub_train.html). Alternatively, you can find models shared by community members at the [MaixHub Model Library](https://maixhub.com/model/zoo?platform maixcam). ## Training Your Own Object Detection Model Offline We strongly recommend starting with MaixHub for online training, as the offline method is much more difficult and is not suitable for beginners. Some knowledge may not be explicitly covered here, so be prepared to do further research. Refer to [Training a Custom YOLOv5 Model](./customize_model_yolov5.html) or [Training a Custom YOLOv8/YOLO11 Model Offline](./customize_model_yolov8.html). ## Appendix: 80 Classes The 80 objects in the COCO dataset are: ```txt person bicycle car motorcycle airplane bus train truck boat traffic light fire hydrant stop sign parking meter bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard sports ball kite baseball bat baseball glove skateboard surfboard tennis racket bottle wine glass cup fork knife spoon bowl banana apple sandwich orange broccoli carrot hot dog pizza donut cake chair couch potted plant bed dining table toilet tv laptop mouse remote keyboard cell phone microwave oven toaster sink refrigerator book clock vase scissors teddy bear hair dryer toothbrush ```"},"/maixpy/doc/en/vision/ai.html":{"title":"MaixCAM MaixPy Basic Knowledge of AI Vision","content":" title: MaixCAM MaixPy Basic Knowledge of AI Vision update: date: 2024 04 03 author: neucrack version: 1.0.0 content: Initial documentation ## Introduction If you don't have an AI background, you can first read [What is Artificial Intelligence (AI) and Machine Learning](https://wiki.sipeed.com/ai/en/basic/what_is_ai.html) to understand the basic concepts of AI before learning about AI. Then, the visual AI we use is generally based on the `deep neural network learning` method. If you are interested, you can check out [Deep Neural Network (DNN) Basics](https://wiki.sipeed.com/ai/en/basic/dnn_basic.html). ## Using Visual AI in MaixPy Using visual AI in MaixPy is very simple. By default, commonly used AI models are provided, and you can use them directly without having to train the models yourself. You can find the `maixcam` models in the [MaixHub Model Library](https://maixhub.com/model/zoo). Additionally, the underlying APIs have been well encapsulated, and you only need to make simple calls to implement them. If you want to train your own model, you can start with [MaixHub Online Training](https://maixhub.com/model/training/project). On the online platform, you can train models just by clicking, without the need to purchase expensive machines, set up complex development environments, or write code, making it very suitable for beginners and also for experienced users who are too lazy to read code. Generally, once you have obtained the model file, you can transfer it to the device and call the MaixPy API to use it. The specific calling methods are discussed in the following sections."},"/maixpy/doc/en/vision/display.html":{"title":"MaixCAM MaixPy Screen Usage","content":" title: MaixCAM MaixPy Screen Usage update: date: 2024 03 31 author: neucrack version: 1.0.0 content: Initial document ## Introduction MaixPy provides the `display` module, which can display images on the screen, and can also send images to MaixVision for display, facilitating debugging and development. ## API Documentation This document introduces commonly used methods. For more APIs, please refer to the [display](/api/maix/display.html) section of the API documentation. ## Using the Screen * Import the `display` module: ```python from maix import display ``` * Create a `Display` object: ```python disp display.Display() ``` * Display an image: ```python disp.show(img) ``` Here, the `img` object is a `maix.image.Image` object, which can be obtained through the `read` method of the `camera` module, or loaded from an image file in the file system using the `load` method of the `image` module, or created as a blank image using the `Image` class of the `image` module. For example: ```python from maix import image, display disp display.Display() img image.load(\"/root/dog.jpg\") disp.show(img) ``` Here, you need to transfer the `dog.jpg` file to the `/root` directory on the device first. Display text: ```python from maix import image, display disp display.Display() img image.Image(320, 240) img.draw_rect(0, 0, disp.width(), disp.height(), color image.Color.from_rgb(255, 0, 0), thickness 1) img.draw_rect(10, 10, 100, 100, color image.Color.from_rgb(255, 0, 0)) img.draw_string(10, 10, \"Hello MaixPy!\", color image.Color.from_rgb(255, 255, 255)) disp.show(img) ``` Read an image from the camera and display it: ```python from maix import camera, display, app disp display.Display() cam camera.Camera(320, 240) while not app.need_exit(): img cam.read() disp.show(img) ``` > Here, `while not app.need_exit():` is used to facilitate exiting the loop when the `app.set_exit_flag()` method is called elsewhere. ## Adjusting Backlight Brightness You can manually adjust the backlight brightness in the system's \"Settings\" app. If you want to adjust the backlight brightness programmatically, you can use the `set_backlight` method, with the parameter being the brightness percentage, ranging from 0 to 100: ```python disp.set_backlight(50) ``` Note that when the program exits and returns to the app selection interface, the backlight brightness will automatically revert to the system setting. ## Displaying on MaixVision When running code in MaixVision, images can be displayed on MaixVision for easier debugging and development. When calling the `show` method, the image will be automatically compressed and sent to MaixVision for display. Of course, if you don't have a screen, or to save memory by not initializing the screen, you can also directly call the `send_to_maixvision` method of the `maix.display` object to send the image to MaixVision for display. ```python from maix import image,display from maix import image,display img image.Image(320, 240) disp display.Display() img.draw_rect(0, 0, img.width(), img.height(), color image.Color.from_rgb(255, 0, 0), thickness 1) img.draw_rect(10, 10, 100, 100, color image.Color.from_rgb(255, 0, 0)) img.draw_string(10, 10, \"Hello MaixPy!\", color image.Color.from_rgb(255, 255, 255)) display.send_to_maixvision(img) ``` ## Replacing with Other Screen Models If you wish to switch to a screen of a different size, you can consult and purchase from the [store](https://wiki.sipeed.com/store). For MaixCAM, the following four screen options are currently supported: * 2.3 inch 552x368 resolution capacitive touch screen: The default screen that comes with MaixCAM. * 2.4 inch 640x480 resolution capacitive touch screen: The default screen that comes with MaixCAM Pro. * 5 inch 854x480 resolution non touch screen: Note that this is a non touch screen, similar in size to a mobile phone screen. * 7 inch 1280x800 resolution capacitive touch screen: A large 7 inch screen, suitable for scenarios requiring a fixed screen display. The image refresh time difference between different screens is about 1 5 milliseconds, which is not significant; the main difference lies in the image resolution, which affects image processing time. When replacing the screen, you must also **modify the configuration file**; otherwise, mismatched refresh timing could **cause screen burn in** (leaving a ghost image on the screen). It’s important to follow the steps strictly as outlined below. If screen burn in occurs, don’t panic; powering off and leaving it overnight usually resolves the issue. * Follow the system burning documentation to burn the system. Once completed, a USB drive will appear. * Open the USB drive, and you will see a `uEnv.txt` file. * Edit the `uEnv.txt` file, modifying the `pannel` key value as follows: * 2.3 inch (MaixCAM default screen): `st7701_hd228001c31`. * 2.4 inch (MaixCAM Pro default screen): `st7701_lct024bsi20`. * 5 inch: `st7701_dxq5d0019_V0`, with the earlier (2023) test screen being `st7701_dxq5d0019b480854`. * 7 inch: `mtd700920b`, with the earlier (2023) test screen being `zct2133v1`. * Save the `uEnv.txt` file, and **click to eject the USB drive**—do not just disconnect the power, or the file may be lost. * Press the board's `reset` button, or power cycle to restart. The above method is the safest, ensuring the screen model is set correctly before powering on. If you have already burned the system, you can also modify the system’s `/boot/uEnv.txt` file and then reboot."},"/maixpy/doc/en/vision/ocr.html":{"title":"OCR Image Text Recognition with MaixCAM MaixPy","content":" title: OCR Image Text Recognition with MaixCAM MaixPy ## Introduction to OCR OCR (Optical Character Recognition) refers to the visual recognition of text in images. It can be applied in various scenarios, such as: * Recognizing text/numbers on cards * Extracting text from cards, such as ID cards * Digitizing paper documents * Reading digital displays, useful for meter reading and digitizing old instrument data * License plate recognition ## Using OCR in MaixPy MaixPy has integrated [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR), an open source OCR algorithm developed by Baidu. For understanding the principles, you can refer to this open source project. ![OCR](../../assets/ocr.jpg) **First, ensure that your MaixPy version is > 4.6.** Then, execute the code: (The complete, latest code can be found in the [MaixPy repository](https://github.com/sipeed/MaixPy/blob/main/examples/vision/ai_vision/nn_pp_ocr.py); please refer to the source code.) ```python from maix import camera, display, image, nn, app model \"/root/models/pp_ocr.mud\" ocr nn.PP_OCR(model) cam camera.Camera(ocr.input_width(), ocr.input_height(), ocr.input_format()) dis display.Display() image.load_font(\"ppocr\", \"/maixapp/share/font/ppocr_keys_v1.ttf\", size 20) image.set_default_font(\"ppocr\") while not app.need_exit(): img cam.read() objs ocr.detect(img) for obj in objs: points obj.box.to_list() img.draw_keypoints(points, image.COLOR_RED, 4, 1, 1) img.draw_string(obj.box.x4, obj.box.y4, obj.char_str(), image.COLOR_RED) dis.show(img) ``` You can see that `ocr nn.PP_OCR(model)` loads the model, and then `ocr.detect(img)` detects and recognizes the text, displaying the results on the screen. ## More Model Options You can download more complete models with different input resolutions, languages, and versions from the [MaixHub Model Download](https://maixhub.com/model/zoo/449) (MaixPy currently defaults to the pp_ocr.mud model, which uses PPOCRv3 for detection and v4 for recognition). ## Recognizing Without Detection If you already have a processed image with known coordinates for the four corners of the text, you can skip calling the `detect` function and simply call the `recognize` function. This way, it will only recognize the text in the image without detection. ## Custom Models The default model provides detection and recognition for Chinese and English text. If you have specific requirements, such as another language or only want to detect certain shapes without recognizing all types of text, you can download the corresponding model from the [PaddleOCR Official Model Library](https://paddlepaddle.github.io/PaddleOCR/ppocr/model_list.html) and convert it to a format supported by MaixCAM. The most complex part here is converting the model into a format usable by MaixCAM, which is a **relatively complex** process that requires basic Linux skills and adaptability. * First, either train your model using PaddleOCR source code or download the official models. Choose PP OCRv3 for detection because it is efficient and faster than v4, and download the v4 model for recognition; tests show that v3 does not perform well when quantized on MaixCAM. * Then, convert the model to ONNX: ```shell model_path ./models/ch_PP OCRv3_rec_infer paddle2onnx model_dir ${model_path} model_filename inference.pdmodel params_filename inference.pdiparams save_file ${model_path}/inference.onnx opset_version 14 enable_onnx_checker True ``` * Next, set up the environment according to the [ONNX to MUD format model documentation](../ai_model_converter/maixcam.html) and convert the model. Sample conversion scripts are provided in the appendix. * Finally, load and run it using MaixPy. ## Appendix: Model Conversion Scripts Detection: ```shell #!/bin/bash set e net_name ch_PP_OCRv3_det input_w 320 input_h 224 output_name sigmoid_0.tmp_0 # scale 1/255.0 # \"mean\": [0.485, 0.456, 0.406], # \"std\": [0.229, 0.224, 0.225], # mean: mean * 255 # scale: 1/(std*255) # mean: 123.675, 116.28, 103.53 # scale: 0.01712475, 0.017507, 0.01742919 mkdir p workspace cd workspace # convert to mlir model_transform.py \\ model_name ${net_name} \\ model_def ../${net_name}.onnx \\ input_shapes [[1,3,${input_h},${input_w}]] \\ mean \"123.675,116.28,103.53\" \\ scale \"0.01712475,0.017507,0.01742919\" \\ keep_aspect_ratio \\ pixel_format bgr \\ channel_format nchw \\ output_names \"${output_name}\" \\ test_input ../test_images/test3.jpg \\ test_result ${net_name}_top_outputs.npz \\ tolerance 0.99,0.99 \\ mlir ${net_name}.mlir # export bf16 model # not use quant_input, use float32 for easy coding model_deploy.py \\ mlir ${net_name}.mlir \\ quantize BF16 \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ model ${net_name}_bf16.cvimodel echo \"calibrate for int8 model\" # export int8 model run_calibration.py ${net_name}.mlir \\ dataset ../images \\ input_num 200 \\ o ${net_name}_cali_table echo \"convert to int8 model\" # export int8 model # add quant_input, use int8 for faster processing in maix.nn.NN.forward_image model_deploy.py \\ mlir ${net_name}.mlir \\ quantize INT8 \\ quant_input \\ calibration_table ${net_name}_cali_table \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ tolerance 0.9,0.5 \\ model ${net_name}_int8.cvimodel ``` Recognition: ```shell #!/bin/bash set e # net_name ch_PP_OCRv4_rec # output_name softmax_11.tmp_0 net_name ch_PP_OCRv3_rec_infer_sophgo output_name softmax_5.tmp_0 input_w 320 input_h 48 cali_images ../images_crop_320 # scale 1/255.0 # \"mean\": [0.5, 0.5, 0.5], # \"std\": [0.5, 0.5, 0.5], # mean: mean * 255 # scale: 1/(std*255) # mean: 127.5,127.5,127.5 # scale: 0.00784313725490196,0.00784313725490196,0.00784313725490196 mkdir p workspace cd workspace # convert to mlir model_transform.py \\ model_name ${net_name} \\ model_def ../${net_name}.onnx \\ input_shapes [[1,3,${input_h},${input_w}]] \\ mean \"127.5,127.5,127.5\" \\ scale \"0.00784313725490196,0.00784313725490196,0.00784313725490196\" \\ keep_aspect_ratio \\ pixel_format bgr \\ channel_format nchw \\ output_names \"${output_name}\" \\ test_input ../test_images/test3.jpg \\ test_result ${net_name}_top_outputs.npz \\ tolerance 0.99,0.99 \\ mlir ${net_name}.mlir # export bf16 model # not use quant_input, use float32 for easy coding model_deploy.py \\ mlir ${net_name}.mlir \\ quantize BF16 \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ model ${net_name}_bf16.cvimodel echo \"calibrate for int8 model\" # export int8 model run_calibration.py ${net_name}.mlir \\ dataset $cali_images \\ input_num 200 \\ o ${net_name}_cali_table echo \"convert to int8 model\" # export int8 model # add quant_input, use int8 for faster processing in maix.nn.NN.forward_image model_deploy.py \\ mlir ${net_name}.mlir \\ quantize INT8 \\ quant_input \\ calibration_table ${net _name}_cali_table \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ tolerance 0.9,0.5 \\ model ${net_name}_int8.cvimodel ```"},"/maixpy/doc/en/vision/face_detection.html":{"title":"MaixCAM MaixPy Face Detection and Keypoint Detection","content":" title: MaixCAM MaixPy Face Detection and Keypoint Detection ## Introduction Face detection can be applied in many scenarios, such as providing the face detection step for face recognition, or for face tracking applications, etc. The face detection provided here can not only detect faces but also detect 5 key points, including two eyes, one nose, and two corners of the mouth. ![face detection](../../assets/face_detection.jpg) ## Using Face Detection in MaixPy MaixPy officially provides three face detection models from the open source projects [Face Detector 1MB with landmark](https://github.com/biubug6/Face Detector 1MB with landmark), [Retinaface](https://github.com/biubug6/Pytorch_Retinaface), and [YOLOv8 face](https://github.com/derronqi/yolov8 face). All three models can be used. `YOLOv8 face` performs better but is slightly slower, so you can choose based on your testing. Using `YOLOv8 face` (requires MaixPy version > 4.3.8): ```python from maix import camera, display, image, nn, app detector nn.YOLOv8(model \"/root/models/yolov8n_face.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) dis display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45, keypoint_th 0.5) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) detector.draw_pose(img, obj.points, 2, image.COLOR_RED) dis.show(img) ``` For the other two models: Here, a line of commented out code is used to load the `Retinaface` model. Choose which line of code to use based on the model you download. ```python from maix import camera, display, image, nn, app import math detector nn.Retinaface(model \"/root/models/retinaface.mud\") # detector nn.FaceDetector(model \"/root/models/face_detector.mud\") cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) dis display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.4, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) radius math.ceil(obj.w / 10) img.draw_keypoints(obj.points, image.COLOR_RED, size radius if radius < 5 else 4) dis.show(img) ``` ## Model Downloads and Other Resolution Models Download the models; the compressed package contains multiple resolutions to choose from. Higher resolution models are more accurate but take longer to process: * [Face Detector 1MB with landmark](https://maixhub.com/model/zoo/377) * [Retinaface](https://maixhub.com/model/zoo/378) * [YOLOv8 face](https://maixhub.com/model/zoo/407) ## dual_buff Dual Buffer Acceleration You may have noticed that the model initialization uses `dual_buff` (which defaults to `True`). Enabling the `dual_buff` parameter can improve running efficiency and increase the frame rate. For detailed principles and usage notes, see [dual_buff Introduction](./dual_buff.html)."},"/maixpy/doc/en/vision/qrcode.html":{"title":"MaixCAM MaixPy QR Code Recognition","content":" title: MaixCAM MaixPy QR Code Recognition update: date: 2024 04 03 author: lxowalle version: 1.0.0 content: Initial document Before reading this article, make sure you are familiar with how to develop with MaixCAM. For details, please read [Quick Start](../index.html). ## Introduction This article explains how to use MaixPy for QR code recognition. ## Using MaixPy to Recognize QR Codes MaixPy's `maix.image.Image` includes the `find_qrcodes` method for QR code recognition. ### How to Recognize QR Codes A simple example that recognizes QR codes and draws a bounding box: ```python from maix import image, camera, display cam camera.Camera(320, 240) disp display.Display() while True: img cam.read() qrcodes img.find_qrcodes() for qr in qrcodes: corners qr.corners() for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_RED) img.draw_string(qr.x(), qr.y() 15, qr.payload(), image.COLOR_RED) disp.show(img) ``` Steps: 1. Import the image, camera, and display modules: ```python from maix import image, camera, display ``` 2. Initialize the camera and display: ```python cam camera.Camera(320, 240) # Initialize the camera with a resolution of 320x240 in RGB format disp display.Display() ``` 3. Capture and display images from the camera: ```python while True: img cam.read() disp.show(img) ``` 4. Use the `find_qrcodes` method to detect QR codes in the camera image: ```python qrcodes img.find_qrcodes() ``` `img` is the camera image captured by `cam.read()`. When initialized as `cam camera.Camera(320, 240)`, the `img` object is a 320x240 resolution RGB image. `img.find_qrcodes` searches for QR codes and saves the results in `qrcodes` for further processing. 5. Process and display the results of QR code recognition on the screen: ```python for qr in qrcodes: corners qr.corners() for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_RED) img.draw_string(qr.x(), qr.y() 15, qr.payload(), image.COLOR_RED) ``` `qrcodes` contains the results from `img.find_qrcodes()`. If no QR codes are found, `qrcodes` will be empty. `qr.corners()` retrieves the coordinates of the four corners of the detected QR code. `img.draw_line()` uses these coordinates to draw the QR code outline. `img.draw_string` displays information about the QR code content and position. `qr.x()` and `qr.y()` retrieve the x and y coordinates of the QR code's top left corner, and `qr.payload()` retrieves the content of the QR code. ### Common Parameter Explanation List common parameters and their explanations. If you cannot find parameters that fit your application, consider whether to use a different algorithm or extend the functionality based on the current algorithm's results. Parameter Description Example roi Sets the rectangular area for the algorithm to compute, where roi [x, y, w, h], x and y denote the top left coordinates of the rectangle, and w and h denote the width and height of the rectangle, defaulting to the entire image. Compute the area with coordinates (50,50) and width and height of 100:<br />`img.find_qrcodes(roi [50, 50, 100, 100])` qrcoder_type Set the QR code library decoder type; you can choose either `image.QRCodeDecoderType.QRCODE_DECODER_TYPE_ZBAR` or `image::QRCodeDecoderType::QRCODE_DECODER_TYPE_QUIRC`. `QRCODE_DECODER_TYPE_ZBAR` offers faster recognition speed and higher accuracy at lower resolutions. `QRCODE_DECODER_TYPE_QUIRC` is relatively faster at higher resolutions but with slightly lower accuracy. By default, `QRCODE_DECODER_TYPE_ZBAR` is used.<br />Effective in version 4.7.7 and later. img.find_qrcodes(decoder_type image.QRCodeDecoderType.QRCODE_DECODER_TYPE_ZBAR) This article introduces common methods. For more API details, refer to the [image](../../../api/maix/image.html) section of the API documentation."},"/maixpy/doc/en/vision/segmentation.html":{"title":"MaixCAM MaixPy Image Semantic Segmentation","content":" title: MaixCAM MaixPy Image Semantic Segmentation ## Introduction Image semantic segmentation refers to identifying specific objects in an image and recognizing the pixels that represent the parts of those objects. For example, in the image below, the human body and the dog are identified, and their body parts are segmented. This can be used for collision detection, autonomous vehicle navigation, area measurement, and more. ![](../../assets/yolov8_seg.jpg) ## Image Semantic Segmentation with MaixPy MaixPy includes `YOLOv8 seg` and `YOLO11 seg` for object detection and image segmentation. MaixPy provides a model for 80 object categories from the COCO dataset by default. > To use YOLOv8, MaixPy version must be > 4.4.0 > To use YOLO11, MaixPy version must be > 4.7.0 The following code demonstrates the usage, and you can also find it in [MaixPy examples](https://github.com/sipeed/maixpy/tree/main/examples/). ```python from maix import camera, display, image, nn, app, time detector nn.YOLOv8(model \"/root/models/yolov8n_seg.mud\", dual_buff True) # detector nn.YOLO11(model \"/root/models/yolo11n_seg.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) dis display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: # img.draw_image(obj.x, obj.y, obj.seg_mask) detector.draw_seg_mask(img, obj.x, obj.y, obj.seg_mask, threshold 127) img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) dis.show(img) ``` > To switch between YOLOv8 and YOLO11, just modify the commented part of the above code. ## Models with More Resolutions The default model resolution is 320x224. For models with different resolutions, download them from the MaixHub model library: * YOLOv8 seg: [[MaixHub Model Library](https://maixhub.com/model/zoo/413)](https://maixhub.com/model/zoo/413) * YOLO11 seg: [[MaixHub Model Library](https://maixhub.com/model/zoo/455)](https://maixhub.com/model/zoo/455) ## dual_buff for Double Buffering Acceleration You may notice that `dual_buff` is used for model initialization (default value is `True`). Enabling the `dual_buff` parameter can improve efficiency and increase the frame rate. For more details and considerations, refer to the [dual_buff Introduction](./dual_buff.html). ## Customizing Your Own Object Segmentation Model The provided models are based on the 80 categories from the COCO dataset. If this does not meet your needs, you can train your own specific object detection and segmentation model. Follow the instructions in [Offline Training YOLOv8/YOLO11](./customize_model_yolov8.html) to use the official YOLOv8/YOLO11 model training method, and then convert it to a model format supported by MaixCAM."},"/maixpy/doc/en/vision/image_ops.html":{"title":"MaixCAM MaixPy Basic Image Operations","content":" title: MaixCAM MaixPy Basic Image Operations update: date: 2024 04 03 author: neucrack version: 1.0.0 content: Initial document ## Introduction Images play a very important role in visual applications. Whether it's a picture or a video, since a video is essentially a series of frames, image processing is the foundation of visual applications. ## API Documentation This document introduces common methods. For more APIs, refer to the documentation of the maix.image module. ## Image Formats MaixPy provides a basic image module `image`, where the most important part is the `image.Image` class, which is used for image creation and various basic image operations, as well as image loading and saving. There are many image formats, and we generally use `image.Format.FMT_RGB888` or `image.Format.FMT_RGBA8888` or `image.Format.FMT_GRAYSCALE` or `image.Format.FMT_BGR888`, etc. We all know that the three colors `RGB` can synthesize any color, so in most cases, we use `image.Format.FMT_RGB888`, which is sufficient. `RGB888` is `RGB packed` in memory, i.e., the arrangement in memory is: `pixel1_red, pixel1_green, pixel1_blue, pixel2_red, pixel2_green, pixel2_blue, ...` arranged in sequence. ## Creating an Image Creating an image is very simple, you only need to specify the width and height of the image, and the image format: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) print(img) print(img.width(), img.height(), img.format()) ``` `320` is the width of the image, `240` is the height of the image, and `image.Format.FMT_RGB888` is the format of the image. The format parameter can be omitted, and the default is `image.Format.FMT_RGB888`. Here, you can get the width, height, and format of the image using `img.width()`, `img.height()`, and `img.format()`. ## Displaying on the Screen MaixPy provides the `maix.display.Display` class, which can conveniently display images: ``` from maix import image, display disp display.Display() img image.Image(320, 240, image.Format.FMT_RGB888) disp.show(img) ``` Note that here, since there is no image data, a black image is displayed. See the following sections for how to modify the image. ## Reading Images from the File System MaixPy provides the `maix.image.load` method, which can read images from the file system: ``` from maix import image img image.load(\"/root/image.jpg\") if img is None: raise Exception(f\"load image failed\") print(img) ``` Note that here, `/root/image.jpg` has been transferred to the board in advance. You can refer to the previous tutorials for the method. It supports `jpg` and `png` image formats. ## Saving Images to the File System MaixPy's `maix.image.Image` provides the `save` method, which can save images to the file system: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) # do something with img img.save(\"/root/image.jpg\") ``` ## Drawing Rectangles `image.Image` provides the `draw_rect` method, which can draw rectangles on the image: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_rect(10, 10, 100, 100, image.Color.from_rgb(255, 0, 0)) ``` Here, the parameters are: `x`, `y`, `w`, `h`, `color`. `x` and `y` are the coordinates of the top left corner of the rectangle, `w` and `h` are the width and height of the rectangle, and `color` is the color of the rectangle, which can be created using the `image.Color.from_rgb` method. You can specify the line width of the rectangle using `thickness`, which defaults to `1`. You can also draw a solid rectangle by passing `thickness 1`: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_rect(10, 10, 100, 100, (255, 0, 0), thickness 1) ``` ## Writing Strings `image.Image` provides the `draw_string` method, which can write text on the image: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_string(10, 10, \"Hello MaixPy\", image.Color.from_rgb(255, 0, 0)) ``` Here, the parameters are: `x`, `y`, `text`, `color`. `x` and `y` are the coordinates of the top left corner of the text, `text` is the text to be written, and `color` is the color of the text, which can be created using the `image.Color.from_rgb` method. You can also enlarge the font by passing the `scale` parameter: ``` img.draw_string(10, 10, \"Hello MaixPy\", image.Color.from_rgb(255, 0, 0), scale 2) ``` Get the width and height of the font: ``` w, h img.string_size(\"Hello MaixPy\", scale 2) print(w, h) ``` **Note** that here, `scale` is the magnification factor, and the default is `1`. It should be consistent with `draw_string`. ## Chinese support and custom fonts The `image` module supports loading `ttf/otf` fonts. The default font only supports English. If you want to display Chinese or custom fonts, you can first download the font file to the device and then load the font. The system also has several built in fonts, under the `/maixapp/share/font` directory, code example: ```python from maix import image, display, app, time image.load_font(\"sourcehansans\", \"/maixapp/share/font/SourceHanSansCN Regular.otf\", size 32) print(\"fonts:\", image.fonts()) image.set_default_font(\"sourcehansans\") disp display.Display() img image.Image(disp.width(), disp.height()) img.draw_string(2, 2, \"Hello! Hello, world!\", image.Color.from_rgba(255, 0, 0)) disp.show(img) while not app.need_exit(): time.sleep(1) ``` Load the font file, then set the default font, or you can set the default font without setting the default font, and set the parameters in the writing function: ```python img.draw_string(2, 2, \"你好！Hello, world!\", image.Color.from_rgba(255, 0, 0), font \"sourcehansans\") ``` Note that the `string_size` method will also use the default font to calculate the size, and you can also use the `font` parameter to set the font to be calculated separately. ## Drawing Lines `image.Image` provides the `draw_line` method, which can draw lines on the image: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_line(10, 10, 100, 100, image.Color.from_rgb(255, 0, 0)) ``` Here, the parameters are: `x1`, `y1`, `x2`, `y2`, `color`. `x1` and `y1` are the coordinates of the starting point of the line, `x2` and `y2` are the coordinates of the end point of the line, and `color` is the color of the line, which can be created using the `image.Color.from_rgb` method. ## Drawing Circles `image.Image` provides the `draw_circle` method, which can draw circles on the image: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_circle(100, 100, 50, image.Color.from_rgb(255, 0, 0)) ``` Here, the parameters are: `x`, `y`, `r`, `color`. `x` and `y` are the coordinates of the center of the circle, `r` is the radius, and `color` is the color of the circle, which can be created using the `image.Color.from_rgb` method. ## Resizing Images `image.Image` provides the `resize` method, which can resize images: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.resize(160, 120) print(img, img_new) ``` Note that here, the `resize` method returns a new image object, and the original image remains unchanged. ## Cropping Images `image.Image` provides the `crop` method, which can crop images: ``` from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.crop(10, 10, 100, 100) print(img, img_new) ``` Note that here, the `crop` method returns a new image object, and the original image remains unchanged. ## Rotating Images `image.Image` provides the `rotate` method, which can rotate images: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.rotate(90) print(img, img_new) ``` Note that here, the `rotate` method returns a new image object, and the original image remains unchanged. ## Copying Images `image.Image` provides the `copy` method, which can copy an independent image: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.copy() print(img, img_new) ``` ## Affine Transformations `image.Image` provides the `affine` method, which can perform affine transformations. By providing the coordinates of three or more points in the current image and the corresponding coordinates in the target image, you can automatically perform operations such as rotation, scaling, and translation on the image to transform it into the target image: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.affine([(10, 10), (100, 10), (10, 100)], [(10, 10), (100, 20), (20, 100)]) print(img, img_new) ``` For more parameters and usage, please refer to the API documentation. ## Drawing Keypoints `image.Image` provides the `draw_keypoints` method, which can draw keypoints on the image: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) keypoints [10, 10, 100, 10, 10, 100] img.draw_keypoints(keypoints, image.Color.from_rgb(255, 0, 0), size 10, thickness 1, fill False) ``` This draws three red keypoints at the coordinates `(10, 10)`, `(100, 10)`, and `(10, 100)`. The size of the keypoints is `10`, the line width is `1`, and they are not filled. ## Drawing Crosses `image.Image` provides the `draw_cross` method, which can draw crosses on the image: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_cross(100, 100, image.Color.from_rgb(255, 0, 0), size 5, thickness 1) ``` This draws a red cross at the coordinate `(100, 100)`. The extension size of the cross is `5`, so the length of the line segment is `2 * size + thickness`, and the line width is `1`. ## Drawing Arrows `image.Image` provides the `draw_arrow` method, which can draw arrows on the image: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_arrow(10, 10, 100, 100, image.Color.from_rgb(255, 0, 0), thickness 1) ``` This draws a red arrow starting from the coordinate `(10, 10)`, with the end point at `(100, 100)`, and a line width of `1`. ## Drawing Images `image.Image` provides the `draw_image` method, which can draw images on the image: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img2 image.Image(100, 100, image.Format.FMT_RGB888) img2.draw_rect(10, 10, 90, 90, image.Color.from_rgb(255, 0, 0)) img.draw_image(10, 10, img2) ``` ## Converting Formats `image.Image` provides the `to_format` method, which can convert image formats: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.to_format(image.Format.FMT_BGR888) print(img, img_new) img_jpg img.to_format(image.Format.FMT_JPEG) print(img, img_new) ``` Note that here, the `to_format` method returns a new image object, and the original image remains unchanged. ## Converting between Numpy/OpenCV and maix.image.Image Formats Refer to [MaixPy use OpenCV documentation](./opencv.html) ## Converting between bytes Data `image.Image` provides the `to_bytes` method, which can convert an image to `bytes` data: ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) data img.to_bytes() print(type(data), len(data), img.data_size()) img_jpeg image.from_bytes(320, 240, image.Format.FMT_RGB888, data) print(img_jpeg) img img_jpeg.to_format(image.Format.FMT_RGB888) print(img) ``` Here, `to_bytes` returns a new `bytes` object, which is independent memory and does not affect the original image. The `image.Image` constructor can directly construct an image object from `bytes` data by passing the `data` parameter. Note that the new image is also independent memory and does not affect `data`. Since memory copying is involved, this method is relatively time consuming and should not be used frequently. > If you want to optimize your program without copying (not recommended for casual use, as poorly written code can easily cause crashes), please refer to the API documentation. ## More Basic API Usage For more API usage, please refer to the documentation of the maix.image module."},"/maixpy/doc/en/vision/touchscreen.html":{"title":"MaixPy / MaixCAM Touchscreen Usage Guide","content":" title: MaixPy / MaixCAM Touchscreen Usage Guide ## Introduction MaixCAM comes equipped with a touchscreen, which, when used in conjunction with applications, can facilitate numerous engaging functionalities. We can utilize APIs to detect touch interactions on the touchscreen. ## Reading Touch Input with MaixPy MaixPy offers a straightforward `maix.touchscreen.TouchScreen` class for reading touch inputs. Here's an example: ```python from maix import touchscreen, app, time ts touchscreen.TouchScreen() pressed_already False last_x 0 last_y 0 last_pressed False while not app.need_exit(): x, y, pressed ts.read() if x ! last_x or y ! last_y or pressed ! last_pressed: print(x, y, pressed) last_x x last_y y last_pressed pressed if pressed: pressed_already True else: if pressed_already: print(f\"clicked, x: {x}, y: {y}\") pressed_already False time.sleep_ms(1) # sleep some time to free some CPU usage ``` ## Interactivity with the Screen Integrating the screen can enable various interactive user experiences. More examples can be found in the [MaixPy/examples/vision/touchscreen](https://github.com/sipeed/MaixPy) directory. As previously described, to display content on the screen, typically, a `maix.image.Image` object is created and displayed using `disp.show(img)`. Implementing a button is as simple as drawing one on the image and then detecting touches within its area, ensuring that the image's dimensions match those of the screen: ```python from maix import touchscreen, app, time, display, image ts touchscreen.TouchScreen() disp display.Display() img image.Image(disp.width(), disp.height()) # draw exit button exit_label \"< Exit\" size image.string_size(exit_label) exit_btn_pos [0, 0, 8*2 + size.width(), 12 * 2 + size.height()] img.draw_string(8, 12, exit_label, image.COLOR_WHITE) img.draw_rect(exit_btn_pos[0], exit_btn_pos[1], exit_btn_pos[2], exit_btn_pos[3], image.COLOR_WHITE, 2) def is_in_button(x, y, btn_pos): return x > btn_pos[0] and x < btn_pos[0] + btn_pos[2] and y > btn_pos[1] and y < btn_pos[1] + btn_pos[3] while not app.need_exit(): x, y, pressed ts.read() if is_in_button(x, y, exit_btn_pos): app.set_exit_flag(True) img.draw_circle(x, y, 1, image.Color.from_rgb(255, 255, 255), 2) disp.show(img) ``` ## Handling Different Screen and Image Sizes In the example above, the `img` matches the screen size. If your `img` and screen sizes differ (e.g., using `img image.Image(240, 240)` on a `640x480` screen), the default behavior of `disp.show(img)` is `image.Fit.FIT_CONTAIN`, which scales the image to `480x480` and fills the sides with black. If a button is drawn on the `240x240` image, such as at coordinates `(0, 0, 60, 40)`, the button will also be scaled up. Thus, the coordinates for touch detection should be adjusted to `((640 480) / 2, 0, 480/240*60, 480/240*40)`, which translates to `(80, 0, 120, 80)`. For convenience in scaling images and quickly calculating the positions and sizes of points or rectangles in the scaled image, the `image.resize_map_pos` function is provided: ```python from maix import touchscreen, app, time, display, image ts touchscreen.TouchScreen() disp display.Display() img image.Image(240, 240) img.draw_rect(0, 0, img.width(), img.height(), image.COLOR_WHITE) # draw exit button exit_label \"< Exit\" size image.string_size(exit_label) exit_btn_pos [0, 0, 8*2 + size.width(), 12 * 2 + size.height()] img.draw_string(8, 12, exit_label, image.COLOR_WHITE) img.draw_rect(exit_btn_pos[0], exit_btn_pos[1], exit_btn_pos[2], exit_btn_pos[3], image.COLOR_WHITE, 2) # 图像按键坐标映射到屏幕上的坐标 exit_btn_disp_pos image.resize_map_pos(img.width(), img.height(), disp.width(), disp.height(), image.Fit.FIT_CONTAIN, exit_btn_pos[0], exit_btn_pos[1], exit_btn_pos[2], exit_btn_pos[3]) def is_in_button(x, y, btn_pos): return x > btn_pos[0] and x < btn_pos[0] + btn_pos[2] and y > btn_pos[1] and y < btn_pos[1] + btn_pos[3] while not app.need_exit(): x, y, pressed ts.read() if is_in_button(x, y, exit_btn_disp_pos): app.set_exit_flag(True) # 屏幕的坐标映射回图像上对应的坐标，然后在图像上画点 x, y image.resize_map_pos_reverse(img.width(), img.height(), disp.width(), disp.height(), image.Fit.FIT_CONTAIN, x, y) img.draw_circle(x, y, 1, image.Color.from_rgb(255, 255, 255), 2) disp.show(img, fit image.Fit.FIT_CONTAIN) ```"},"/maixpy/doc/en/vision/customize_model_yolov5.html":{"title":"Offline Training of YOLOv5 Model for Custom Object Detection with MaixCAM MaixPy","content":" title: Offline Training of YOLOv5 Model for Custom Object Detection with MaixCAM MaixPy update: date: 2024 6 20 version: v1.0 author: neucrack content: Documentation written ## Introduction The default official model provides detection for 80 types of objects. If this does not meet your needs, you can train your own detection objects using two methods: * Use [MaixHub Online Training](./maixhub_train.html), which is convenient and fast, without needing to buy a server or set up an environment, just a few clicks of the mouse. * Set up a training environment on your own computer or server. The former is simple and quick, while the latter uses your own computer and the number of training images is not limited, but the latter is much more difficult. **Note:** This article explains how to customize training, but some basic knowledge is assumed. If you do not have this knowledge, please learn it yourself: * This article will not explain how to install the training environment. Please search and install it yourself (Pytorch environment installation) and test it. * This article will not explain the basic concepts of machine learning or basic Linux usage knowledge. If you think there is something in this article that needs improvement, feel free to click `Edit this article` in the upper right corner to contribute and submit a documentation PR. ## Process and Goals of this Article To use our model on MaixPy (MaixCAM), the following process is required: * Set up the training environment (this is not covered in this article, please search for Pytorch training environment setup). * Pull the [yolov5](https://github.com/ultralytics/yolov5) source code to your local machine. * Prepare the dataset and format it as required by the yolov5 project. * Train the model to get an `onnx` model file, which is the final output file of this article. * Convert the `onnx` model to a `MUD` file supported by MaixPy, which is detailed in [MaixCAM Model Conversion](../ai_model_converter/maixcam.html). * Use MaixPy to load and run the model. ## Reference Articles Since this is a relatively common operational process, this article only provides an overview. For specific details, you can refer to the **[YOLOv5 official code and documentation](https://github.com/ultralytics/yolov5)** (**recommended**), and search for training tutorials to ultimately export the onnx file. Here are some articles from the MaixHub community: * [Deploy yolov5s custom model on maixcam](https://maixhub.com/share/23) * [【Process Sharing】YOLOv5 training custom dataset and deploying on Maixcam](https://maixhub.com/share/32) * [YOLOv5 cat and dog recognition model—free cloud training (reproducible by beginners)](https://maixhub.com/share/25) If you find any good articles, feel free to modify this article and submit a PR. ## Exporting YOLOv5 ONNX Model File YOLOv5 provides an export option. Execute the following command in the `yolov5` directory: ```shell python export.py weights ../yolov5s.pt include onnx img 224 320 ``` This command loads the `pt` parameter file and converts it to `onnx`, while also specifying the resolution. Note that the height comes first, followed by the width. The model was trained with `640x640`, but we re specified the resolution to improve the running speed. The resolution `320x224` is used because it is closer to the MaixCAM screen ratio for better display. You can set it according to your needs. ## MaixCAM MUD File When converting onnx to `mud` format model files, refer to [MaixCAM Model Conversion](../ai_model_converter/maixcam.html). You will eventually get a `mud` file and a `cvimodel` file. The content of the `mud` file is: ```ini [basic] type cvimodel model yolov8n.cvimodel [extra] model_type yolov8 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush ``` Replace the parameters according to the content of your training. For example, if you train to detect digits `0 9`, then just replace `labels 0,1,2,3,4,5,6,7,8,9`, and then place the two files in the same directory and load the `mud` file when running the model. ## Upload share on MaixHub Share your model on [MaixHub model zoo](https://maixhub.com/model/zoo?platform maixcam) 上传并分享你的模型，可以多提供几个分辨率供大家选择。"},"/maixpy/doc/en/vision/line_tracking.html":{"title":"MaixCAM MaixPy Line Tracking","content":" title: MaixCAM MaixPy Line Tracking update: date: 2024 05 09 author: lxowalle version: 1.0.0 content: Initial document Before reading this article, make sure you already know how to develop MaixCAM. For details, please read [Quick Start](../index.html). ## Introduction In vision applications, the function of tracking line is often required in applications such as line following robot. In this article, we will describe: How to use MaixPy to tracking line. How to tracking line using MaixCam's default application ## How to use MaixPy to tracking line The `maix.image.Image` module in MaixPy provides the `get_regression` method, which can conveniently tracking line. ### Code example A simple example of finding and drawing a line. ```python from maix import camera, display, image cam camera.Camera(320, 240) disp display.Display() # thresholds [[0, 80, 40, 80, 10, 80]] # red thresholds [[0, 80, 120, 10, 0, 30]] # green # thresholds [[0, 80, 30, 100, 120, 60]] # blue while 1: img cam.read() lines img.get_regression(thresholds, area_threshold 100) for a in lines: img.draw_line(a.x1(), a.y1(), a.x2(), a.y2(), image.COLOR_GREEN, 2) theta a.theta() rho a.rho() if theta > 90: theta 270 theta else: theta 90 theta img.draw_string(0, 0, \"theta: \" + str(theta) + \", rho: \" + str(rho), image.COLOR_BLUE) disp.show(img) ``` Steps: 1. import image, camera, display modules ```python from maix import image, camera, display ``` 2. Initialize camera and display ```python cam camera.Camera(320, 240) # Initialise camera, output resolution 320x240 in RGB format. disp display.Display() ``` 3. Get the image from the camera and display it ```python while 1: img cam.read() disp.show(img) ``` 4. Call the `get_regression` method to find the straight line in the camera image and draw it to the screen ```python lines img.get_regression(thresholds, area_threshold 100) for a in lines: img.draw_line(a.x1(), a.y1(), a.x2(), a.y2(), image.COLOR_GREEN, 2) theta a.theta() rho a.rho() if theta > 90: theta 270 theta else: theta 90 theta img.draw_string(0, 0, \"theta: \" + str(theta) + \", rho: \" + str(rho), image.COLOR_BLUE) ``` `img` is the camera image read via `cam.read()`, when initialised as `cam camera.Camera(320, 240)`, the `img` object is an RGB image with a resolution of 320x240. `img.get_regression` is used to find straight lines, `thresholds` is a list of colour thresholds, each element is a colour threshold, multiple thresholds are passed in if multiple thresholds are found at the same time, and each colour threshold has the format `[L_MIN, L_MAX, A_MIN, A_MAX, B_MIN, B_MAX]`, where ` L`, `A`, `B` are the three channels of `LAB` colour space, `L` channel is the luminance, `A` channel is the red green channel, `B` channel is the blue yellow channel. `pixels_threshold` is a pixel area threshold used to filter some unwanted straight lines. `for a in lines` is used to iterate through the returned `Line` objects, where `a` is the current `Line` object. Normally the `get_regression` function will only return one `Line` object, but if you need to find more than one line, try the `find_line` method. Use `img.draw_line` to draw the found line, `a.x1(), a.y1(), a.x2(), a.y2()` represent the coordinates of the ends of the line. Use `img.draw_string` to show the angle between the line and the x axis in the upper left corner, and `a.theta()` is the angle between the line and the y axis, which is converted to `theta` for easier understanding, `a.rho()` is the length of the vertical line from the origin to the line. 5. Run the code through the maixvision, you can find the line, look at the effect! ![image 20240509110204007](../../../static/image/line_tracking_demo.jpg) ### Common Parameter Explanations Here are explanations of commonly used parameters. If you cannot find parameters that can implement your application, you may need to consider using other algorithms or extending the required functionality based on the current algorithm's results. Parameter Description Example thresholds Thresholds based on the LAB color space, thresholds [[l_min, l_max, a_min, a_max, b_min, b_max]], representing:<br/>Brightness range [l_min, l_max]<br/>Green to red component range [a_min, a_max]<br/>Blue to yellow component range [b_min, b_max]<br/>Multiple thresholds can be set simultaneously Set two thresholds to detect red and green<br/>```img.find_blobs(thresholds [[0, 80, 40, 80, 10, 80], [0, 80, 120, 10, 0, 30]])```<br/>Red threshold is [0, 80, 40, 80, 10, 80]<br/>Green threshold is [0, 80, 120, 10, 0, 30] invert Enable threshold inversion, when enabled, the passed thresholds are inverted. Default is False. Enable threshold inversion<br/>```img.find_blobs(invert True)``` roi Set the rectangular region for the algorithm to compute, roi [x, y, w, h], where x and y represent the coordinates of the top left corner of the rectangle, and w and h represent the width and height of the rectangle, respectively. The default is the entire image. Compute the region at (50, 50) with a width and height of 100<br/>```img.find_blobs(roi [50, 50, 100, 100])``` area_threshold Filter out blobs with a pixel area smaller than area_threshold, in units of pixels. The default is 10. This parameter can be used to filter out some useless small blobs. Filter out blobs with an area smaller than 1000<br/>```img.find_blobs(area_threshold 1000)``` pixels_threshold Filter out blobs with fewer valid pixels than pixels_threshold. The default is 10. This parameter can be used to filter out some useless small blobs. Filter out blobs with fewer than 1000 valid pixels<br/>```img.find_blobs(pixels_threshold 1000)``` This article introduces commonly used methods. For more APIs, please see the [image](../../../api/maix/image.html) section of the API documentation. ### Increasing the speed of line tracking Here are a few ways to increase the speed of line tracking 1. Choose a suitable resolution The larger the resolution, the slower the calculation speed, you can choose a more suitable resolution according to the recognition distance and accuracy requirements. 2. Use gray scale image When using gray scale recognition, the algorithm will only process one channel, there is a faster recognition speed, in the environment of a single color will be very useful. Note that only `l_min` and `l_max` are valid when passing `thresholds` to `get_regression` when using gray scale image recognition. Methods for get gray scale image: ```python # Example 1 cam camera.Camera(320, 240， image.Format.FMT_GRAYSCALE) \t# Support after MaixPy v4.2.1 gray_img cam.read()\t\t\t\t\t\t\t\t\t\t\t# get gray scale image # Example 2 cam camera.Camera(320, 240) img cam.read() gray_img img.to_format(image.Format.FMT_GRAYSCALE)\t\t\t# get gray scale image ``` ## How to tracking line using MaixCam's default application To quickly verify the line tracking functionality, you can use the `line_tracking` application provided by MaixCam to experience the line finding effect. ### How to use it 1. Select and open the `Line tracking` application. 2. Click on the line in the screen that needs to be identified and the colour of the line will be displayed on the left hand side 3. Click on the colour to be detected on the left (the colour below L A B in the screen) 4. The line will be identified and the coordinates and angle of the line will be output from the serial port. ### Demo <video src \"/static/video/line_tracking_app.mp4\" controls \"controls\" width \"100%\" height \"auto\"></video> ### Advanced operations #### Manual adjustment of LAB threshold to tracking line The application provides manual setting of LAB threshold to tracking line accurately. Steps: 1. `Click` the `options icon` in the bottom left corner to enter configuration mode. 2. Point the `camera` at the `object` you need to `find`, `click` on the `target object` on the screen, and the `left side` will display a `rectangular frame` of the object's color and show the `LAB values` of that color. 3. Click on the bottom options `L Min`, `L Max`, `A Min`, `A Max`, `B Min`, `B Max`. After clicking, a slider will appear on the right side to set the value for that option. These values correspond to the minimum and maximum values of the L, A, and B channels in the LAB color format, respectively. 4. Referring to the `LAB values` of the object color calculated in step 2, adjust `L Min`, `L Max`, `A Min`, `A Max`, `B Min`, `B Max` to appropriate values to identify the corresponding color blobs. For example, if `LAB (20, 50, 80)`, since `L 20`, to accommodate a certain range, set `L Min 10` and `L Max 30`. Similarly, since `A 50`, set `A Min 40` and `A Max 60`. Since `B 80`, set `B Min 70` and `B Max 90`. #### Getting Detection Data via Serial Protocol The line tracking application supports reporting detected straight line information via the serial port (default baud rate is 115200). Since only one report message is sent, we can illustrate the content of the report message with an example. For instance, if the report message is: ```shell AA CA AC BB 0E 00 00 00 00 E1 09 FC 01 01 00 E9 01 6F 01 57 00 C1 C6 ``` `AA CA AC BB`: Protocol header, fixed content `0E 00 00 00`: Data length, the total length excluding the protocol header and data length, here means the length is 14. `E1`: Flag bit, used to identify the serial message flag `09`: Command type, for the line tracking application, this value is fixed at 0x09. `FC 01 01 00 E9 01 6F 01 57 00`: The coordinates and angle information for both ends of line, with each value represented as a 2 byte value in little end format. `FC 01` and `01 00` indicate that the coordinates of the first endpoint are (508, 1), `E9 01` and `6F 01` indicate that the coordinates of the second endpoint are (489, 367), and `57 00` indicates that the angle of the line to the x axis is 87 degrees `C1 C6`: CRC checksum value, used to verify if the frame data has errors during transmission."},"/maixpy/doc/en/vision/dual_buff.html":{"title":"Introduction to Running Models in Dual Buffer Mode with MaixPy MaixCAM","content":" title: Introduction to Running Models in Dual Buffer Mode with MaixPy MaixCAM ## Introduction You may have noticed that there is a parameter `dual_buff True` when initializing the code for model running. For example, in `YOLOv5`: ```python from maix import camera, display, image, nn, app detector nn.YOLOv5(model \"/root/models/yolov5s.mud\", dual_buff True) # detector nn.YOLOv8(model \"/root/models/yolov8n.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) dis display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) dis.show(img) ``` Generally, this parameter defaults to `True`, unless you manually set `dual_buff False` to disable the dual buffer function. Enabling this feature improves running efficiency, thereby increasing the frame rate (assuming the camera's frame rate is not limited, the above code will halve the loop time on MaixCAM, effectively doubling the frame rate). However, there are drawbacks. The `detect` function returns the result of the previous call to the `detect` function, meaning there is a one frame delay between the result and the input. If you want the detection result to match the input `img` rather than the previous frame, disable this feature. Additionally, due to the preparation of dual buffers, memory usage will increase. If you encounter insufficient memory issues, you will also need to disable this feature. ## Principle Model object detection involves several steps: * Capturing the image * Image preprocessing * Model execution * Post processing the results Only the model execution step runs on the hardware NPU, while other steps run on the CPU. If `dual_buff` is set to `False`, during `detect`, the CPU preprocesses (while the NPU is idle), then the NPU performs the computation (while the CPU is idle waiting for the NPU to finish), and then the CPU post processes (while the NPU is idle). This process is linear and relatively simple. However, a problem arises because either the CPU or the NPU is always idle. When `dual_buff True` is enabled, the CPU preprocesses and hands off to the NPU for computation. At this point, the CPU does not wait for the NPU to produce results but instead exits the `detect` function and proceeds to the next camera read and preprocess. Once the NPU finishes its computation, the CPU has already prepared the next data, immediately passing it to the NPU to continue computing without giving the NPU any idle time. This maximizes the efficient simultaneous operation of both the CPU and NPU. However, note that if the camera frame rate is not high enough, it will still limit the overall frame rate."},"/maixpy/doc/en/vision/find_blobs.html":{"title":"MaixCAM MaixPy Find Blobs","content":" title: MaixCAM MaixPy Find Blobs update: date: 2024 04 03 author: neucrack version: 1.0.0 content: Initial documentation date: 2024 04 03 author: lxowalle version: 1.0.1 content: Added detailed usage for finding blobs Before reading this article, make sure you know how to develop with MaixCAM. For details, please read [Quick Start](../index.html). ## Introduction This article will introduce how to use MaixPy to find color blobs and how to use the default application of MaixCam to find color blobs. In vision applications, finding color blobs is a very common requirement, such as robots finding color blobs, automated production lines finding color blobs, etc., which requires identifying specific color areas in the image and obtaining information such as the position and size of these areas. ## Using MaixPy to Find Blobs The `maix.image.Image` module in MaixPy provides the `find_blobs` method, which can conveniently find color blobs. ### How to Find Blobs A simple example to find color blobs and draw bounding boxes: ```python from maix import image, camera, display cam camera.Camera(320, 240) disp display.Display() # Select the corresponding configuration based on the color of the blob thresholds [[0, 80, 40, 80, 10, 80]] # red # thresholds [[0, 80, 120, 10, 0, 30]] # green # thresholds [[0, 80, 30, 100, 120, 60]] # blue while 1: img cam.read() blobs img.find_blobs(thresholds, pixels_threshold 500) for blob in blobs: img.draw_rect(blob[0], blob[1], blob[2], blob[3], image.COLOR_GREEN) disp.show(img) ``` Steps: 1. Import the image, camera, and display modules ```python from maix import image, camera, display ``` 2. Initialize the camera and display ```python cam camera.Camera(320, 240)\t# Initialize the camera with an output resolution of 320x240 in RGB format disp display.Display() ``` 3. Get the image from the camera and display it ```python while 1: img cam.read() disp.show(img) ``` 4. Call the `find_blobs` method to find color blobs in the camera image and draw them on the screen ```python blobs img.find_blobs(thresholds, pixels_threshold 500) for blob in blobs: img.draw_rect(blob[0], blob[1], blob[2], blob[3], image.COLOR_GREEN) ``` `img` is the camera image obtained through `cam.read()`. When initialized with `cam camera.Camera(320, 240)`, the `img` object is an RGB image with a resolution of 320x240. `img.find_blobs` is used to find color blobs. `thresholds` is a list of color thresholds, where each element is a color threshold. Multiple thresholds can be passed in to find multiple colors simultaneously. Each color threshold is in the format `[L_MIN, L_MAX, A_MIN, A_MAX, B_MIN, B_MAX]`, where `L`, `A`, and `B` are the three channels in the LAB color space. The `L` channel represents brightness, the `A` channel represents the red green component, and the `B` channel represents the blue yellow component. `pixels_threshold` is a pixel count threshold used to filter out unwanted small blobs. `img.draw_rect` is used to draw bounding boxes around the color blobs. `blob[0]`, `blob[1]`, `blob[1]`, and `blob[1]` represent the x coordinate of the top left corner of the blob, the y coordinate of the top left corner of the blob, the width of the blob, and the height of the blob, respectively. ### Common Parameter Explanations Here are explanations of commonly used parameters. If you cannot find parameters that can implement your application, you may need to consider using other algorithms or extending the required functionality based on the current algorithm's results. Parameter Description Example thresholds Thresholds based on the LAB color space, thresholds [[l_min, l_max, a_min, a_max, b_min, b_max]], representing:<br/>Brightness range [l_min, l_max]<br/>Green to red component range [a_min, a_max]<br/>Blue to yellow component range [b_min, b_max]<br/>Multiple thresholds can be set simultaneously Set two thresholds to detect red and green<br/>```img.find_blobs(thresholds [[0, 80, 40, 80, 10, 80], [0, 80, 120, 10, 0, 30]])```<br/>Red threshold is [0, 80, 40, 80, 10, 80]<br/>Green threshold is [0, 80, 120, 10, 0, 30] invert Enable threshold inversion, when enabled, the passed thresholds are inverted. Default is False. Enable threshold inversion<br/>```img.find_blobs(invert True)``` roi Set the rectangular region for the algorithm to compute, roi [x, y, w, h], where x and y represent the coordinates of the top left corner of the rectangle, and w and h represent the width and height of the rectangle, respectively. The default is the entire image. Compute the region at (50, 50) with a width and height of 100<br/>```img.find_blobs(roi [50, 50, 100, 100])``` area_threshold Filter out blobs with a pixel area smaller than area_threshold, in units of pixels. The default is 10. This parameter can be used to filter out some useless small blobs. Filter out blobs with an area smaller than 1000<br/>```img.find_blobs(area_threshold 1000)``` pixels_threshold Filter out blobs with fewer valid pixels than pixels_threshold. The default is 10. This parameter can be used to filter out some useless small blobs. Filter out blobs with fewer than 1000 valid pixels<br/>```img.find_blobs(pixels_threshold 1000)``` This article introduces commonly used methods. For more APIs, please see the [image](../../../api/maix/image.html) section of the API documentation. ## Setting Thresholds Offline To quickly verify the function of find blobs, you can first use the find blobs application provided by MaixCam to experience the effect of finding color blobs. ### Demo Turn on the device, select `Find Blobs` application, then select the colour you want to identify, or customize the colour, then you can identify the corresponding colour, the `setting bar` at the bottom will show the `threshold range`, and the serial port will also output the coordinates and colour information of the identified coordinates. <video src \"/static/video/find_blobs.mp4\" controls \"controls\" width \"100%\" height \"auto\"></video> [source code address](https://github.com/sipeed/MaixCDK/tree/main/projects/app_find_blobs) ### Quick use #### Using the default threshold The find blobs app provides four configurations, `red`, `green`, `blue` and `user`, where `red`, `green` and `blue` are used to find `red`, `green` and `blue` colour blocks, and `user` customized thresholds are saved when the app is exited, and the next time the app is opened the thresholds from the last debugging are loaded. For quick experience, you can switch to the corresponding configuration by `clicking` the `button` at the bottom of the interface, the app interface is referenced below: ![](../../../static/image/find_blobs_app.jpg) #### Quick Debug Thresholds Method of operation: 1. Aim the `camera` at the `object` you need to `find`, `click` on the `target` on the screen, then the `left` side will show the `rectangle` of the corresponding colour of the object, and the LAB value of the object's colour. 2. Click on the rectangular box, the system will `automatically set' the LAB threshold, then the screen will draw the edge of the object. The advantage of this method is that it is easy and quick to set the threshold and find the corresponding colour block. The disadvantage is that it is not precise enough, you can fine tuning it manually in the next step. #### Manually fine tune the threshold Method of operation: 1. `Click` on the `Options icon` in the lower left corner to enter configuration mode 2. Aim the `camera` at the `object` you need to `find`, `click` on the `target object` on the screen, at this time the `left` side will show the `rectangular box` of the corresponding colour of the object, and display the `LAB value` of the object's colour. 3. Click on the lower option `L Min, L Max, A Min, A Max, B Min, B Max`, and a slider will appear on the right to set the value of this option. These values correspond to the minimum and maximum values of the L, A and B channels of the LAB colour format. 4. Referring to the `LAB value` of the object colour calculated in step 2, adjust `L Min, L Max, A Min, A Max, B Min, B Max` to the appropriate value to identify the corresponding colour block. For example, `LAB (20, 50, 80)`, since `L 20`, in order to fit a certain range, let `L Min 10`, `L Max 30`; similarly, since `A 50`, let `A Min 40`, `A Max 60`; since `B 80`, let `B Min 70`, `B Max 90`. This method can be more precise to find the right threshold, with the `Quick Debug Threshold` method, it is easy to find the desired threshold. #### Get recognition results via serial protocol The find blobs app supports reporting information about detected color blobs via the serial port (default baud rate is 115200). Since only one report message is sent, we can illustrate the content of the report message with an example. For instance, if the report message is: ``` shellCopy code AA CA AC BB 14 00 00 00 E1 08 EE 00 37 00 15 01 F7 FF 4E 01 19 00 27 01 5A 00 A7 20 ``` `AA CA AC BB`: Protocol header, content is fixed `14 00 00 00`: Data length, the total length excluding the protocol header and data length `E1`: Flag, used to identify the serial message flag `08`: Command type, for the find blobs app application, this value is fixed at 0x08 `EE 00 37 00 15 01 F7 FF 4E 01 19 00 27 01 5A 00`: Coordinates of the four vertices of the found color blob, with each value represented by 2 bytes in little endian format. `EE 00` and `37 00` represent the first vertex coordinate as (238, 55), `15 01` and `F7 FF` represent the second vertex coordinate as (277, 9), `4E 01` and `19 00` represent the third vertex coordinate as (334, 25), `27 01` and `5A 00` represent the fourth vertex coordinate as (295, 90). `A7 20`: CRC checksum value, used to verify if the frame data has errors during transmission. ## About the LAB Color Space The LAB color space, like the RGB color space, is a way to represent colors. LAB can represent all colors visible to the human eye. If you need to learn more about LAB, you can search for relevant articles online, which will provide more details. However, for you, it should be sufficient to understand why LAB is advantageous for MaixPy. Advantages of LAB for MaixPy: 1. The color gamut of the LAB color space is larger than that of RGB, so it can completely replace RGB. 2. In the LAB color space, since the L channel is the brightness channel, we often set it to a relatively large range (commonly [0, 80]), and when coding, we mainly focus on the A and B channels. This can save a lot of time spent struggling with how to select color thresholds. 3. The color perception in the LAB color space is more uniform and easier to debug with code. For example, if you only need to find red color blobs, you can fix the values of the L and B channels and only adjust the value of the A channel (in cases where high color accuracy is not required). For RGB channels, you generally need to adjust all three R, G, and B channels simultaneously to find suitable thresholds."},"/maixpy/doc/en/vision/self_learn_detector.html":{"title":"MaixCAM MaixPy Self-Learning Detection Tracker","content":" title: MaixCAM MaixPy Self Learning Detection Tracker ## MaixPy Self Learning Detection Tracker Similar to the self learning classifier, this tracker doesn't require training. You can simply select the target object by drawing a box around it, and the system will detect and track the object, making it quite useful in simple detection scenarios. Unlike the self learning classifier, the detection tracker provides the coordinates and size of the object. <video playsinline controls autoplay loop muted preload src \"/static/video/self_learn_tracker.mp4\" style \"width: 100%; min height: 20em;\"></video> ## Using the Self Learning Detection Tracker in MaixPy MaixPy currently offers a single target learning detection tracking algorithm. Once you select the target object, the tracker will continuously follow it. The algorithm used here is [NanoTrack](https://github.com/HonglinChu/SiamTrackers/tree/master/NanoTrack), which you can explore if you're interested in learning more about the underlying principles. You can directly use the built in self learning tracking application after flashing the latest system image (> 2024.9.5_v4.5.0) to see the results. To use it, call the `maix.nn.NanoTrack` class. After initializing the object, call the `init` method to specify the target to be detected, then call the `track` method to continuously track the target. Below is a simplified code example: ```python from maix import nn model_path \"/root/models/nanotrack.mud\" tracker nn.NanoTrack(model_path) tracker.init(img, x, y, w, h) pos tracker.track(img) ``` Note that this uses a built in model located in the system at `/root/models`. You can also download the model from the [MaixHub model library](https://maixhub.com/model/zoo/437). For more detailed code, refer to [MaixPy/examples/vision/ai_vision/nn_self_learn_tracker.py](https://github.com/sipeed/MaixPy/blob/main/examples/vision/ai_vision/nn_self_learn_tracker.py). ## Other Self Learning Tracking Algorithms Currently, the NanoTrack algorithm is implemented, which is highly stable and reliable in simple scenarios and provides a sufficient frame rate. However, its limitations include the need for the object to return near the last disappearance point to be detected again if it goes out of view, and the fact that it can only detect one target at a time. If you have better algorithms, you can refer to the existing NanoTrack implementation for guidance. Feel free to discuss or submit code PRs."},"/maixpy/doc/en/vision/object_track.html":{"title":"MaixCAM MaixPy Object Tracking and Counting (e.g., Pedestrian Counting)","content":" title: MaixCAM MaixPy Object Tracking and Counting (e.g., Pedestrian Counting) ## Introduction to Object Tracking Previously, we used YOLOv5, YOLOv8, or even `find_blobs` to detect objects. However, when there are multiple objects in the frame and we need to distinguish between each object, object tracking becomes necessary. For instance, if there are five people moving in the frame, we need to assign each person a number and track their movement. Applications: * Pedestrian counting, such as counting the number of people passing through a certain area. * Counting workpieces, such as counting products on a production line. * Recording and recognizing the movement trajectories of objects. ## MaixCAM/MaixPy Object Tracking and Pedestrian Counting Results As shown in the video below, the system can track each person and count those who cross the yellow area from top to bottom (displayed in the lower left corner): <video playsinline controls autoplay loop muted preload src \"/static/video/tracker.mp4\" style \"width: 100%; min height: 20em;\"></video> ## Using MaixCAM/MaixPy for Object Tracking and Pedestrian Counting You can directly install the [application](https://maixhub.com/app/61) to experience it. You can also check the [examples in the `examples/vision/tracker` directory](https://github.com/sipeed/MaixPy/tree/main/examples/vision/tracker). The `tracker_bytetrack.py` example is a basic object tracking example and involves several steps: * Use YOLOv5 or YOLOv8 to detect objects. This allows you to replace the model to detect different objects according to your needs. * Use the `maix.tracker.ByteTracker` algorithm for object tracking. Simply calling the `update` function will give you the results (the trajectory of each object in the frame), which is very straightforward. Several parameters need to be adjusted according to your specific scenario. Refer to the example code and API documentation for detailed parameter descriptions: ```python # configs conf_threshold 0.3 # detection threshold iou_threshold 0.45 # detection IOU threshold max_lost_buff_time 120 # the number of frames to keep lost tracks track_thresh 0.4 # tracking confidence threshold high_thresh 0.6 # threshold to add a new track match_thresh 0.8 # matching threshold for tracking; if IOU < match_thresh between an object in two frames, they are considered the same object max_history_num 5 # maximum length of a track's position history show_detect False # show detection valid_class_id [0] # classes used in the detection model ``` The `tracker_bytetrack_count.py` example adds pedestrian counting. To keep it simple, the example only implements counting for people walking from top to bottom. If a person is below the yellow area and their trajectory crosses into the yellow area, they are counted as crossing from top to bottom. You can write custom logic based on your specific application scenario."},"/maixpy/doc/en/vision/customize_model_yolov8.html":{"title":"Offline Training for YOLO11/YOLOv8 Models on MaixCAM MaixPy to Customize Object and Keypoint Detection","content":" title: Offline Training for YOLO11/YOLOv8 Models on MaixCAM MaixPy to Customize Object and Keypoint Detection update: date: 2024 06 21 version: v1.0 author: neucrack content: Document creation date: 2024 10 10 version: v2.0 author: neucrack content: Added YOLO11 support ## Introduction The default official model provides detection for 80 different objects. If this doesn't meet your needs, you can train your own model to detect custom objects, which can be done on your own computer or server by setting up a training environment. YOLOv8 / YOLO11 not only supports object detection but also supports keypoint detection with YOLOv8 pose / YOLO11 pose. Apart from the official human keypoints, you can also create your own keypoint dataset to train models for detecting specific objects and keypoints. Since YOLOv8 and YOLO11 mainly modify the internal network while the preprocessing and post processing remain the same, the training and conversion steps for YOLOv8 and YOLO11 are identical, except for the output node names. **Note:** This article explains how to train a custom model but assumes some basic knowledge. If you do not have this background, please learn it independently: * This article will not cover how to set up the training environment; please search for how to install and test a PyTorch environment. * This article will not cover basic machine learning concepts or Linux related knowledge. If you think there are parts of this article that need improvement, please click on `Edit this article` at the top right and submit a PR to contribute to the documentation. ## Process and Article Goal To ensure our model can be used on MaixPy (MaixCAM), it must go through the following steps: * Set up the training environment (not covered in this article, please search for how to set up a PyTorch training environment). * Clone the [YOLO11/YOLOv8](https://github.com/ultralytics/ultralytics) source code locally. * Prepare the dataset and format it according to the YOLO11 / YOLOv8 project requirements. * Train the model to obtain an `onnx` model file, which is the final output of this article. * Convert the `onnx` model into a `MUD` file supported by MaixPy, as described in the [MaixCAM Model Conversion](../ai_model_converter/maixcam.html) article. * Use MaixPy to load and run the model. ## Reference Articles Since this process is quite general, this article only provides an overview. For specific details, please refer to the **[YOLO11 / YOLOv8 official code and documentation](https://github.com/ultralytics/ultralytics)** (**recommended**) and search for training tutorials to eventually export an ONNX file. If you come across good articles, feel free to edit this one and submit a PR. ## Exporting YOLO11 / YOLOv8 ONNX Models Create an `export_onnx.py` file in the `ultralytics` directory: ```python from ultralytics import YOLO import sys print(sys.path) net_name sys.argv[1] # yolov8n.pt yolov8n pose.pt # https://docs.ultralytics.com/models/yolov8/#supported tasks and modes input_width int(sys.argv[2]) input_height int(sys.argv[3]) # Load a model model YOLO(net_name) # load an official model # model YOLO(\"path/to/best.pt\") # load a custom model # Predict with the model results model(\"https://ultralytics.com/images/bus.jpg\") # predict on an image path model.export(format \"onnx\", imgsz [input_height, input_width]) # export the model to ONNX format print(path) ``` Then run `python export_onnx.py yolov8n.pt 320 224` to export the `onnx` model. Here, we have redefined the input resolution. The model was originally trained with `640x640`, but we use `320x224` to improve the processing speed and match the MaixCAM's screen aspect ratio for convenient display. You can set the resolution according to your own needs. ## Converting to a Model Supported by MaixCAM and MUD File MaixPy/MaixCDK currently supports YOLOv8 / YOLO11 for object detection, YOLOv8 pose / YOLO11 pose for keypoint detection, and YOLOv8 seg / YOLO11 seg for segmentation (as of 2024 10 10). Follow [MaixCAM Model Conversion](../ai_model_converter/maixcam.html) to convert the model. Pay attention to the model output node selection: * Object detection: * YOLOv8 extracts `/model.22/dfl/conv/Conv_output_0,/model.22/Sigmoid_output_0` from ONNX as outputs. * YOLO11 extracts `/model.23/dfl/conv/Conv_output_0,/model.23/Sigmoid_output_0`. * Keypoint detection: * YOLOv8 pose extracts `/model.22/dfl/conv/Conv_output_0,/model.22/Sigmoid_output_0,/model.22/Concat_output_0` as outputs. * YOLO11 pose extracts `/model.23/dfl/conv/Conv_output_0,/model.23/Sigmoid_output_0,/model.23/Concat_output_0`. * Image segmentation: * YOLOv8 seg extracts `/model.22/dfl/conv/Conv_output_0,/model.22/Sigmoid_output_0,/model.22/Concat_output_0,output1`. * YOLO11 seg extracts `/model.23/dfl/conv/Conv_output_0,/model.23/Sigmoid_output_0,/model.23/Concat_output_0,output1`. ![](../../assets/yolov8_out1.jpg) ![](../../assets/yolov8_out2.jpg) For object detection, the MUD file would be as follows (replace `yolo11` for YOLO11): ```ini [basic] type cvimodel model yolov8n.cvimodel [extra] model_type yolov8 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair dryer, toothbrush ``` Replace `labels` according to the objects you trained. For keypoint detection (yolov8 pose), the MUD file would be (replace `yolo11` for YOLO11): ```ini [basic] type cvimodel model yolov8n_pose.cvimodel [extra] model_type yolov8 type pose input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels person ``` The default model is for human pose detection, so `labels` only contains `person`. Replace it according to your detected objects. For image segmentation (yolov8 seg), the MUD file would be (replace `yolo11` for YOLO11): ```ini [basic] type cvimodel model yolo11n seg_320x224_int8.cvimodel [extra] model_type yolov8 input_type rgb type seg mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair dryer, toothbrush ``` ## Upload and Share on MaixHub Visit the [MaixHub Model Library](https://maixhub.com/model/zoo?platform maixcam) to upload and share your model. Consider providing multiple resolutions for others to choose from."},"/maixpy/doc/en/vision/classify.html":{"title":"Using AI Models for Object Classification in MaixCAM MaixPy","content":" title: Using AI Models for Object Classification in MaixCAM MaixPy ## Object Classification Concept For example, if there are two images in front of you, one with an apple and the other with an airplane, the task of object classification is to input these two images into an AI model one by one. The model will then output two results, one for apple and one for airplane. ## Using Object Classification in MaixPy MaixPy provides a pre trained `1000` classification model based on the `imagenet` dataset, which can be used directly: ```python from maix import camera, display, image, nn classifier nn.Classifier(model \"/root/models/mobilenetv2.mud\", dual_buff True) cam camera.Camera(classifier.input_width(), classifier.input_height(), classifier.input_format()) dis display.Display() while 1: img cam.read() res classifier.classify(img) max_idx, max_prob res[0] msg f\"{max_prob:5.2f}: {classifier.labels[max_idx]}\" img.draw_string(10, 10, msg, image.COLOR_RED) dis.show(img) ``` Result video: <video playsinline controls autoplay loop muted preload src \"/static/video/classifier.mp4\" type \"video/mp4\"> Classifier Result video </video> Here, the camera captures an image, which is then passed to the `classifier` for recognition. The result is displayed on the screen. For more API usage, refer to the documentation for the [maix.nn](/api/maix/nn.html) module. ## dual_buff Dual Buffer Acceleration You may have noticed that the model initialization uses `dual_buff` (which defaults to `True`). Enabling the `dual_buff` parameter can improve running efficiency and increase the frame rate. For detailed principles and usage notes, see [dual_buff Introduction](./dual_buff.html). ## Training Your Own Classification Model on MaixHub If you want to train a classification model for specific images, visit [MaixHub](https://maixhub.com) to learn and train the model. When creating a project, select \"Classification Model\", then simply upload your images to train. There's no need to set up a training environment or spend money on expensive GPUs—training can be done quickly with one click. ## Offline Training for Your Own Classification Model For offline training, you need to set up your environment. Search for keywords such as `PyTorch classification model training` or `Mobilenet` for guidance. After training the model, export it in ONNX format, then refer to the [MaixCAM Model Conversion Documentation](../ai_model_converter/maixcam.html) to convert it into a model format supported by MaixCAM. Finally, use the `nn.Classifier` class mentioned above to load the model. The classification model can be Mobilenet or another model like ResNet. During model conversion, it's best to extract the layer just before `softmax` as the final output layer because the `classifier.classify(img, softmax True)` function has `softmax` enabled by default—this means the function will perform a `softmax` calculation on the results. Therefore, the model itself doesn't need a `softmax` layer. However, if the model does include a `softmax` layer, you can specify not to execute it again by using: `classifier.classify(img, softmax False)`."},"/maixpy/doc/en/vision/body_key_points.html":{"title":"MaixCAM MaixPy Human Pose Keypoint Detection","content":" title: MaixCAM MaixPy Human Pose Keypoint Detection ## Introduction Using MaixPy, you can easily detect the coordinates of keypoints on human joints, which can be used for posture detection, such as monitoring sitting posture or providing input for motion based games. MaixPy implements human pose detection based on [YOLOv8 Pose / YOLO11 Pose](https://github.com/ultralytics/ultralytics), capable of detecting `17` keypoints on the human body. ![](../../assets/body_keypoints.jpg) ## Usage You can easily implement this using the `maix.nn.YOLOv8` or `maix.nn.YOLO11` classes in MaixPy: ```python from maix import camera, display, image, nn, app detector nn.YOLOv8(model \"/root/models/yolov8n_pose.mud\", dual_buff True) # detector nn.YOLO11(model \"/root/models/yolo11n_pose.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) dis display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45, keypoint_th 0.5) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) detector.draw_pose(img, obj.points, 8 if detector.input_width() > 480 else 4, image.COLOR_RED) dis.show(img) ``` You can also find the code in the [MaixPy/examples/vision](https://github.com/sipeed/MaixPy/tree/main/examples/vision/ai_vision) directory. Since `YOLOv8 Pose` is used here, the `YOLOv8` class is also used, with the only difference being the model file compared to `YOLOv8` object detection. The same applies to `YOLO11`. The `detect` function returns an additional `points` value, which is a list of `int` containing `17` keypoints. The points are arranged in order; for example, the first value is the x coordinate of the nose, the second value is the y coordinate of the nose, and so on: ```python 1. Nose 2. Left Eye 3. Right Eye 4. Left Ear 5. Right Ear 6. Left Shoulder 7. Right Shoulder 8. Left Elbow 9. Right Elbow 10. Left Wrist 11. Right Wrist 12. Left Hip 13. Right Hip 14. Left Knee 15. Right Knee 16. Left Ankle 17. Right Ankle ``` If any of these parts are occluded, the value will be ` 1`. ## Models with More Resolutions The default model input resolution is `320x224`. If you want to use models with higher resolution, you can download and transfer them from the MaixHub model library: * YOLOv8 Pose: [https://maixhub.com/model/zoo/401](https://maixhub.com/model/zoo/401) * YOLO11 Pose: [https://maixhub.com/model/zoo/454](https://maixhub.com/model/zoo/454) Higher resolution generally provides better accuracy but at the cost of lower processing speed. Choose the model based on your application needs. If the provided resolution does not meet your requirements, you can train your own model using the source code from [YOLOv8 Pose / YOLO11 Pose](https://github.com/ultralytics/ultralytics) and export your own ONNX model, then convert it to a format supported by MaixCAM (methods are covered in later articles). ## dual_buff for Double Buffering Acceleration You may notice that `dual_buff` is used for model initialization (default value is `True`). Enabling the `dual_buff` parameter can improve efficiency and increase the frame rate. For more details and considerations, refer to the [dual_buff Introduction](./dual_buff.html)."},"/maixpy/doc/en/vision/custmize_model.html":{"title":"","content":"Please refer to [MaixCAM Model Conversion](../ai_model_converter/maixcam.html), and find the model documentation you need to convert in the left directory, such as [Custom YOLOv5 Model](./customize_model_yolov5.html)."},"/maixpy/doc/en/vision/opencv.html":{"title":"MaixCAM MaixPy Use OpenCV","content":" title: MaixCAM MaixPy Use OpenCV ## Introduction For MaixCAM, since it uses Linux and the performance can support using the Python version of OpenCV, you can use the `cv2` module directly in addition to the `maix` module. The examples in this article and more can be found in [MaixPy/examples/vision/opencv](https://github.com/sipeed/MaixPy/tree/main/examples/vision/opencv). **Note that OpenCV functions are basically CPU calculated. If you can use maix modules, try not to use OpenCV, because many maix functions are hardware accelerated.** ## Converting between Numpy/OpenCV and maix.image.Image Formats You can convert `maix.image.Image` object to a `numpy` array, which can then be used by libraries such as `numpy` and `opencv`: ```python from maix import image, time, display, app disp display.Display() while not app.need_exit(): img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_rect(0, 0, 100, 100, image.COLOR_RED, thickness 1) t time.ticks_ms() img_bgr image.image2cv(img, ensure_bgr True, copy True) img2 image.cv2image(img_bgr, bgr True, copy True) print(\"time:\", time.ticks_ms() t) print(type(img_bgr), img_bgr.shape) print(type(img2), img2) print(\"\") disp.show(img2) ``` The previous program is slower because each conversion involves a memory copy. Below is an optimized version for better performance. However, it is not recommended to use this unless you are aiming for extreme speed, as it is prone to errors: ```python from maix import image, time, display, app disp display.Display() while not app.need_exit(): img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_rect(0, 0, 100, 100, image.COLOR_RED, thickness 1) t time.ticks_ms() img_rgb image.image2cv(img, ensure_bgr False, copy False) img2 image.cv2image(img_rgb, bgr False, copy False) print(\"time:\", time.ticks_ms() t) print(type(img_rgb), img_rgb.shape) print(type(img2), img2) disp.show(img2) ``` * In `img_rgb image.image2cv(img, ensure_bgr False, copy False)`, `img_rgb` directly uses the data from `img` without creating a memory copy. Note that the obtained `img_rgb` is an `RGB` image. Since OpenCV APIs assume the image is `BGR`, you need to be careful when using OpenCV APIs to process the image. If you are not sure, set `ensure_bgr` to `True`. * In `img2 image.cv2image(img_rgb, bgr False, copy False)`, setting `copy` to `False` means `img2` directly uses the memory of `img_rgb` without creating a new memory copy, resulting in faster performance. However, be cautious because `img_rgb` must not be destroyed before `img2` finishes using it; otherwise, the program will crash. * Note that since memory is borrowed, modifying the converted image will also affect the original image. ## Load an Image ```python import cv2 file_path \"/maixapp/share/icon/detector.png\" img cv2.imread(file_path) print(img) ``` Since the `cv2` module is quite large, `import cv2` may take some time. ## Display Image on Screen To display an image on the screen, convert it to a `maix.image.Image` object and then use `display` to show it: ```python from maix import display, image, time import cv2 disp display.Display() file_path \"/maixapp/share/icon/detector.png\" img cv2.imread(file_path) img_show image.cv2image(img) disp.show(img_show) while not app.need_exit(): time.sleep(1) ``` ## Use OpenCV Functions For example, edge detection: Based on the code above, use the `cv2.Canny` function: ```python from maix import image, display, app, time import cv2 file_path \"/maixapp/share/icon/detector.png\" img0 cv2.imread(file_path) disp display.Display() while not app.need_exit(): img img0.copy() # canny method t time.ticks_ms() edged cv2.Canny(img, 180, 60) t2 time.ticks_ms() t # show by maix.display t time.ticks_ms() img_show image.cv2image(edged) print(f\"edge time: {t2}ms, convert time: {time.ticks_ms() t}ms\") disp.show(img_show) ``` ## Use Camera On a PC, we use OpenCV's `VideoCapture` class to read from the camera. For MaixCAM, OpenCV does not support this directly, so we use the `maix.camera` module to read from the camera and then use it with OpenCV. Convert a `maix.image.Image` object to a `numpy.ndarray` object using the `image.image2cv` function: ```python from maix import image, display, app, time, camera import cv2 disp display.Display() cam camera.Camera(320, 240, image.Format.FMT_BGR888) while not app.need_exit(): img cam.read() # convert maix.image.Image object to numpy.ndarray object t time.ticks_ms() img image.image2cv(img, ensure_bgr False, copy False) print(\"time: \", time.ticks_ms() t) # canny method edged cv2.Canny(img, 180, 60) # show by maix.display img_show image.cv2image(edged, bgr True, copy False) disp.show(img_show) ``` ## Read USB camera First, in the development board settings, select `USB Mode` under `USB Settings` and set it to `HOST` mode. If there is no screen available, you can use the `examples/tools/maixcam_switch_usb_mode.py` script to set it. ```python from maix import image, display, app import cv2 import sys cap cv2.VideoCapture(0) cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # cap.set(cv2.CAP_PROP_CONVERT_RGB, 0) disp display.Display() if not cap.isOpened(): print(\"无法打开摄像头\") sys.exit(1) print(\"开始读取\") while not app.need_exit(): ret, frame cap.read() if not ret: print(\"无法读取帧\") break img image.cv2image(frame, bgr True, copy False) disp.show(img) ```"},"/maixpy/doc/en/vision/self_learn_classifier.html":{"title":"MaixCAM MaixPy Self-Learning Classifier","content":" title: MaixCAM MaixPy Self Learning Classifier ## Introduction to MaixPy Self Learning Classifier Usually, to recognize new categories, we need to collect a dataset on a computer and retrain the model, which is a cumbersome and difficult process. Here, we provide a method that allows for instant learning of new objects directly on the device without the need for computer side training, suitable for less complex scenarios. For example, if there is a bottle and a phone in front of you, you can use the device to take a picture of each as the basis for two classifications. Then, you collect a few more pictures of them from different angles, extract their features and save them. During recognition, the feature values of the image are compared with the saved feature values, and the classification that is more similar to the saved features is considered the corresponding classification. ## Using the Self Learning Classifier in MaixPy The default image comes with the [Self Learning Classification APP](https://maixhub.com/app/30), which you can use directly to get familiar with the process. ![](../../assets/self_learn_classifier.jpg) Steps: * Click the `+ Class` button to collect n classification (class) images. The object needs to be within the white frame on the screen while collecting the images. * Click the `+ Sample` button to collect m sample images. Collect some images for each classification. The order does not matter, and the number is flexible. It's best to take pictures from different angles, but not too different. * Click the `Learn` button to start learning. The device will automatically classify and learn based on the collected classification and sample images, obtaining the characteristics of the classifications. * Align the object with the center of the screen, recognize the image, and output the result. The screen will show the classification it belongs to and the similarity distance to this classification. The closer the similarity distance, the more similar it is. * The feature values ​​learned by this APP will be saved to `/root/my_classes.bin`, so the last one will be automatically loaded after exiting the application or restarting it. Simplified version of the code, for the complete version, please refer to the [examples](https://github.com/sipeed/maixpy/tree/main/examples/vision/ai_vision) for the full code. ```python from maix import nn, image classifier nn.SelfLearnClassifier(model \"/root/models/mobilenetv2.mud\", dual_buff True) img1 image.load(\"/root/1.jpg\") img2 image.load(\"/root/2.jpg\") img3 image.load(\"/root/3.jpg\") sample_1 image.load(\"/root/sample_1.jpg\") sample_2 image.load(\"/root/sample_2.jpg\") sample_3 image.load(\"/root/sample_3.jpg\") sample_4 image.load(\"/root/sample_4.jpg\") sample_5 image.load(\"/root/sample_5.jpg\") sample_6 image.load(\"/root/sample_6.jpg\") classifier.add_class(img1) classifier.add_class(img2) classifier.add_class(img3) classifier.add_sample(sample_1) classifier.add_sample(sample_2) classifier.add_sample(sample_3) classifier.add_sample(sample_4) classifier.add_sample(sample_5) classifier.add_sample(sample_6) classifier.learn() img image.load(\"/root/test.jpg\") max_idx, max_score classifier.classify(img) print(max_idx, max_score) ``` ## Storing and Loading Learned Feature Values Use the `save` function to store the learned feature values. This will generate a binary file containing the feature values of the objects. When you need to use it again, simply use the `load` function to load the feature values. ```python classifier.save(\"/root/my_classes.bin\") classifier.load(\"/root/my_classes.bin\") ``` If you have named each classification and stored them in the `labels` variable, you can also use: ```python classifier.save(\"/root/my_classes.bin\", labels labels) labels classifier.load(\"/root/my_classes.bin\") ``` ## dual_buff Dual Buffer Acceleration You may have noticed that the model initialization uses `dual_buff` (which defaults to `True`). Enabling the `dual_buff` parameter can improve running efficiency and increase the frame rate. For detailed principles and usage notes, see [dual_buff Introduction](./dual_buff.html)."},"/maixpy/doc/en/vision/camera.html":{"title":"MaixCAM MaixPy Camera Usage","content":" title: MaixCAM MaixPy Camera Usage update: date: 2024 04 03 author: neucrack version: 1.0.0 content: Initial documentation ## Introduction For the MaixCAM, it comes with a pre installed GC4653 camera, or an optional OS04A10 camera or global shutter camera, and even an HDMI to MIPI module, all of which can be directly used with simple API calls. ## API Documentation This article introduces common methods. For more API usage, refer to the documentation of the [maix.camera](/api/maix/camera.html) module. ## Camera Switching Currently supported cameras: * **GC4653**: M12 universal lens, 1/3\" sensor, clear image quality, 4MP. * **OS04A10**: M12 universal lens, 1/1.8\" large sensor, ultra clear image quality, 4MP. * **OV2685**: Does not support lens replacement, lowest image quality, and lowest cost; generally not recommended for use. * **SC035HGS**: Monochrome global shutter camera, 0.3MP black and white, suitable for capturing high speed objects. The system will automatically switch; simply replace the hardware to use. ## Getting Images from the Camera Using MaixPy to easily get images: ```python from maix import camera cam camera.Camera(640, 480) while 1: img cam.read() print(img) ``` Here we import the `camera` module from the `maix` module, then create a `Camera` object, specifying the width and height of the image. Then, in a loop, we continuously read the images. The default output is in `RGB` format. If you need `BGR` format or other formats, please refer to the API documentation. ```python from maix import camera, image cam camera.Camera(640, 480, image.Format.FMT_GRAYSCALE) # Set the output greyscale image ``` Also get the NV21 image ```python from maix import camera, image cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) # set to output NV21 image ``` Note: You need to disable MaixVision's online browsing function if you set a very high resolution (e.g. `2560x1440`), otherwise the code may run abnormally due to lack of memory. You can also get greyscale images ## Setting the frame rate of the camera Currently the camera supports `30fps`, `60fps` and `80fps` configurations, the frame rate is selected by the `width`, `height`, `fps` parameters passed when creating the `Camera` object, currently the maximum supported resolution is `1280x720` under `60/80fps`, and the maximum supported resolution is `2560x1440` under `30fps`. ### Setting the frame rate to 30 fps ```python from maix import camera cam camera.Camera(640, 480, fps 30) # set the frame rate to 30 fps # or cam camera.Camera(1920, 1280) # Frame rate is set to 30 fps when resolution is higher than 1280x720 ``` ### Set the frame rate to 60 fps ```python from maix import camera cam camera.Camera(640, 480, fps 60) # Set frame rate to 60 fps # or cam camera.Camera(640, 480) # Set frame rate to 60fps if resolution is less than or equal to 1280x720 ``` ### Set the frame rate to 80 fps ```python from maix import camera cam camera.Camera(640, 480, fps 80) # Set frame rate to 60 fps ``` Notes: 1. if `Camera` is passed in a size larger than `1280x720`, for example written as `camera.Camera(1920, 1080, fps 60)`, then the `fps` parameter will be invalidated, and the frame rate will remain at `30fps`. 2. A `60/80fps` frame will be offset by a few pixels compared to a `30fps` frame, and the offset will need to be corrected if the viewing angle is critical. 3. Note that due to the fact that `60/80fps` and `30fps` share the same `isp` configuration, in some environments there will be some deviation in the quality of the screen at the two frame rates. 4. The camera's performance depends on the system. Some systems may not support setting the camera to 80fps, which can result in strange patterns appearing on the screen. In such cases, please switch back to the normal 60fps setting. ## Image correction In case of distortion such as fisheye, you can use the `lens_corr` function under the `Image` object to correct the distortion of the image. In general, you just need to increase or decrease the value of `strength` to adjust the image to the right effect. ``python from maix import camera, display cam camera.Camera(320, 240) disp display.Display() while not app.need_exit():: t time. t time.ticks_ms() img cam.read() img img.lens_corr(strength 1.5) # Adjust the strength value until the image is no longer distorted. disp display.Display() `` Note that since the correction is done through software, it takes some time. Alternatively, you can use a distortion free lens (inquire with the vendor) to solve the issue from a hardware perspective. ## Skipping Initial Frames During the brief initialization period of the camera, the image acquisition may not be stable, resulting in strange images. You can use the `skip_frames` function to skip the initial few frames: ```python cam camera.Camera(640, 480) cam.skip_frames(30) # Skip the first 30 frames ``` ## Displaying Images MaixPy provides the `display` module, which can conveniently display images: ```python from maix import camera, display cam camera.Camera(640, 480) disp display.Display() while 1: img cam.read() disp.show(img) ``` ## Setting the camera parameters ### Set exposure time Note that after setting the exposure time, the camera will switch to manual exposure mode, if you want to switch back to automatic exposure mode you need to run `cam.exp_mode(0)`. ```python cam camera.Camera() cam.exposure(1000) ``` ### Setting the gain Note that after setting the gain, the camera will switch to manual exposure mode, to switch back to auto exposure mode you need to run `cam.exp_mode(0)`. Customised gain values will only work in manual exposure mode. ```python cam camera.Camera() cam.gain(100) ``` ### Setting the white balance ```python cam camera.Camera() cam.awb_mode(1) # 0,turn on white balance;1,turn off white balance ``` ### Setting brightness, contrast and saturation ```python cam camera.Camera() cam.luma(50) # Set brightness, range [0, 100] cam.constrast(50) # set contrast, range [0, 100] cam.saturation(50) # Set the saturation, range [0, 100]. ``` ## Using a USB Camera In addition to using the MIPI interface camera that comes with the development board, you can also use an external USB camera. Method: * First, in the development board settings, select `USB Mode` under `USB Settings` and set it to `HOST` mode. If there is no screen available, you can use the `examples/tools/maixcam_switch_usb_mode.py` script to set it. * Currently (as of 2024.10.24), the `maix.camera` module does not yet support USB cameras, but you can use `OpenCV` for this. ```python from maix import image, display import cv2 import sys cap cv2.VideoCapture(0) cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # cap.set(cv2.CAP_PROP_CONVERT_RGB, 0) disp display.Display() if not cap.isOpened(): print(\"Unable to open camera\") sys.exit(1) print(\"Starting to read\") while True: ret, frame cap.read() if not ret: print(\"Unable to read frame\") return img image.cv2image(frame, bgr True, copy False) disp.show(img) ```"},"/maixpy/doc/en/no_translate.html":{"title":"no translation","content":" title: no translation class: md_page <div id \"visit_from\"></div> <div id \"no_translate_hint\">This page not translated yet</div> <div> <span id \"visit_hint\">Please visit</span> <a id \"translate_src\"></a> </div> <div> <script> function getQueryVariable(variable) { var query window.location.search.substring(1); var vars query.split(\"&\"); for (var i 0;i<vars.length;i++) { var pair vars[i].split(\" \"); if(pair[0] variable){return pair[1];} } return(false); } var ref getQueryVariable(\"ref\"); var from getQueryVariable(\"from\"); var link document.getElementById(\"translate_src\"); var fromDis document.getElementById(\"visit_from\"); link.href ref; link.text ref; fromDis.innerHTML from; </script> </div>"}}